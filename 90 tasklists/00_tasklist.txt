tasklist : 
11th 
set to (✅)

31 August week:
Worked in file : DFS_frog_yajat

1.) We will be connecting with PHD student (Mahroosh)
2.)  See how attention maps behave when  images with multiple objects
 3.) Get more complex images from Kailash
 -    Fewer heads have problem with confounding maps
4.) We look at the  output layer ( when attention maps multiplied by value) (it will have all heads combined)
5.) Downsample the image of dog/cat combine we had to 32*32  - Y
6. see 04 tried from new dataset , evauated on images from visualisation repo and all iamges failed -A
7. see prpbabilites(confidence) and attentions on the same and what assigned on misclassified -A


week 3 . 2 : 
    1 . look at 
    https://github.com/kentaroy47/vision-transformers-cifar10

    instead of running from command line, we need to go and set these arguments manually
    i.e. open train_cifar10.py and manually set patchsise = 4 and epoch  = 500
    and train the model
    (btw if you start gettting good accuracy then stop traiing, since we need to add logit saving code and train again)

    2 . vit_food.ipynb (in this repo) for reference : added as ipynb
    can copy codes for git clone etc
    noet : this one is modified version, original can be seen at his page (linekd at top of vit_food.ipynb)

    3. other resource if 1 doesnt work out :
    this guy has written this blog and claims to acheive 75% after 100 lines of training in blog
    but in his code there is only 5 epochs tak trianing so less reliable   

    code : https://github.com/tintn/vision-transformer-from-scratch/blob/main/vision_transformers.ipynb

    blog : https://tintn.github.io/Implementing-Vision-Transformer-from-Scratch/


week 3 : 
    1. abstract ⭕
    2. kaggle : 17 flowers: [REFERENCE for training loop]
        https://www.kaggle.com/code/asterisk007/17-flowers
        
    3.[CODE] vit2 : change learning rate manually by seeing  [CODE]: ayushmaan
    
    3. cnn : transfer and replicating
        transfer learning : https://www.learnpytorch.io/06_pytorch_transfer_learning/ [REFERENCE]


      [CODE] 3/4  replicating : 
        https://www.learnpytorch.io/08_pytorch_paper_replicating/

    4. LLM : 3 lecture (for anlaysis) [LATER]
        watch : https://lcs2-iitd.github.io/ELL881-AIL821-2401/lectures/
        lecs 5.3, 6.1, 6.2

    4. pre training : yajat
     [CODE]   pytorch pretrained : vit_b_32(ViT_B_32_Weights.IMAGENET1K_V1)  into vit_b_32
            take weights and put into vit_2 (new file)
        redownload oxford dataset 
        

      [CODE] 3/4 try with new dataset: <insert link>

      ANlalysis :
        1. feature atrribution method from cnn
        2. 


week 1:

    A Classes change: ✅ a
        1. type from classes_ref.ipynb into list manually
        2. change these into the list manually 
        set labels manually :
        1200 , 0
        1500, 0
        1650, 1
        2050, 0
        2250, 0
        2350, 0
        2450, 0
        2750, 0

        set 2800 to dog


        3. zip the list 
        4. load zippped list and check wtih non loaded list 
        save into classes_list.gz 
            eg :
            with gzip.open('new_labels.gz', 'rb') as f:
                loaded_labels = pickle.load(f)
            # with gzip.open('binary_label_dict.gz', 'rb') as f:
            #     loaded_labels = pickle.load(f)

            # # Display the loaded list
            # print("Loaded list:", loaded_list)

    B Binary class ✅ a
        1. write code to change dataset classes to classes from clases_list.gz
        2. BCE loss
        3. Reduce number of layers
        4. Train and loss and accuracy

    C Gradients: ❌  y
        1. write code to fetch and display gradient from any layers [weite a function]
        2. see if graident can be even seen? else just display weights 

    Next meet :
    look at performance after A and B
    look grads if needed : 
        then go for dropout or skip

---------------------------------------------------------
Monday 12th:
Week 2:
    C look at implmenetation using just 2k sales on vit:
        triaiming with only 2040 sales? idk if this is true ? needs verification : (a)
            https://github.com/niranjankrishna-acad/Training-Vision-Transformers-with-Only-2040-Images
                1. inspect dataset
                2. inspect model acrichtecture if it is correct? is it really a Vit?
                3. Do we fully understand the model?
                3. is the model interpretable? as in can we interpret all the components?

    D Read pretrained
        1. pretrained resrouces : (y)
                1. https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html#torchvision.models.vit_b_16
                2. Imagenet

            2. Hyperaperemter copy/fine tuning:
                1 ) someone said Hugging fave : write code 
                2) fine tuning sttrats like LORA etc(need pretrained anyway) : write
            3. 




        dataset : CIFAR
        Tensorflow implementation

    

