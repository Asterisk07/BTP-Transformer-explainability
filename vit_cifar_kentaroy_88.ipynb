{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n'''\n\nTrain CIFAR10 with PyTorch and Vision Transformers!\nwritten by @kentaroy47, @arutema47\nsource : https://github.com/kentaroy47/vision-transformers-cifar10\n\n'''\n\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport numpy as np\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport pandas as pd\nimport csv\nimport time\n\n\n","metadata":{"id":"Llt_Ire4Sxp2","execution":{"iopub.status.busy":"2024-08-23T02:48:56.082293Z","iopub.execute_input":"2024-08-23T02:48:56.082719Z","iopub.status.idle":"2024-08-23T02:48:56.093700Z","shell.execute_reply.started":"2024-08-23T02:48:56.082679Z","shell.execute_reply":"2024-08-23T02:48:56.092561Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"run_number = 1\nbase_dir = \"results/runs\"\n\n# Define the new run directory\n\nos.makedirs(\"results\", exist_ok=True)\nos.makedirs(\"results/runs\", exist_ok=True)","metadata":{"id":"MmxrO8v6Sxp5","execution":{"iopub.status.busy":"2024-08-23T02:48:56.095914Z","iopub.execute_input":"2024-08-23T02:48:56.097109Z","iopub.status.idle":"2024-08-23T02:48:56.105185Z","shell.execute_reply.started":"2024-08-23T02:48:56.097057Z","shell.execute_reply":"2024-08-23T02:48:56.104253Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ROEAX6L0Wf7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O9k1NsUWISs","outputId":"6b67a80e-f9d1-43af-ebf4-3088aa41efd0","execution":{"iopub.status.busy":"2024-08-23T02:48:56.107022Z","iopub.execute_input":"2024-08-23T02:48:56.107280Z","iopub.status.idle":"2024-08-23T02:48:56.116426Z","shell.execute_reply.started":"2024-08-23T02:48:56.107251Z","shell.execute_reply":"2024-08-23T02:48:56.115471Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x78b034bbc410>"},"metadata":{}}]},{"cell_type":"code","source":"# # setup for a read only personal access token\n# # note : token expires 19 aug 2025\n# token = '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'\n# token_user = 'Asterisk07'\n# repo_host = 'Asterisk07'\n# repo_name = 'BTP-Transformer-explainability'\n\n# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n# !git clone {url}\n\n# !mv {repo_name}/models .\n# !rm -rf BTP-Transformer-explainability # delete a file","metadata":{"id":"aa7zHkXPSxp5","execution":{"iopub.status.busy":"2024-08-23T02:48:56.117554Z","iopub.execute_input":"2024-08-23T02:48:56.117865Z","iopub.status.idle":"2024-08-23T02:48:56.122691Z","shell.execute_reply.started":"2024-08-23T02:48:56.117834Z","shell.execute_reply":"2024-08-23T02:48:56.121820Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JfB6PgwoSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YF9tLt1iSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eQR0IlVsSxp7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fnxx0KDSxp7","outputId":"c0015607-859a-4164-db22-8783ff70f8c1","execution":{"iopub.status.busy":"2024-08-23T02:48:56.124270Z","iopub.execute_input":"2024-08-23T02:48:56.124602Z","iopub.status.idle":"2024-08-23T02:48:57.172944Z","shell.execute_reply.started":"2024-08-23T02:48:56.124564Z","shell.execute_reply":"2024-08-23T02:48:57.171709Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"__pycache__  data  log\tresults  utils.py  wandb\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"rO-x5w5QSxp8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf models","metadata":{"id":"aDRb-t5HSxp9","execution":{"iopub.status.busy":"2024-08-23T02:48:57.174508Z","iopub.execute_input":"2024-08-23T02:48:57.174847Z","iopub.status.idle":"2024-08-23T02:48:57.180431Z","shell.execute_reply.started":"2024-08-23T02:48:57.174809Z","shell.execute_reply":"2024-08-23T02:48:57.179399Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# !npm install -g github-files-fetcher","metadata":{"id":"nyZGC9wISxp9","execution":{"iopub.status.busy":"2024-08-23T02:48:57.182812Z","iopub.execute_input":"2024-08-23T02:48:57.183316Z","iopub.status.idle":"2024-08-23T02:48:57.190202Z","shell.execute_reply.started":"2024-08-23T02:48:57.183284Z","shell.execute_reply":"2024-08-23T02:48:57.189125Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n","metadata":{"id":"XLQdzmZYSxp9","execution":{"iopub.status.busy":"2024-08-23T02:48:57.191629Z","iopub.execute_input":"2024-08-23T02:48:57.192236Z","iopub.status.idle":"2024-08-23T02:48:57.197541Z","shell.execute_reply.started":"2024-08-23T02:48:57.192192Z","shell.execute_reply":"2024-08-23T02:48:57.196518Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZPrL29xSxp9","outputId":"0cab9daf-2631-4d8f-ee64-1d51ccbdf40e","execution":{"iopub.status.busy":"2024-08-23T02:48:57.198697Z","iopub.execute_input":"2024-08-23T02:48:57.199023Z","iopub.status.idle":"2024-08-23T02:48:57.207678Z","shell.execute_reply.started":"2024-08-23T02:48:57.198982Z","shell.execute_reply":"2024-08-23T02:48:57.206528Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"u0zItmyxSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Check if 'utils.py' exists in the current directory\nif os.path.exists('utils.py'):\n    print(\"utils.py exists in the current directory.\")\nelse:\n    print(\"utils.py does not exist in the current directory.\")\n    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n    print(\"utils.py fetched\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSnJhbUCU4J9","outputId":"d466bf62-4b25-4a9b-d2f7-83213799ad8a","execution":{"iopub.status.busy":"2024-08-23T02:48:57.209037Z","iopub.execute_input":"2024-08-23T02:48:57.209886Z","iopub.status.idle":"2024-08-23T02:48:57.218264Z","shell.execute_reply.started":"2024-08-23T02:48:57.209810Z","shell.execute_reply":"2024-08-23T02:48:57.217404Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"utils.py exists in the current directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"id":"5XLsXJxiSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import progress_bar","metadata":{"id":"Pe1-pReSSxp-","execution":{"iopub.status.busy":"2024-08-23T02:48:57.219630Z","iopub.execute_input":"2024-08-23T02:48:57.220244Z","iopub.status.idle":"2024-08-23T02:48:57.225205Z","shell.execute_reply.started":"2024-08-23T02:48:57.220201Z","shell.execute_reply":"2024-08-23T02:48:57.224201Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"progress_bar","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"_yVbM9QmSxp-","outputId":"2ebfb3d7-3459-40ed-c8a1-33e3839da492","execution":{"iopub.status.busy":"2024-08-23T02:48:57.229041Z","iopub.execute_input":"2024-08-23T02:48:57.229372Z","iopub.status.idle":"2024-08-23T02:48:57.236795Z","shell.execute_reply.started":"2024-08-23T02:48:57.229316Z","shell.execute_reply":"2024-08-23T02:48:57.235817Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"<function utils.progress_bar(current, total, msg=None)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"mlKjovnlSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# from randomaug import RandAugment\nfrom torchvision.transforms import RandAugment\n\n","metadata":{"id":"RGLFDHKiSxp_","execution":{"iopub.status.busy":"2024-08-23T02:48:57.238090Z","iopub.execute_input":"2024-08-23T02:48:57.238772Z","iopub.status.idle":"2024-08-23T02:48:57.243745Z","shell.execute_reply.started":"2024-08-23T02:48:57.238726Z","shell.execute_reply":"2024-08-23T02:48:57.242778Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rHHLarISxp_","outputId":"45997e81-9926-4465-d2dd-12835012d6b5","execution":{"iopub.status.busy":"2024-08-23T02:48:57.245142Z","iopub.execute_input":"2024-08-23T02:48:57.246217Z","iopub.status.idle":"2024-08-23T02:49:10.040562Z","shell.execute_reply.started":"2024-08-23T02:48:57.246153Z","shell.execute_reply":"2024-08-23T02:49:10.039103Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.8.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# from models import *\n# from models.vit import ViT\n# from models.convmixer import ConvMixer","metadata":{"id":"UsC7sE2cSxp_","execution":{"iopub.status.busy":"2024-08-23T02:49:10.042714Z","iopub.execute_input":"2024-08-23T02:49:10.043050Z","iopub.status.idle":"2024-08-23T02:49:10.050057Z","shell.execute_reply.started":"2024-08-23T02:49:10.043015Z","shell.execute_reply":"2024-08-23T02:49:10.048932Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJEMQtO5Upra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport json","metadata":{"id":"VJNDccCQe_XC","execution":{"iopub.status.busy":"2024-08-23T02:49:10.051733Z","iopub.execute_input":"2024-08-23T02:49:10.052139Z","iopub.status.idle":"2024-08-23T02:49:10.062518Z","shell.execute_reply.started":"2024-08-23T02:49:10.052094Z","shell.execute_reply":"2024-08-23T02:49:10.061382Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"\nqkv_titles = ['q','k','v']","metadata":{"id":"WADSesO6g1ea","execution":{"iopub.status.busy":"2024-08-23T02:49:10.063763Z","iopub.execute_input":"2024-08-23T02:49:10.064075Z","iopub.status.idle":"2024-08-23T02:49:10.071650Z","shell.execute_reply.started":"2024-08-23T02:49:10.064034Z","shell.execute_reply":"2024-08-23T02:49:10.070515Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n# VIT.py\nimport torch\nfrom torch import nn\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\nimport numpy as np\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        out =  self.net(x)\n        if(save_flag==True):\n                file_path = os.path.join(run_dir, 'ff_out.npy')\n                # np.save(file_path, out)\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n        return out\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n\n        inner_dim = dim_head *  heads\n        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim = -1)\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        qkv = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n\n\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n\n        out = torch.matmul(attn, v)\n        if(save_flag==True):\n\n                # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n                for i, tensor in enumerate((q,k,v)):\n                    np_array = tensor[img_idx].detach().cpu().numpy()  # Convert to numpy\n                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n                    np.save(file_path, np_array)\n                file_path = os.path.join(run_dir, 'att_out')\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n                file_path = os.path.join(run_dir, 'att_score')\n                np.save(file_path,attn[img_idx].detach().cpu().numpy())\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        # return self.to_out(out),q,k,v\n        return self.to_out(out)\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n        super().__init__()\n        # print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n\n        self.layers = nn.ModuleList([])\n#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n        # self.saved_values = list()  # To store th\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n            ]))\n\n    def forward(self, x,save_flag=False, run_dir = None, img_idx = None):\n        for i, (attn, ff) in enumerate(self.layers):\n            # Unpack the output from the Attention layer\n            #\n            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n            if save_flag:\n              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n              os.makedirs(layer_dir, exist_ok=True)\n              # print(\"passed trans layer direcetory \", layer_dir)\n            else:\n              layer_dir = None\n            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx)\n\n\n\n            # Save the query, key, value, and logits (output) for this layer\n            # self.saved_values.append(q.cpu().detach().numpy())\n            # self.saved_values.append(k.cpu().detach().numpy())\n            # self.saved_values.append(v.cpu().detach().numpy())\n\n            # Combine the attention output with the original x\n            x = attn_out + x\n            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n            # print(\"i : \",i)\n            # Apply the feedforward network\n#             x = ff(x) + x\n\n            x = ff(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx) + x\n\n        return x\n\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        # print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img, save_flag=False, run_dir = None,img_idx = None):\n        # if (save_flag):\n          # print(\"\\n\\treached here 3\")\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n\n        x = self.transformer(x,save_flag, run_dir, img_idx)\n#         if(save_flag==True):\n#                 # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n#                 for i, tensor in enumerate(qkv):\n#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n\n\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"id":"OzQdLRddSxp_","execution":{"iopub.status.busy":"2024-08-23T02:49:10.073706Z","iopub.execute_input":"2024-08-23T02:49:10.074065Z","iopub.status.idle":"2024-08-23T02:49:10.118752Z","shell.execute_reply.started":"2024-08-23T02:49:10.074027Z","shell.execute_reply":"2024-08-23T02:49:10.117792Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RskDA5B5zDv6","outputId":"85715f3b-73f8-4996-e0e8-b43df9b8dc08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Define your arguments here\ndef parse_args():\n    # parsers\n    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n    parser.add_argument('--opt', default=\"adam\")\n    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n    parser.add_argument('--net', default='vit')\n    parser.add_argument('--dp', action='store_true', help='use data parallel')\n    parser.add_argument('--bs', default='512')\n    parser.add_argument('--size', default=\"32\")\n    parser.add_argument('--n_epochs', type=int, default='200')\n    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n    parser.add_argument('--dimhead', default=\"512\", type=int)\n    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n\n    return parser.parse_args()\n\n\n","metadata":{"id":"GVdr58MRSxp_","execution":{"iopub.status.busy":"2024-08-23T02:49:10.119902Z","iopub.execute_input":"2024-08-23T02:49:10.120224Z","iopub.status.idle":"2024-08-23T02:49:10.135772Z","shell.execute_reply.started":"2024-08-23T02:49:10.120192Z","shell.execute_reply":"2024-08-23T02:49:10.134747Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\ncommand.split()[1:]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JbxSOG5SxqA","outputId":"2c280127-8d9e-4cd0-fc27-3bc03c51d0f2","execution":{"iopub.status.busy":"2024-08-23T02:49:10.137495Z","iopub.execute_input":"2024-08-23T02:49:10.137867Z","iopub.status.idle":"2024-08-23T02:49:10.149201Z","shell.execute_reply.started":"2024-08-23T02:49:10.137822Z","shell.execute_reply":"2024-08-23T02:49:10.148258Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"},"metadata":{}}]},{"cell_type":"code","source":"# Simulate command-line arguments\n# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\nsys.argv = command.split()[1:]\n\nargs = parse_args()\n\n","metadata":{"id":"SFLk9RG5SxqA","execution":{"iopub.status.busy":"2024-08-23T02:49:10.150808Z","iopub.execute_input":"2024-08-23T02:49:10.151155Z","iopub.status.idle":"2024-08-23T02:49:10.158285Z","shell.execute_reply.started":"2024-08-23T02:49:10.151115Z","shell.execute_reply":"2024-08-23T02:49:10.157125Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall","metadata":{"id":"TZfQJlNKSxqA","execution":{"iopub.status.busy":"2024-08-23T02:49:10.159690Z","iopub.execute_input":"2024-08-23T02:49:10.160085Z","iopub.status.idle":"2024-08-23T02:49:10.165424Z","shell.execute_reply.started":"2024-08-23T02:49:10.160052Z","shell.execute_reply":"2024-08-23T02:49:10.164501Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZRdesLOdSxqA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (2.0.1+cu117)\n# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)","metadata":{"id":"xBdPskigSxqA","execution":{"iopub.status.busy":"2024-08-23T02:49:10.166979Z","iopub.execute_input":"2024-08-23T02:49:10.167570Z","iopub.status.idle":"2024-08-23T02:49:10.173750Z","shell.execute_reply.started":"2024-08-23T02:49:10.167467Z","shell.execute_reply":"2024-08-23T02:49:10.172630Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# !pip show torchvision\n","metadata":{"id":"uiDtWCYKSxqA","execution":{"iopub.status.busy":"2024-08-23T02:49:10.175281Z","iopub.execute_input":"2024-08-23T02:49:10.175933Z","iopub.status.idle":"2024-08-23T02:49:10.184241Z","shell.execute_reply.started":"2024-08-23T02:49:10.175888Z","shell.execute_reply":"2024-08-23T02:49:10.183225Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"id":"_T0LacFUt74i","execution":{"iopub.status.busy":"2024-08-23T02:49:10.185630Z","iopub.execute_input":"2024-08-23T02:49:10.186009Z","iopub.status.idle":"2024-08-23T02:49:10.193226Z","shell.execute_reply.started":"2024-08-23T02:49:10.185965Z","shell.execute_reply":"2024-08-23T02:49:10.192129Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# !pip show torch\n# #","metadata":{"id":"NRmD_dGiSxqA","execution":{"iopub.status.busy":"2024-08-23T02:49:10.194595Z","iopub.execute_input":"2024-08-23T02:49:10.195683Z","iopub.status.idle":"2024-08-23T02:49:10.199911Z","shell.execute_reply.started":"2024-08-23T02:49:10.195638Z","shell.execute_reply":"2024-08-23T02:49:10.198995Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m-UHnDboSxqA","outputId":"81f73c03-4a0e-490f-e36e-08f56d3b0124","execution":{"iopub.status.busy":"2024-08-23T02:49:10.206547Z","iopub.execute_input":"2024-08-23T02:49:10.206923Z","iopub.status.idle":"2024-08-23T02:49:10.214519Z","shell.execute_reply.started":"2024-08-23T02:49:10.206879Z","shell.execute_reply":"2024-08-23T02:49:10.213488Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"'0.19.0'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aQh5PidkSxqA","outputId":"78297830-3ca1-42b2-fa0a-1b761d0e61fe","execution":{"iopub.status.busy":"2024-08-23T02:49:10.215745Z","iopub.execute_input":"2024-08-23T02:49:10.216069Z","iopub.status.idle":"2024-08-23T02:49:10.223458Z","shell.execute_reply.started":"2024-08-23T02:49:10.216038Z","shell.execute_reply":"2024-08-23T02:49:10.222413Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hedCXexeSxqB","outputId":"247ba528-fb2e-4d69-e300-408eb63d93dd","execution":{"iopub.status.busy":"2024-08-23T02:49:10.224953Z","iopub.execute_input":"2024-08-23T02:49:10.225241Z","iopub.status.idle":"2024-08-23T02:49:23.351781Z","shell.execute_reply.started":"2024-08-23T02:49:10.225210Z","shell.execute_reply":"2024-08-23T02:49:23.350457Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# take in args\nusewandb = ~args.nowandb\nif usewandb:\n    import wandb\n    watermark = \"{}_lr{}\".format(args.net, args.lr)\n    wandb.init(project=\"cifar10-challange\",\n            name=watermark)\n    wandb.config.update(args)\n\nbs = int(args.bs)\nimsize = int(args.size)\n\nuse_amp = not args.noamp\naug = args.noaug\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\nif args.net==\"vit_timm\":\n    size = 384\nelse:\n    size = imsize\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize(size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Add RandAugment with N, M(hyperparameter)\nif aug:\n    N = 2; M = 14;\n    transform_train.transforms.insert(0, RandAugment(N, M))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"qnyCPg0HSxqB","outputId":"f6b2c294-26d0-4eaf-aede-2eb3a3c436b9","execution":{"iopub.status.busy":"2024-08-23T02:49:23.353727Z","iopub.execute_input":"2024-08-23T02:49:23.354167Z","iopub.status.idle":"2024-08-23T02:49:45.207016Z","shell.execute_reply.started":"2024-08-23T02:49:23.354116Z","shell.execute_reply":"2024-08-23T02:49:45.205875Z"},"trusted":true},"execution_count":117,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:wcpj5vvz) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▁▂▂▃▄▅▂▂▃▄▅▅▆▇▁▂▂▃▄▅▅▆▁▁▂▂▃▄▅▁▂▃▄▅▅▆▇█</td></tr><tr><td>epoch_time</td><td>▅▅▇▂▂▃▃▂▂▂▃▂▁▁▁▁▇▂▁▁▂▁▂▁█▇▂▁▂▂▂▇▁▃▂▂▂▂▂▇</td></tr><tr><td>lr</td><td>████▇▇▇▆█▇▇▇▆▅▄▃██▇▇▇▆▅▄███▇▇▇▆█▇▇▇▆▅▄▃▁</td></tr><tr><td>train_loss</td><td>█▆█▆▄▄▃▃▆▄▄▃▃▂▂▁█▆▄▄▃▃▂▂██▆▄▄▃▃█▄▄▃▃▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▂▁▂▄▅▅▆▂▄▅▅▆▆▇▇▁▂▄▅▅▆▆▇▁▁▂▄▅▅▆▁▄▅▅▆▆▇▇█</td></tr><tr><td>val_loss</td><td>█▇█▇▅▄▄▃▇▅▄▄▃▃▃▂█▇▅▄▄▃▃▃██▇▅▄▄▃█▅▄▄▃▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>epoch_time</td><td>31.31984</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>train_loss</td><td>1.29985</td></tr><tr><td>val_acc</td><td>63.19</td></tr><tr><td>val_loss</td><td>102.83137</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vit_lr0.0005</strong> at: <a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange/runs/wcpj5vvz' target=\"_blank\">https://wandb.ai/asterisk07-iit-delhi/cifar10-challange/runs/wcpj5vvz</a><br/> View project at: <a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange' target=\"_blank\">https://wandb.ai/asterisk07-iit-delhi/cifar10-challange</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240823_015349-wcpj5vvz/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:wcpj5vvz). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240823_024923-w99t1zvt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange/runs/w99t1zvt' target=\"_blank\">vit_lr0.0005</a></strong> to <a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange' target=\"_blank\">https://wandb.ai/asterisk07-iit-delhi/cifar10-challange</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asterisk07-iit-delhi/cifar10-challange/runs/w99t1zvt' target=\"_blank\">https://wandb.ai/asterisk07-iit-delhi/cifar10-challange/runs/w99t1zvt</a>"},"metadata":{}},{"name":"stdout","text":"==> Preparing data..\n","output_type":"stream"}]},{"cell_type":"code","source":"# use only this token :\n# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe #aster","metadata":{"id":"V-X21wSpSxqB","execution":{"iopub.status.busy":"2024-08-23T02:49:45.208365Z","iopub.execute_input":"2024-08-23T02:49:45.208653Z","iopub.status.idle":"2024-08-23T02:49:45.212447Z","shell.execute_reply.started":"2024-08-23T02:49:45.208621Z","shell.execute_reply":"2024-08-23T02:49:45.211590Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"NUM_WORKERS = 4\n\n# Prepare dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUzFJatHSxqB","outputId":"3a5a3505-936f-4461-b40a-fc75c7fb4f98","execution":{"iopub.status.busy":"2024-08-23T02:49:45.213590Z","iopub.execute_input":"2024-08-23T02:49:45.213955Z","iopub.status.idle":"2024-08-23T02:49:46.851306Z","shell.execute_reply.started":"2024-08-23T02:49:45.213921Z","shell.execute_reply":"2024-08-23T02:49:46.850495Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# For Multi-GPU\nif 'cuda' in device:\n    print(device)\n    if args.dp:\n        print(\"using data parallel\")\n        net = torch.nn.DataParallel(net) # make parallel\n        cudnn.benchmark = True\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUqsuNN8SxqB","outputId":"0a2d5706-2adf-45db-d903-f74316ec1faa","execution":{"iopub.status.busy":"2024-08-23T02:49:46.852420Z","iopub.execute_input":"2024-08-23T02:49:46.852727Z","iopub.status.idle":"2024-08-23T02:49:46.858578Z","shell.execute_reply.started":"2024-08-23T02:49:46.852694Z","shell.execute_reply":"2024-08-23T02:49:46.857815Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"ycedpM59zTyh","outputId":"aa2b13bb-b636-44c7-9b7d-b2f2880470da","execution":{"iopub.status.busy":"2024-08-23T02:49:46.860012Z","iopub.execute_input":"2024-08-23T02:49:46.860416Z","iopub.status.idle":"2024-08-23T02:49:47.938092Z","shell.execute_reply.started":"2024-08-23T02:49:46.860330Z","shell.execute_reply":"2024-08-23T02:49:47.936934Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"\ndef get_vit():\n    return ViT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,\n    heads = 8,\n    # mlp_dim = 512,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    )","metadata":{"id":"ygIfkREcrvX7","execution":{"iopub.status.busy":"2024-08-23T02:49:47.939683Z","iopub.execute_input":"2024-08-23T02:49:47.940025Z","iopub.status.idle":"2024-08-23T02:49:47.946106Z","shell.execute_reply.started":"2024-08-23T02:49:47.939989Z","shell.execute_reply":"2024-08-23T02:49:47.945201Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model factory..\nprint('==> Building model..')\n# net = VGG('VGG19')\nif args.net==\"vit\":\n    # ViT for cifar10\n    net = get_vit()\n\n\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ND8qhixnSxqB","outputId":"e6edb544-3753-446e-ae32-03a9ab15df36","execution":{"iopub.status.busy":"2024-08-23T02:49:47.947256Z","iopub.execute_input":"2024-08-23T02:49:47.947622Z","iopub.status.idle":"2024-08-23T02:49:48.031742Z","shell.execute_reply.started":"2024-08-23T02:49:47.947587Z","shell.execute_reply":"2024-08-23T02:49:48.030850Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"nc4jNV-bSxqC","execution":{"iopub.status.busy":"2024-08-23T02:49:48.032765Z","iopub.execute_input":"2024-08-23T02:49:48.033058Z","iopub.status.idle":"2024-08-23T02:49:48.037264Z","shell.execute_reply.started":"2024-08-23T02:49:48.033025Z","shell.execute_reply":"2024-08-23T02:49:48.036415Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"\nlen(trainloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8emZ75LWcpgE","outputId":"5423fb4a-63af-4ffb-a027-899ae0d60136","execution":{"iopub.status.busy":"2024-08-23T02:49:48.038395Z","iopub.execute_input":"2024-08-23T02:49:48.038686Z","iopub.status.idle":"2024-08-23T02:49:48.047291Z","shell.execute_reply.started":"2024-08-23T02:49:48.038655Z","shell.execute_reply":"2024-08-23T02:49:48.046399Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"98"},"metadata":{}}]},{"cell_type":"code","source":"\n# trainloader[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"GCKRyskOugE5","outputId":"32f19894-9636-4bac-b61a-6db4237f6da5","execution":{"iopub.status.busy":"2024-08-23T02:49:48.048755Z","iopub.execute_input":"2024-08-23T02:49:48.049615Z","iopub.status.idle":"2024-08-23T02:49:48.054006Z","shell.execute_reply.started":"2024-08-23T02:49:48.049570Z","shell.execute_reply":"2024-08-23T02:49:48.053003Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"MAX_EPOCHS = 90","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:49:48.055248Z","iopub.execute_input":"2024-08-23T02:49:48.055909Z","iopub.status.idle":"2024-08-23T02:49:48.061082Z","shell.execute_reply.started":"2024-08-23T02:49:48.055865Z","shell.execute_reply":"2024-08-23T02:49:48.060318Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Loss is CE\ncriterion = nn.CrossEntropyLoss()\n\ntorch.manual_seed(42)\nnet = get_vit()\n\nif args.opt == \"adam\":\n    optimizer = optim.Adam(net.parameters(), lr=args.lr)\nelif args.opt == \"sgd\":\n    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n\n# use cosine scheduling\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n\n##### Training\nscaler = torch.amp.GradScaler('cuda',enabled=use_amp)\ndef train(epoch,save_flag, run_dir = None, img_idx = None):\n    \n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    # img_factor = len(trainloader) // img_save_count\n    # run_dir = os.path.join(run_dir,  {epoch:02}\")\n\n    # data_save=list()\n    # main_list=list()\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # Train with amp\n        with torch.amp.autocast('cuda',enabled=use_amp):\n            # if(save_flag==True and batch_idx%img_factor==0):\n\n            if(save_flag==True and batch_idx==0):\n                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n                os.makedirs(batch_dir, exist_ok=True)\n                # np.save(file_path, np_array)\n                # print(\"\\n\\tpassed \",batch_dir, type(batch_dir))\n\n                outputs = net(inputs, True, batch_dir, img_idx)\n                # outputs = net(inputs, False, 12)\n                #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n            else:\n                outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    # data_save.append(net.transformer.saved_values)\n\n#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n#     return train_loss/(batch_idx+1),net.transformer.saved_values\n    return train_loss/(batch_idx+1)\n##### Validation\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n#     if acc > best_acc:\n#         print('Saving..')\n#         state = {\"model\": net.state_dict(),\n#               \"optimizer\": optimizer.state_dict(),\n#               \"scaler\": scaler.state_dict()}\n#         if not os.path.isdir('checkpoint'):\n#             os.mkdir('checkpoint')\n#         torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n#         best_acc = acc\n\n#     os.makedirs(\"log\", exist_ok=True)\n     os.makedirs(\"results\", exist_ok=True)\n     os.makedirs(\"results/log\", exist_ok=True)\n    content = f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n    print(content)\n    with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n        appender.write(content + \"\\n\")\n    return test_loss, acc\n\nlist_loss = []\nlist_acc = []\n\nif usewandb:\n    wandb.watch(net)\n\n    \n\n# save_epochs-=1\nbatch_size = int(args.bs)\n# max_epochs = args.n_epochs\n\n\n\n\nif device == 'cuda':\n  net.cuda()\nmain_list=list()\ndata_save=list()\nn_param=5\n\nrun_dir = os.path.join(base_dir, f\"run {run_number:02}\")\nos.makedirs(run_dir, exist_ok=True)\nprint(\"Run number \",run_number)\n\nimg_idx = torch.randperm(batch_size)[:img_save_count]\nimg_idx= img_idx.sort()[0]\nprint(\"chosen images are of batch 0 and numbers : \",[x.item() for x in list(img_idx)])\n\n\nfile_path = os.path.join(run_dir, 'img_idx.npy')\nnp.save(file_path, img_idx.detach().cpu().numpy())\n\n\n\n\nimport shutil\nfrom IPython.display import FileLink\n\n# Specify the directory you want to compress\ndirectory_name = run_dir\nzip_filename = f'{run_dir}.zip'\n\n\n\n\nrun_number += 1\n\nmax_epochs = MAX_EPOCHS\n\n# take_epoch_factor = \nimg_save_count = 50 #IMP\n\nsave_epochs = 11 #IMP\n# epoch_factor = max_epochs  // save_epochs #IMP\n\nepoch_factor = 10 #IMP\n\n\nprint(f\"Saving every {epoch_factor} epochs \")\n\n\n\n\nprint(\"Training started\")\nfor i in tqdm(range(start_epoch, max_epochs), desc=\"Training\"):\n    epoch = i+1\n#     print('\\nEpoch: %d' % epoch)\n    start = time.time()\n#     if(epoch%epoch_factor==0 or epoch == max_epochs):\n    \n    if(epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs):\n      # Define the new run directory\n        \n        epoch_dir = os.path.join(run_dir, f\"epoch {epoch:02}\")\n        # print(\"\\n\\tpassed into trainloss\",run_dir)\n        trainloss = train(epoch,True, run_dir = epoch_dir, img_idx = img_idx)\n        print(\"saved epoch\")\n        # Compress the directory into a zip file, overwriting if it already exists\n        shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n        print(\"Click here to download run  : \")\n        display(FileLink(zip_filename))\n    \n    else:\n        trainloss = train(epoch,False)\n\n\n\n#     if(epoch%n_param!=0 or epoch==0):\n#         data_save.append(saved_data)\n#     else:\n#         data_save.append(saved_data)\n#         main_list.append(data_save)\n#         data_save=list()\n    val_loss, acc = test(epoch)\n\n    scheduler.step() # step cosine scheduling\n\n    list_loss.append(val_loss)\n    list_acc.append(acc)\n\n    # Log training..\n    if usewandb:\n        wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n        \"epoch_time\": time.time()-start})\n\n    # Write out csv..\n    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n        writer = csv.writer(f, lineterminator='\\n')\n        writer.writerow(list_loss)\n        writer.writerow(list_acc)\n#     print(list_loss)\n    print()\n    \n# writeout wandb\nif usewandb:\n    wandb.save(\"wandb_{}.h5\".format(args.net))\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":636},"id":"O1brRsc3SxqH","outputId":"062f1e66-7ad7-49f8-fb09-27f797a6909c","execution":{"iopub.status.busy":"2024-08-23T03:09:36.964152Z","iopub.execute_input":"2024-08-23T03:09:36.964558Z","iopub.status.idle":"2024-08-23T04:01:38.887321Z","shell.execute_reply.started":"2024-08-23T03:09:36.964519Z","shell.execute_reply":"2024-08-23T04:01:38.886144Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"Run number  7\nchosen images are of batch 0 and numbers :  [11, 12, 17, 19, 23, 44, 56, 97, 99, 103, 147, 152, 154, 162, 183, 187, 197, 202, 212, 230, 241, 251, 256, 267, 274, 277, 311, 313, 314, 317, 320, 332, 343, 367, 371, 393, 394, 408, 410, 417, 422, 430, 437, 445, 459, 469, 479, 480, 490, 506]\nSaving every 10 epochs \nTraining started\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/90 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"saved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:   1%|          | 1/90 [00:39<58:16, 39.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1, lr: 0.0005000, val loss: 161.45557, acc: 41.94000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▏         | 2/90 [01:09<49:48, 33.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2, lr: 0.0005000, val loss: 150.88297, acc: 44.89000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 3/90 [01:39<46:28, 32.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3, lr: 0.0005000, val loss: 136.06395, acc: 50.32000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▍         | 4/90 [02:08<44:35, 31.11s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 4, lr: 0.0005000, val loss: 130.18875, acc: 53.01000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▌         | 5/90 [02:38<43:23, 30.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 5, lr: 0.0004999, val loss: 125.29897, acc: 55.17000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   7%|▋         | 6/90 [03:08<42:30, 30.36s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 6, lr: 0.0004999, val loss: 117.74250, acc: 57.21000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 7/90 [03:38<41:43, 30.16s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 7, lr: 0.0004998, val loss: 117.32786, acc: 58.32000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   9%|▉         | 8/90 [04:08<41:02, 30.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 8, lr: 0.0004998, val loss: 115.41125, acc: 58.96000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 9/90 [04:37<40:26, 29.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 9, lr: 0.0004997, val loss: 108.95495, acc: 61.55000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  11%|█         | 10/90 [05:24<46:59, 35.25s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10, lr: 0.0004996, val loss: 105.39031, acc: 62.43000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▏        | 11/90 [05:55<44:25, 33.74s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 11, lr: 0.0004995, val loss: 102.83137, acc: 63.19000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  13%|█▎        | 12/90 [06:25<42:20, 32.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 12, lr: 0.0004994, val loss: 99.40059, acc: 64.27000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▍        | 13/90 [06:54<40:38, 31.67s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 13, lr: 0.0004993, val loss: 100.67912, acc: 63.98000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▌        | 14/90 [07:24<39:26, 31.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 14, lr: 0.0004992, val loss: 95.82338, acc: 65.62000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  17%|█▋        | 15/90 [07:54<38:27, 30.77s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15, lr: 0.0004990, val loss: 95.85497, acc: 66.08000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 16/90 [08:24<37:36, 30.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 16, lr: 0.0004989, val loss: 93.15425, acc: 66.94000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  19%|█▉        | 17/90 [08:54<36:53, 30.32s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 17, lr: 0.0004987, val loss: 92.02762, acc: 67.11000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|██        | 18/90 [09:24<36:13, 30.18s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 18, lr: 0.0004986, val loss: 90.25629, acc: 67.94000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██        | 19/90 [09:54<35:38, 30.12s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 19, lr: 0.0004984, val loss: 88.20175, acc: 69.29000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  22%|██▏       | 20/90 [10:49<43:48, 37.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20, lr: 0.0004982, val loss: 84.39274, acc: 69.86000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  23%|██▎       | 21/90 [11:19<40:36, 35.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 21, lr: 0.0004980, val loss: 82.16359, acc: 70.66000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  24%|██▍       | 22/90 [11:49<38:09, 33.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 22, lr: 0.0004978, val loss: 83.45730, acc: 70.65000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  26%|██▌       | 23/90 [12:19<36:23, 32.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 23, lr: 0.0004976, val loss: 77.37180, acc: 72.39000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  27%|██▋       | 24/90 [12:49<35:06, 31.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 24, lr: 0.0004974, val loss: 79.79322, acc: 72.25000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|██▊       | 25/90 [13:19<33:55, 31.32s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 25, lr: 0.0004972, val loss: 76.89740, acc: 72.39000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 26/90 [13:49<32:55, 30.86s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 26, lr: 0.0004969, val loss: 76.23590, acc: 73.01000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|███       | 27/90 [14:18<32:03, 30.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 27, lr: 0.0004967, val loss: 71.75855, acc: 74.26000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  31%|███       | 28/90 [14:48<31:19, 30.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 28, lr: 0.0004964, val loss: 72.44552, acc: 74.57000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 29/90 [15:18<30:38, 30.15s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 29, lr: 0.0004961, val loss: 72.29670, acc: 74.55000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  33%|███▎      | 30/90 [16:20<39:44, 39.74s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 30, lr: 0.0004959, val loss: 69.48505, acc: 75.24000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|███▍      | 31/90 [16:50<36:18, 36.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 31, lr: 0.0004956, val loss: 71.22585, acc: 74.50000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  36%|███▌      | 32/90 [17:20<33:40, 34.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 32, lr: 0.0004953, val loss: 68.30499, acc: 75.94000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  37%|███▋      | 33/90 [17:50<31:36, 33.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 33, lr: 0.0004950, val loss: 65.55686, acc: 76.99000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  38%|███▊      | 34/90 [18:20<30:04, 32.23s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 34, lr: 0.0004946, val loss: 67.70130, acc: 76.12000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  39%|███▉      | 35/90 [18:50<28:51, 31.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 35, lr: 0.0004943, val loss: 65.08933, acc: 77.50000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|████      | 36/90 [19:19<27:53, 30.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 36, lr: 0.0004940, val loss: 65.68675, acc: 77.44000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  41%|████      | 37/90 [19:49<27:03, 30.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 37, lr: 0.0004936, val loss: 64.47322, acc: 77.25000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  42%|████▏     | 38/90 [20:19<26:20, 30.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 38, lr: 0.0004933, val loss: 63.30965, acc: 78.27000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 39/90 [20:49<25:44, 30.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 39, lr: 0.0004929, val loss: 61.47676, acc: 78.34000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  44%|████▍     | 40/90 [22:00<35:23, 42.47s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 40, lr: 0.0004925, val loss: 59.79138, acc: 78.97000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  46%|████▌     | 41/90 [22:30<31:40, 38.79s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 41, lr: 0.0004921, val loss: 62.56235, acc: 77.96000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  47%|████▋     | 42/90 [23:00<28:53, 36.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 42, lr: 0.0004918, val loss: 61.18800, acc: 78.36000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  48%|████▊     | 43/90 [23:30<26:44, 34.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 43, lr: 0.0004913, val loss: 58.46163, acc: 79.74000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  49%|████▉     | 44/90 [23:59<25:10, 32.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 44, lr: 0.0004909, val loss: 59.28314, acc: 79.41000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  50%|█████     | 45/90 [24:29<23:56, 31.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 45, lr: 0.0004905, val loss: 55.91828, acc: 80.55000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  51%|█████     | 46/90 [24:59<22:57, 31.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 46, lr: 0.0004901, val loss: 55.76783, acc: 80.30000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  52%|█████▏    | 47/90 [25:29<22:10, 30.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 47, lr: 0.0004896, val loss: 56.68991, acc: 80.28000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 48/90 [25:59<21:26, 30.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 48, lr: 0.0004892, val loss: 56.62746, acc: 80.50000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  54%|█████▍    | 49/90 [26:29<20:47, 30.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 49, lr: 0.0004887, val loss: 58.80830, acc: 79.39000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  56%|█████▌    | 50/90 [27:47<29:43, 44.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 50, lr: 0.0004882, val loss: 56.37315, acc: 80.37000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  57%|█████▋    | 51/90 [28:17<26:07, 40.20s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 51, lr: 0.0004878, val loss: 52.76902, acc: 81.36000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  58%|█████▊    | 52/90 [28:47<23:31, 37.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 52, lr: 0.0004873, val loss: 53.09667, acc: 81.60000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  59%|█████▉    | 53/90 [29:16<21:31, 34.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 53, lr: 0.0004868, val loss: 52.03132, acc: 81.81000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|██████    | 54/90 [29:46<20:00, 33.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 54, lr: 0.0004863, val loss: 52.79682, acc: 81.56000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  61%|██████    | 55/90 [30:16<18:47, 32.23s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 55, lr: 0.0004857, val loss: 52.41723, acc: 82.00000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  62%|██████▏   | 56/90 [30:46<17:53, 31.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 56, lr: 0.0004852, val loss: 52.56272, acc: 82.04000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  63%|██████▎   | 57/90 [31:16<17:06, 31.12s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 57, lr: 0.0004847, val loss: 51.10339, acc: 82.27000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 58/90 [31:45<16:22, 30.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 58, lr: 0.0004841, val loss: 53.71999, acc: 81.56000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  66%|██████▌   | 59/90 [32:15<15:42, 30.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 59, lr: 0.0004836, val loss: 49.16701, acc: 82.67000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  67%|██████▋   | 60/90 [33:40<23:24, 46.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 60, lr: 0.0004830, val loss: 50.26346, acc: 82.86000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  68%|██████▊   | 61/90 [34:10<20:11, 41.77s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 61, lr: 0.0004824, val loss: 49.38930, acc: 83.39000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  69%|██████▉   | 62/90 [34:40<17:49, 38.20s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 62, lr: 0.0004819, val loss: 47.34471, acc: 83.73000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|███████   | 63/90 [35:10<16:00, 35.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 63, lr: 0.0004813, val loss: 46.48988, acc: 83.70000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  71%|███████   | 64/90 [35:39<14:39, 33.82s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 64, lr: 0.0004807, val loss: 48.42068, acc: 84.02000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  72%|███████▏  | 65/90 [36:09<13:34, 32.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 65, lr: 0.0004801, val loss: 46.12020, acc: 84.13000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  73%|███████▎  | 66/90 [36:39<12:40, 31.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 66, lr: 0.0004794, val loss: 45.72937, acc: 84.10000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  74%|███████▍  | 67/90 [37:08<11:54, 31.08s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 67, lr: 0.0004788, val loss: 45.97971, acc: 84.29000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  76%|███████▌  | 68/90 [37:38<11:14, 30.67s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 68, lr: 0.0004782, val loss: 45.75011, acc: 84.22000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  77%|███████▋  | 69/90 [38:08<10:39, 30.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 69, lr: 0.0004775, val loss: 46.08802, acc: 83.97000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  78%|███████▊  | 70/90 [39:40<16:17, 48.85s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 70, lr: 0.0004769, val loss: 46.61062, acc: 83.97000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  79%|███████▉  | 71/90 [40:10<13:41, 43.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 71, lr: 0.0004762, val loss: 45.16851, acc: 83.93000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  80%|████████  | 72/90 [40:39<11:45, 39.18s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 72, lr: 0.0004755, val loss: 44.51863, acc: 84.24000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  81%|████████  | 73/90 [41:09<10:17, 36.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 73, lr: 0.0004749, val loss: 43.64628, acc: 84.86000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 74/90 [41:39<09:09, 34.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 74, lr: 0.0004742, val loss: 44.73753, acc: 84.72000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  83%|████████▎ | 75/90 [42:09<08:14, 32.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 75, lr: 0.0004735, val loss: 43.05094, acc: 85.19000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  84%|████████▍ | 76/90 [42:38<07:27, 31.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 76, lr: 0.0004728, val loss: 43.42883, acc: 84.96000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  86%|████████▌ | 77/90 [43:08<06:46, 31.26s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 77, lr: 0.0004720, val loss: 43.67812, acc: 85.09000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  87%|████████▋ | 78/90 [43:38<06:09, 30.78s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 78, lr: 0.0004713, val loss: 43.36342, acc: 84.95000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|████████▊ | 79/90 [44:07<05:34, 30.44s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 79, lr: 0.0004706, val loss: 42.98672, acc: 85.12000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training:  89%|████████▉ | 80/90 [45:47<08:31, 51.15s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 80, lr: 0.0004698, val loss: 40.60809, acc: 85.87000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  90%|█████████ | 81/90 [46:17<06:43, 44.80s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 81, lr: 0.0004691, val loss: 42.47739, acc: 85.12000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  91%|█████████ | 82/90 [46:46<05:22, 40.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 82, lr: 0.0004683, val loss: 41.10129, acc: 85.98000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  92%|█████████▏| 83/90 [47:16<04:19, 37.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 83, lr: 0.0004675, val loss: 39.57435, acc: 86.27000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  93%|█████████▎| 84/90 [47:46<03:29, 34.85s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 84, lr: 0.0004668, val loss: 41.62044, acc: 85.61000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  94%|█████████▍| 85/90 [48:15<02:46, 33.24s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 85, lr: 0.0004660, val loss: 40.01507, acc: 86.49000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 86/90 [48:45<02:08, 32.16s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 86, lr: 0.0004652, val loss: 40.38014, acc: 86.29000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  97%|█████████▋| 87/90 [49:14<01:34, 31.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 87, lr: 0.0004644, val loss: 40.06103, acc: 86.60000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  98%|█████████▊| 88/90 [49:44<01:01, 30.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 88, lr: 0.0004636, val loss: 40.01941, acc: 86.46000\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  99%|█████████▉| 89/90 [50:14<00:30, 30.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 89, lr: 0.0004627, val loss: 40.54781, acc: 86.67000\n\nsaved epoch\nClick here to download run  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/results/runs/run 07.zip","text/html":"<a href='results/runs/run 07.zip' target='_blank'>results/runs/run 07.zip</a><br>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 90/90 [52:01<00:00, 34.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 90, lr: 0.0004619, val loss: 40.15518, acc: 86.35000\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf results\n# !rm -rf log","metadata":{"execution":{"iopub.status.busy":"2024-08-23T03:09:33.717436Z","iopub.execute_input":"2024-08-23T03:09:33.717799Z","iopub.status.idle":"2024-08-23T03:09:35.816374Z","shell.execute_reply.started":"2024-08-23T03:09:33.717766Z","shell.execute_reply":"2024-08-23T03:09:35.815050Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Specify the file name\nfilename = base_dir + '/run 07.zip'\n\n# Get the file size\nfile_size_bytes = os.path.getsize(filename)\n\n# Convert to megabytes (MB) for readability\nfile_size_mb = file_size_bytes / (1024 * 1024)\n\nprint(f\"Size of '{filename}': {file_size_bytes} bytes ({file_size_mb:.2f} MB)\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T04:12:10.683406Z","iopub.execute_input":"2024-08-23T04:12:10.684033Z","iopub.status.idle":"2024-08-23T04:12:10.690080Z","shell.execute_reply.started":"2024-08-23T04:12:10.683991Z","shell.execute_reply":"2024-08-23T04:12:10.689202Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"Size of 'results/runs/run 07.zip': 1295205889 bytes (1235.20 MB)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T04:12:06.166976Z","iopub.execute_input":"2024-08-23T04:12:06.167875Z","iopub.status.idle":"2024-08-23T04:12:06.173540Z","shell.execute_reply.started":"2024-08-23T04:12:06.167830Z","shell.execute_reply":"2024-08-23T04:12:06.172614Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"'results/runs'"},"metadata":{}}]},{"cell_type":"code","source":"# img_idx.detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T03:05:53.030763Z","iopub.execute_input":"2024-08-23T03:05:53.031136Z","iopub.status.idle":"2024-08-23T03:05:53.035272Z","shell.execute_reply.started":"2024-08-23T03:05:53.031098Z","shell.execute_reply":"2024-08-23T03:05:53.034327Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Specify the directory you want to compress\ndirectory_name = 'log'\nzip_filename = 'log.zip'\n\n# Compress the directory into a zip file, overwriting if it already exists\nshutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n# Optionally generate and display a download link\nprint(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\nFileLink(zip_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T04:04:10.335509Z","iopub.execute_input":"2024-08-23T04:04:10.336282Z","iopub.status.idle":"2024-08-23T04:04:10.347276Z","shell.execute_reply.started":"2024-08-23T04:04:10.336234Z","shell.execute_reply":"2024-08-23T04:04:10.346367Z"},"trusted":true},"execution_count":153,"outputs":[{"name":"stdout","text":"Directory 'log' has been zipped as 'log.zip'.\n","output_type":"stream"},{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/log.zip","text/html":"<a href='log.zip' target='_blank'>log.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"e1RV3ub4bzaF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnet","metadata":{"id":"n5yDPk01T0oL","execution":{"iopub.status.busy":"2024-08-23T02:51:33.035456Z","iopub.status.idle":"2024-08-23T02:51:33.035820Z","shell.execute_reply.started":"2024-08-23T02:51:33.035643Z","shell.execute_reply":"2024-08-23T02:51:33.035662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n/content/results/runs/run 04/epoch 00/batch 0/layer 01","metadata":{"id":"c61Jvkt9v1cj","execution":{"iopub.status.busy":"2024-08-23T02:51:33.037464Z","iopub.status.idle":"2024-08-23T02:51:33.037803Z","shell.execute_reply.started":"2024-08-23T02:51:33.037631Z","shell.execute_reply":"2024-08-23T02:51:33.037649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9sDNpPTSxqI","outputId":"802a6209-4de8-4ac2-e0c7-37c20468a8bb","execution":{"iopub.status.busy":"2024-08-23T02:51:33.039157Z","iopub.status.idle":"2024-08-23T02:51:33.039579Z","shell.execute_reply.started":"2024-08-23T02:51:33.039326Z","shell.execute_reply":"2024-08-23T02:51:33.039343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:51:33.040632Z","iopub.status.idle":"2024-08-23T02:51:33.041047Z","shell.execute_reply.started":"2024-08-23T02:51:33.040843Z","shell.execute_reply":"2024-08-23T02:51:33.040863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Define the directory path you want to check\ndirectory_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/'\n\n# Check if the directory exists\nif os.path.isdir(directory_path):\n    print(f\"The directory '{directory_path}' exists.\")\nelse:\n    print(f\"The directory '{directory_path}' does not exist.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq9FNrXywIbb","outputId":"db92a1f9-34a2-49a1-8f61-f9e0750ec05d","execution":{"iopub.status.busy":"2024-08-23T02:51:33.042832Z","iopub.status.idle":"2024-08-23T02:51:33.043159Z","shell.execute_reply.started":"2024-08-23T02:51:33.042995Z","shell.execute_reply":"2024-08-23T02:51:33.043012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/01_attention_out.npy'\n\n# Load the NumPy array from the file\ndata = np.load(file_path)","metadata":{"id":"d2GSp2wbSxqI","execution":{"iopub.status.busy":"2024-08-23T02:51:33.044064Z","iopub.status.idle":"2024-08-23T02:51:33.044441Z","shell.execute_reply.started":"2024-08-23T02:51:33.044237Z","shell.execute_reply":"2024-08-23T02:51:33.044255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlFIzQIUSxqI","outputId":"5dce6a00-7620-4944-8d0d-6ccaa42668e6","execution":{"iopub.status.busy":"2024-08-23T02:51:33.045910Z","iopub.status.idle":"2024-08-23T02:51:33.046264Z","shell.execute_reply.started":"2024-08-23T02:51:33.046084Z","shell.execute_reply":"2024-08-23T02:51:33.046102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.shape\n# shape : batch x head x X x Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr5wj-at0UJo","outputId":"874907d1-f72d-45f6-f805-8623093c5a0b","execution":{"iopub.status.busy":"2024-08-23T02:51:33.047665Z","iopub.status.idle":"2024-08-23T02:51:33.048040Z","shell.execute_reply.started":"2024-08-23T02:51:33.047839Z","shell.execute_reply":"2024-08-23T02:51:33.047857Z"},"trusted":true},"execution_count":null,"outputs":[]}]}