{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:24.804408Z",
          "iopub.status.busy": "2024-08-22T14:40:24.803773Z",
          "iopub.status.idle": "2024-08-22T14:40:24.811221Z",
          "shell.execute_reply": "2024-08-22T14:40:24.810091Z",
          "shell.execute_reply.started": "2024-08-22T14:40:24.804368Z"
        },
        "trusted": true,
        "id": "Llt_Ire4Sxp2"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "'''\n",
        "\n",
        "Train CIFAR10 with PyTorch and Vision Transformers!\n",
        "written by @kentaroy47, @arutema47\n",
        "source : https://github.com/kentaroy47/vision-transformers-cifar10\n",
        "\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true,
        "id": "MmxrO8v6Sxp5"
      },
      "outputs": [],
      "source": [
        "run_number = 1\n",
        "base_dir = \"results/runs\"\n",
        "\n",
        "# Define the new run directory\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "os.makedirs(\"results/runs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROEAX6L0Wf7D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O9k1NsUWISs",
        "outputId": "6b67a80e-f9d1-43af-ebf4-3088aa41efd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79159cb48490>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:24.814816Z",
          "iopub.status.busy": "2024-08-22T14:40:24.814549Z",
          "iopub.status.idle": "2024-08-22T14:40:24.824571Z",
          "shell.execute_reply": "2024-08-22T14:40:24.823766Z",
          "shell.execute_reply.started": "2024-08-22T14:40:24.814793Z"
        },
        "trusted": true,
        "id": "aa7zHkXPSxp5"
      },
      "outputs": [],
      "source": [
        "# # setup for a read only personal access token\n",
        "# # note : token expires 19 aug 2025\n",
        "# token = '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'\n",
        "# token_user = 'Asterisk07'\n",
        "# repo_host = 'Asterisk07'\n",
        "# repo_name = 'BTP-Transformer-explainability'\n",
        "\n",
        "# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n",
        "# !git clone {url}\n",
        "\n",
        "# !mv {repo_name}/models .\n",
        "# !rm -rf BTP-Transformer-explainability # delete a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:24.826271Z",
          "iopub.status.busy": "2024-08-22T14:40:24.826009Z",
          "iopub.status.idle": "2024-08-22T14:40:24.838061Z",
          "shell.execute_reply": "2024-08-22T14:40:24.837223Z",
          "shell.execute_reply.started": "2024-08-22T14:40:24.826250Z"
        },
        "trusted": true,
        "id": "JfB6PgwoSxp6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:24.839538Z",
          "iopub.status.busy": "2024-08-22T14:40:24.839211Z",
          "iopub.status.idle": "2024-08-22T14:40:30.687109Z",
          "shell.execute_reply": "2024-08-22T14:40:30.686143Z",
          "shell.execute_reply.started": "2024-08-22T14:40:24.839505Z"
        },
        "trusted": true,
        "id": "YF9tLt1iSxp6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:30.689124Z",
          "iopub.status.busy": "2024-08-22T14:40:30.688719Z",
          "iopub.status.idle": "2024-08-22T14:40:31.697333Z",
          "shell.execute_reply": "2024-08-22T14:40:31.696013Z",
          "shell.execute_reply.started": "2024-08-22T14:40:30.689083Z"
        },
        "trusted": true,
        "id": "eQR0IlVsSxp7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:31.701618Z",
          "iopub.status.busy": "2024-08-22T14:40:31.701196Z",
          "iopub.status.idle": "2024-08-22T14:40:32.701938Z",
          "shell.execute_reply": "2024-08-22T14:40:32.700792Z",
          "shell.execute_reply.started": "2024-08-22T14:40:31.701588Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fnxx0KDSxp7",
        "outputId": "c0015607-859a-4164-db22-8783ff70f8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:32.703622Z",
          "iopub.status.busy": "2024-08-22T14:40:32.703293Z",
          "iopub.status.idle": "2024-08-22T14:40:33.747855Z",
          "shell.execute_reply": "2024-08-22T14:40:33.746596Z",
          "shell.execute_reply.started": "2024-08-22T14:40:32.703593Z"
        },
        "trusted": true,
        "id": "rO-x5w5QSxp8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:33.749804Z",
          "iopub.status.busy": "2024-08-22T14:40:33.749419Z",
          "iopub.status.idle": "2024-08-22T14:40:33.754948Z",
          "shell.execute_reply": "2024-08-22T14:40:33.753789Z",
          "shell.execute_reply.started": "2024-08-22T14:40:33.749765Z"
        },
        "trusted": true,
        "id": "aDRb-t5HSxp9"
      },
      "outputs": [],
      "source": [
        "# !rm -rf models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:33.756986Z",
          "iopub.status.busy": "2024-08-22T14:40:33.756673Z",
          "iopub.status.idle": "2024-08-22T14:40:35.485712Z",
          "shell.execute_reply": "2024-08-22T14:40:35.484717Z",
          "shell.execute_reply.started": "2024-08-22T14:40:33.756956Z"
        },
        "trusted": true,
        "id": "nyZGC9wISxp9"
      },
      "outputs": [],
      "source": [
        "# !npm install -g github-files-fetcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:35.487305Z",
          "iopub.status.busy": "2024-08-22T14:40:35.487004Z",
          "iopub.status.idle": "2024-08-22T14:40:35.491760Z",
          "shell.execute_reply": "2024-08-22T14:40:35.490758Z",
          "shell.execute_reply.started": "2024-08-22T14:40:35.487277Z"
        },
        "trusted": true,
        "id": "XLQdzmZYSxp9"
      },
      "outputs": [],
      "source": [
        "# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n",
        "# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:35.493305Z",
          "iopub.status.busy": "2024-08-22T14:40:35.492990Z",
          "iopub.status.idle": "2024-08-22T14:40:35.507212Z",
          "shell.execute_reply": "2024-08-22T14:40:35.506391Z",
          "shell.execute_reply.started": "2024-08-22T14:40:35.493281Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZPrL29xSxp9",
        "outputId": "0cab9daf-2631-4d8f-ee64-1d51ccbdf40e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true,
        "id": "u0zItmyxSxp-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Check if 'utils.py' exists in the current directory\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"utils.py exists in the current directory.\")\n",
        "else:\n",
        "    print(\"utils.py does not exist in the current directory.\")\n",
        "    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n",
        "    print(\"utils.py fetched\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSnJhbUCU4J9",
        "outputId": "d466bf62-4b25-4a9b-d2f7-83213799ad8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utils.py does not exist in the current directory.\n",
            "--2024-08-22 20:11:39--  https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3501 (3.4K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   3.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-22 20:11:39 (68.6 MB/s) - ‘utils.py’ saved [3501/3501]\n",
            "\n",
            "utils.py fetched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:35.508722Z",
          "iopub.status.busy": "2024-08-22T14:40:35.508374Z",
          "iopub.status.idle": "2024-08-22T14:40:36.571976Z",
          "shell.execute_reply": "2024-08-22T14:40:36.570684Z",
          "shell.execute_reply.started": "2024-08-22T14:40:35.508693Z"
        },
        "trusted": true,
        "id": "5XLsXJxiSxp-"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:36.574231Z",
          "iopub.status.busy": "2024-08-22T14:40:36.573437Z",
          "iopub.status.idle": "2024-08-22T14:40:36.579792Z",
          "shell.execute_reply": "2024-08-22T14:40:36.578714Z",
          "shell.execute_reply.started": "2024-08-22T14:40:36.574192Z"
        },
        "trusted": true,
        "id": "Pe1-pReSSxp-"
      },
      "outputs": [],
      "source": [
        "from utils import progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:36.581356Z",
          "iopub.status.busy": "2024-08-22T14:40:36.581025Z",
          "iopub.status.idle": "2024-08-22T14:40:36.595093Z",
          "shell.execute_reply": "2024-08-22T14:40:36.594090Z",
          "shell.execute_reply.started": "2024-08-22T14:40:36.581325Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "_yVbM9QmSxp-",
        "outputId": "2ebfb3d7-3459-40ed-c8a1-33e3839da492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function utils.progress_bar(current, total, msg=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>utils.progress_bar</b><br/>def progress_bar(current, total, msg=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/utils.py</a>&lt;no docstring&gt;</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 56);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "trusted": true,
        "id": "mlKjovnlSxp-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:36.601950Z",
          "iopub.status.busy": "2024-08-22T14:40:36.601469Z",
          "iopub.status.idle": "2024-08-22T14:40:36.606277Z",
          "shell.execute_reply": "2024-08-22T14:40:36.605412Z",
          "shell.execute_reply.started": "2024-08-22T14:40:36.601919Z"
        },
        "trusted": true,
        "id": "RGLFDHKiSxp_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from randomaug import RandAugment\n",
        "from torchvision.transforms import RandAugment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:36.608061Z",
          "iopub.status.busy": "2024-08-22T14:40:36.607556Z",
          "iopub.status.idle": "2024-08-22T14:40:48.763855Z",
          "shell.execute_reply": "2024-08-22T14:40:48.762726Z",
          "shell.execute_reply.started": "2024-08-22T14:40:36.608029Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHHLarISxp_",
        "outputId": "45997e81-9926-4465-d2dd-12835012d6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.765550Z",
          "iopub.status.busy": "2024-08-22T14:40:48.765196Z",
          "iopub.status.idle": "2024-08-22T14:40:48.770775Z",
          "shell.execute_reply": "2024-08-22T14:40:48.769802Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.765517Z"
        },
        "trusted": true,
        "id": "UsC7sE2cSxp_"
      },
      "outputs": [],
      "source": [
        "# from models import *\n",
        "# from models.vit import ViT\n",
        "# from models.convmixer import ConvMixer"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJEMQtO5Upra"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json"
      ],
      "metadata": {
        "id": "VJNDccCQe_XC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "qkv_titles = ['q','k','v']"
      ],
      "metadata": {
        "id": "WADSesO6g1ea"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.772133Z",
          "iopub.status.busy": "2024-08-22T14:40:48.771888Z",
          "iopub.status.idle": "2024-08-22T14:40:48.787792Z",
          "shell.execute_reply": "2024-08-22T14:40:48.786809Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.772113Z"
        },
        "trusted": true,
        "id": "OzQdLRddSxp_"
      },
      "outputs": [],
      "source": [
        "# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n",
        "# VIT.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "import numpy as np\n",
        "# helpers\n",
        "\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "# classes\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x , save_flag = False):\n",
        "        out =  self.net(x)\n",
        "        if(save_flag==True):\n",
        "                file_path = os.path.join(run_dir, '02_mlp_out.npy')\n",
        "                # np.save(file_path, out)\n",
        "                np.save(file_path, out.detach().cpu().numpy())\n",
        "        return out\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "\n",
        "        inner_dim = dim_head *  heads\n",
        "        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim = -1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x,save_flag=False, run_dir = None):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
        "\n",
        "\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        if(save_flag==True):\n",
        "\n",
        "                # Convert each tensor in `qkv` to a numpy array and save it\n",
        "#                 qkv=attention.to_qkv\n",
        "                for i, tensor in enumerate((q,k,v)):\n",
        "                    np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n",
        "                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n",
        "                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n",
        "                    np.save(file_path, np_array)\n",
        "                file_path = os.path.join(run_dir, '01_attention_out.npy')\n",
        "                np.save(file_path, out.detach().cpu().numpy())\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        # return self.to_out(out),q,k,v\n",
        "        return self.to_out(out)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n",
        "        # self.saved_values = list()  # To store th\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x,save_flag=False, run_dir = None):\n",
        "        for i, (attn, ff) in enumerate(self.layers):\n",
        "            # Unpack the output from the Attention layer\n",
        "            #\n",
        "            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n",
        "            if save_flag:\n",
        "              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n",
        "              os.makedirs(layer_dir, exist_ok=True)\n",
        "              # print(\"passed trans layer direcetory \", layer_dir)\n",
        "            else:\n",
        "              layer_dir = None\n",
        "            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir)\n",
        "\n",
        "\n",
        "\n",
        "            # Save the query, key, value, and logits (output) for this layer\n",
        "            # self.saved_values.append(q.cpu().detach().numpy())\n",
        "            # self.saved_values.append(k.cpu().detach().numpy())\n",
        "            # self.saved_values.append(v.cpu().detach().numpy())\n",
        "\n",
        "            # Combine the attention output with the original x\n",
        "            x = attn_out + x\n",
        "            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n",
        "            # print(\"i : \",i)\n",
        "            # Apply the feedforward network\n",
        "            x = ff(x) + x\n",
        "\n",
        "            # x = ff(x,save_flag=save_flag, run_dir = layer_dir) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "\n",
        "        print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n",
        "\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, save_flag=False, run_dir = None):\n",
        "        # if (save_flag):\n",
        "          # print(\"\\n\\treached here 3\")\n",
        "        x = self.to_patch_embedding(img)\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x,save_flag, run_dir)\n",
        "#         if(save_flag==True):\n",
        "#                 # Convert each tensor in `qkv` to a numpy array and save it\n",
        "#                 qkv=attention.to_qkv\n",
        "#                 for i, tensor in enumerate(qkv):\n",
        "#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n",
        "#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n",
        "\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        return self.mlp_head(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RskDA5B5zDv6",
        "outputId": "85715f3b-73f8-4996-e0e8-b43df9b8dc08"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'512'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.789612Z",
          "iopub.status.busy": "2024-08-22T14:40:48.788968Z",
          "iopub.status.idle": "2024-08-22T14:40:48.801274Z",
          "shell.execute_reply": "2024-08-22T14:40:48.800396Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.789587Z"
        },
        "trusted": true,
        "id": "GVdr58MRSxp_"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import sys\n",
        "\n",
        "# Define your arguments here\n",
        "def parse_args():\n",
        "    # parsers\n",
        "    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n",
        "    parser.add_argument('--opt', default=\"adam\")\n",
        "    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
        "    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n",
        "    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n",
        "    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n",
        "    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n",
        "    parser.add_argument('--net', default='vit')\n",
        "    parser.add_argument('--dp', action='store_true', help='use data parallel')\n",
        "    parser.add_argument('--bs', default='512')\n",
        "    parser.add_argument('--size', default=\"32\")\n",
        "    parser.add_argument('--n_epochs', type=int, default='200')\n",
        "    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n",
        "    parser.add_argument('--dimhead', default=\"512\", type=int)\n",
        "    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.803202Z",
          "iopub.status.busy": "2024-08-22T14:40:48.802427Z",
          "iopub.status.idle": "2024-08-22T14:40:48.817022Z",
          "shell.execute_reply": "2024-08-22T14:40:48.816052Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.803177Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JbxSOG5SxqA",
        "outputId": "2c280127-8d9e-4cd0-fc27-3bc03c51d0f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\n",
        "command.split()[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.818572Z",
          "iopub.status.busy": "2024-08-22T14:40:48.818273Z",
          "iopub.status.idle": "2024-08-22T14:40:48.827586Z",
          "shell.execute_reply": "2024-08-22T14:40:48.826823Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.818549Z"
        },
        "trusted": true,
        "id": "SFLk9RG5SxqA"
      },
      "outputs": [],
      "source": [
        "# Simulate command-line arguments\n",
        "# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\n",
        "sys.argv = command.split()[1:]\n",
        "\n",
        "args = parse_args()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.828897Z",
          "iopub.status.busy": "2024-08-22T14:40:48.828620Z",
          "iopub.status.idle": "2024-08-22T14:40:48.837934Z",
          "shell.execute_reply": "2024-08-22T14:40:48.837039Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.828874Z"
        },
        "trusted": true,
        "id": "TZfQJlNKSxqA"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "trusted": true,
        "id": "ZRdesLOdSxqA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.839182Z",
          "iopub.status.busy": "2024-08-22T14:40:48.838899Z",
          "iopub.status.idle": "2024-08-22T14:40:48.848708Z",
          "shell.execute_reply": "2024-08-22T14:40:48.847938Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.839160Z"
        },
        "trusted": true,
        "id": "xBdPskigSxqA"
      },
      "outputs": [],
      "source": [
        "# (2.0.1+cu117)\n",
        "# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.849856Z",
          "iopub.status.busy": "2024-08-22T14:40:48.849627Z",
          "iopub.status.idle": "2024-08-22T14:40:48.859359Z",
          "shell.execute_reply": "2024-08-22T14:40:48.858539Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.849837Z"
        },
        "trusted": true,
        "id": "uiDtWCYKSxqA"
      },
      "outputs": [],
      "source": [
        "# !pip show torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "_T0LacFUt74i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.860562Z",
          "iopub.status.busy": "2024-08-22T14:40:48.860291Z",
          "iopub.status.idle": "2024-08-22T14:40:48.869778Z",
          "shell.execute_reply": "2024-08-22T14:40:48.868911Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.860531Z"
        },
        "trusted": true,
        "id": "NRmD_dGiSxqA"
      },
      "outputs": [],
      "source": [
        "# !pip show torch\n",
        "# #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.871085Z",
          "iopub.status.busy": "2024-08-22T14:40:48.870825Z",
          "iopub.status.idle": "2024-08-22T14:40:48.881946Z",
          "shell.execute_reply": "2024-08-22T14:40:48.881027Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.871063Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m-UHnDboSxqA",
        "outputId": "81f73c03-4a0e-490f-e36e-08f56d3b0124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.18.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import torchvision\n",
        "torchvision.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.883313Z",
          "iopub.status.busy": "2024-08-22T14:40:48.883066Z",
          "iopub.status.idle": "2024-08-22T14:40:48.892325Z",
          "shell.execute_reply": "2024-08-22T14:40:48.891423Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.883292Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aQh5PidkSxqA",
        "outputId": "78297830-3ca1-42b2-fa0a-1b761d0e61fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.893709Z",
          "iopub.status.busy": "2024-08-22T14:40:48.893367Z",
          "iopub.status.idle": "2024-08-22T14:40:48.903667Z",
          "shell.execute_reply": "2024-08-22T14:40:48.902806Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.893686Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hedCXexeSxqB",
        "outputId": "247ba528-fb2e-4d69-e300-408eb63d93dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:40:48.905576Z",
          "iopub.status.busy": "2024-08-22T14:40:48.904826Z",
          "iopub.status.idle": "2024-08-22T14:41:10.733761Z",
          "shell.execute_reply": "2024-08-22T14:41:10.732894Z",
          "shell.execute_reply.started": "2024-08-22T14:40:48.905550Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "qnyCPg0HSxqB",
        "outputId": "f6b2c294-26d0-4eaf-aede-2eb3a3c436b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240822_201225-qah5zlvj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/qah5zlvj' target=\"_blank\">vit_lr0.0005</a></strong> to <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/qah5zlvj' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/qah5zlvj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# take in args\n",
        "usewandb = ~args.nowandb\n",
        "if usewandb:\n",
        "    import wandb\n",
        "    watermark = \"{}_lr{}\".format(args.net, args.lr)\n",
        "    wandb.init(project=\"cifar10-challange\",\n",
        "            name=watermark)\n",
        "    wandb.config.update(args)\n",
        "\n",
        "bs = int(args.bs)\n",
        "imsize = int(args.size)\n",
        "\n",
        "use_amp = not args.noamp\n",
        "aug = args.noaug\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "if args.net==\"vit_timm\":\n",
        "    size = 384\n",
        "else:\n",
        "    size = imsize\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.Resize(size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Add RandAugment with N, M(hyperparameter)\n",
        "if aug:\n",
        "    N = 2; M = 14;\n",
        "    transform_train.transforms.insert(0, RandAugment(N, M))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:10.735303Z",
          "iopub.status.busy": "2024-08-22T14:41:10.734974Z",
          "iopub.status.idle": "2024-08-22T14:41:10.740153Z",
          "shell.execute_reply": "2024-08-22T14:41:10.739212Z",
          "shell.execute_reply.started": "2024-08-22T14:41:10.735276Z"
        },
        "trusted": true,
        "id": "V-X21wSpSxqB"
      },
      "outputs": [],
      "source": [
        "# api token = df6973a974ca9221b939763af4285be4583027aa\n",
        "# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:10.741474Z",
          "iopub.status.busy": "2024-08-22T14:41:10.741210Z",
          "iopub.status.idle": "2024-08-22T14:41:12.346162Z",
          "shell.execute_reply": "2024-08-22T14:41:12.345040Z",
          "shell.execute_reply.started": "2024-08-22T14:41:10.741452Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUzFJatHSxqB",
        "outputId": "3a5a3505-936f-4461-b40a-fc75c7fb4f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49302269.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Prepare dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:12.348103Z",
          "iopub.status.busy": "2024-08-22T14:41:12.347691Z",
          "iopub.status.idle": "2024-08-22T14:41:12.356130Z",
          "shell.execute_reply": "2024-08-22T14:41:12.354969Z",
          "shell.execute_reply.started": "2024-08-22T14:41:12.348064Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUqsuNN8SxqB",
        "outputId": "0a2d5706-2adf-45db-d903-f74316ec1faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# For Multi-GPU\n",
        "if 'cuda' in device:\n",
        "    print(device)\n",
        "    if args.dp:\n",
        "        print(\"using data parallel\")\n",
        "        net = torch.nn.DataParallel(net) # make parallel\n",
        "        cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ycedpM59zTyh",
        "outputId": "aa2b13bb-b636-44c7-9b7d-b2f2880470da"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mlp_dim' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a84c070f1601>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mlp_dim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_vit():\n",
        "    return ViT(\n",
        "    image_size = size,\n",
        "    patch_size = args.patch,\n",
        "    num_classes = 10,\n",
        "    dim = int(args.dimhead),\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    # mlp_dim = 512,\n",
        "    mlp_dim = 256,\n",
        "    dropout = 0.1,\n",
        "    emb_dropout = 0.1,\n",
        "    )"
      ],
      "metadata": {
        "id": "ygIfkREcrvX7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:12.358446Z",
          "iopub.status.busy": "2024-08-22T14:41:12.357833Z",
          "iopub.status.idle": "2024-08-22T14:41:12.484272Z",
          "shell.execute_reply": "2024-08-22T14:41:12.483314Z",
          "shell.execute_reply.started": "2024-08-22T14:41:12.358415Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND8qhixnSxqB",
        "outputId": "e6edb544-3753-446e-ae32-03a9ab15df36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model factory..\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "if args.net==\"vit\":\n",
        "    # ViT for cifar10\n",
        "    net = get_vit()\n",
        "\n",
        "\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:12.485637Z",
          "iopub.status.busy": "2024-08-22T14:41:12.485352Z",
          "iopub.status.idle": "2024-08-22T14:41:12.491137Z",
          "shell.execute_reply": "2024-08-22T14:41:12.490225Z",
          "shell.execute_reply.started": "2024-08-22T14:41:12.485614Z"
        },
        "trusted": true,
        "id": "nc4jNV-bSxqC"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8emZ75LWcpgE",
        "outputId": "5423fb4a-63af-4ffb-a027-899ae0d60136"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainloader[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "GCKRyskOugE5",
        "outputId": "32f19894-9636-4bac-b61a-6db4237f6da5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'DataLoader' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-36b5d26c01af>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:12.506664Z",
          "iopub.status.busy": "2024-08-22T14:41:12.506362Z",
          "iopub.status.idle": "2024-08-22T14:41:16.284127Z",
          "shell.execute_reply": "2024-08-22T14:41:16.282427Z",
          "shell.execute_reply.started": "2024-08-22T14:41:12.506641Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "O1brRsc3SxqH",
        "outputId": "062f1e66-7ad7-49f8-fb09-27f797a6909c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vit : dim =  512 | dim_head =  64 | heads =  8  | mlp =  256\n",
            "transformer : dim =  512 | dim_head =  64 | heads =  8\n",
            "Run number  12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "  0%|          | 1/500 [01:08<9:26:46, 68.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 22 20:47:11 2024 Epoch 0, lr: 0.0005000, val loss: 159.10754, acc: 42.84000\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/500 [01:23<11:38:12, 83.95s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-78b0eb2d9120>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mtrainloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_save_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_save_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mtrainloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-78b0eb2d9120>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, save_flag, run_dir, img_save_count)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    349\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    348\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    349\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Loss is CE\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "net = get_vit()\n",
        "\n",
        "if args.opt == \"adam\":\n",
        "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
        "elif args.opt == \"sgd\":\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n",
        "\n",
        "# use cosine scheduling\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n",
        "\n",
        "##### Training\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "def train(epoch,save_flag, run_dir = None, img_save_count = None):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # img_factor = len(trainloader) // img_save_count\n",
        "    # run_dir = os.path.join(run_dir,  {epoch:02}\")\n",
        "\n",
        "    # data_save=list()\n",
        "    # main_list=list()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        # Train with amp\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            # if(save_flag==True and batch_idx%img_factor==0):\n",
        "\n",
        "            if(save_flag==True and batch_idx==0):\n",
        "                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n",
        "                os.makedirs(batch_dir, exist_ok=True)\n",
        "                # np.save(file_path, np_array)\n",
        "                # print(\"\\n\\tpassed \",batch_dir, type(batch_dir))\n",
        "\n",
        "                outputs = net(inputs, True, batch_dir)\n",
        "                # outputs = net(inputs, False, 12)\n",
        "                #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n",
        "            else:\n",
        "                outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # data_save.append(net.transformer.saved_values)\n",
        "\n",
        "#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "#     return train_loss/(batch_idx+1),net.transformer.saved_values\n",
        "    return train_loss/(batch_idx+1)\n",
        "##### Validation\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\"model\": net.state_dict(),\n",
        "              \"optimizer\": optimizer.state_dict(),\n",
        "              \"scaler\": scaler.state_dict()}\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n",
        "        best_acc = acc\n",
        "\n",
        "    os.makedirs(\"log\", exist_ok=True)\n",
        "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n",
        "    print(content)\n",
        "    with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n",
        "        appender.write(content + \"\\n\")\n",
        "    return test_loss, acc\n",
        "\n",
        "list_loss = []\n",
        "list_acc = []\n",
        "\n",
        "if usewandb:\n",
        "    wandb.watch(net)\n",
        "\n",
        "if device == 'cuda':\n",
        "  net.cuda()\n",
        "main_list=list()\n",
        "data_save=list()\n",
        "n_param=5\n",
        "save_epochs = 5 #IMP\n",
        "img_save_count = 50 #IMP\n",
        "\n",
        "run_dir = os.path.join(base_dir, f\"run {run_number:02}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "print(\"Run number \",run_number)\n",
        "run_number += 1\n",
        "\n",
        "save_epochs-=1\n",
        "max_epochs = args.n_epochs\n",
        "epoch_factor = max_epochs  // save_epochs\n",
        "for epoch in tqdm(range(start_epoch, max_epochs )):\n",
        "    start = time.time()\n",
        "    if(epoch%epoch_factor==0 or epoch == max_epochs):\n",
        "      # Define the new run directory\n",
        "        run_dir = os.path.join(run_dir, f\"epoch {epoch:02}\")\n",
        "        # print(\"\\n\\tpassed into trainloss\",run_dir)\n",
        "        trainloss = train(epoch,True, run_dir = run_dir, img_save_count = img_save_count)\n",
        "    else:\n",
        "        trainloss = train(epoch,False)\n",
        "\n",
        "\n",
        "\n",
        "#     if(epoch%n_param!=0 or epoch==0):\n",
        "#         data_save.append(saved_data)\n",
        "#     else:\n",
        "#         data_save.append(saved_data)\n",
        "#         main_list.append(data_save)\n",
        "#         data_save=list()\n",
        "    val_loss, acc = test(epoch)\n",
        "\n",
        "    scheduler.step(epoch-1) # step cosine scheduling\n",
        "\n",
        "    list_loss.append(val_loss)\n",
        "    list_acc.append(acc)\n",
        "\n",
        "    # Log training..\n",
        "    if usewandb:\n",
        "        wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "        \"epoch_time\": time.time()-start})\n",
        "\n",
        "    # Write out csv..\n",
        "    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n",
        "        writer = csv.writer(f, lineterminator='\\n')\n",
        "        writer.writerow(list_loss)\n",
        "        writer.writerow(list_acc)\n",
        "#     print(list_loss)\n",
        "\n",
        "# writeout wandb\n",
        "if usewandb:\n",
        "    wandb.save(\"wandb_{}.h5\".format(args.net))\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_dir"
      ],
      "metadata": {
        "id": "e1RV3ub4bzaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "net"
      ],
      "metadata": {
        "id": "n5yDPk01T0oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "/content/results/runs/run 04/epoch 00/batch 0/layer 01"
      ],
      "metadata": {
        "id": "c61Jvkt9v1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-22T14:41:16.285823Z",
          "iopub.status.idle": "2024-08-22T14:41:16.286680Z",
          "shell.execute_reply": "2024-08-22T14:41:16.286436Z",
          "shell.execute_reply.started": "2024-08-22T14:41:16.286416Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9sDNpPTSxqI",
        "outputId": "802a6209-4de8-4ac2-e0c7-37c20468a8bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint  data  log  __pycache__  results  sample_data  utils.py  wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Define the directory path you want to check\n",
        "directory_path = r'results/runs//run 04/epoch 00/batch 0/layer 01/'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.isdir(directory_path):\n",
        "    print(f\"The directory '{directory_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The directory '{directory_path}' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq9FNrXywIbb",
        "outputId": "db92a1f9-34a2-49a1-8f61-f9e0750ec05d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The directory 'results/runs//run 04/epoch 00/batch 0/layer 01/' exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-22T14:41:37.693363Z",
          "iopub.status.busy": "2024-08-22T14:41:37.692735Z",
          "iopub.status.idle": "2024-08-22T14:41:37.701448Z",
          "shell.execute_reply": "2024-08-22T14:41:37.700451Z",
          "shell.execute_reply.started": "2024-08-22T14:41:37.693324Z"
        },
        "trusted": true,
        "id": "d2GSp2wbSxqI"
      },
      "outputs": [],
      "source": [
        "file_path = r'results/runs/run 10/epoch 00/batch 0/layer 01/q.npy'\n",
        "\n",
        "# Load the NumPy array from the file\n",
        "data = np.load(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlFIzQIUSxqI",
        "outputId": "5dce6a00-7620-4944-8d0d-6ccaa42668e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 65, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data.shape\n",
        "# shape : batch x head x X x Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr5wj-at0UJo",
        "outputId": "874907d1-f72d-45f6-f805-8623093c5a0b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 8, 65, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}