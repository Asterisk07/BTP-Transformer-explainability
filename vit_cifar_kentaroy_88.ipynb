{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n'''\n\nTrain CIFAR10 with PyTorch and Vision Transformers!\nwritten by @kentaroy47, @arutema47\nsource : https://github.com/kentaroy47/vision-transformers-cifar10\n\n'''\n\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport numpy as np\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport pandas as pd\nimport csv\nimport time\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:24.803773Z","iopub.execute_input":"2024-08-22T14:40:24.804408Z","iopub.status.idle":"2024-08-22T14:40:24.811221Z","shell.execute_reply.started":"2024-08-22T14:40:24.804368Z","shell.execute_reply":"2024-08-22T14:40:24.810091Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup for a read only personal access token\n# note : token expires 19 aug 2025\ntoken = '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'\ntoken_user = 'Asterisk07'\nrepo_host = 'Asterisk07'\nrepo_name = 'BTP-Transformer-explainability'\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:24.814549Z","iopub.execute_input":"2024-08-22T14:40:24.814816Z","iopub.status.idle":"2024-08-22T14:40:24.824571Z","shell.execute_reply.started":"2024-08-22T14:40:24.814793Z","shell.execute_reply":"2024-08-22T14:40:24.823766Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\nurl","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:24.826009Z","iopub.execute_input":"2024-08-22T14:40:24.826271Z","iopub.status.idle":"2024-08-22T14:40:24.838061Z","shell.execute_reply.started":"2024-08-22T14:40:24.826250Z","shell.execute_reply":"2024-08-22T14:40:24.837223Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"'https://Asterisk07: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@github.com/Asterisk07/BTP-Transformer-explainability/'"},"metadata":{}}]},{"cell_type":"code","source":"!git clone {url}","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:24.839211Z","iopub.execute_input":"2024-08-22T14:40:24.839538Z","iopub.status.idle":"2024-08-22T14:40:30.687109Z","shell.execute_reply.started":"2024-08-22T14:40:24.839505Z","shell.execute_reply":"2024-08-22T14:40:30.686143Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Cloning into 'BTP-Transformer-explainability'...\nremote: Enumerating objects: 159, done.\u001b[K\nremote: Counting objects: 100% (72/72), done.\u001b[K\nremote: Compressing objects: 100% (56/56), done.\u001b[K\nremote: Total 159 (delta 36), reused 51 (delta 16), pack-reused 87 (from 1)\u001b[K\nReceiving objects: 100% (159/159), 114.99 MiB | 40.94 MiB/s, done.\nResolving deltas: 100% (72/72), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv {repo_name}/models .","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:30.688719Z","iopub.execute_input":"2024-08-22T14:40:30.689124Z","iopub.status.idle":"2024-08-22T14:40:31.697333Z","shell.execute_reply.started":"2024-08-22T14:40:30.689083Z","shell.execute_reply":"2024-08-22T14:40:31.696013Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:31.701196Z","iopub.execute_input":"2024-08-22T14:40:31.701618Z","iopub.status.idle":"2024-08-22T14:40:32.701938Z","shell.execute_reply.started":"2024-08-22T14:40:31.701588Z","shell.execute_reply":"2024-08-22T14:40:32.700792Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"BTP-Transformer-explainability\tdata\tutils.py    wandb\n__pycache__\t\t\tmodels\tutils.py.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf BTP-Transformer-explainability # delete a file","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:32.703293Z","iopub.execute_input":"2024-08-22T14:40:32.703622Z","iopub.status.idle":"2024-08-22T14:40:33.747855Z","shell.execute_reply.started":"2024-08-22T14:40:32.703593Z","shell.execute_reply":"2024-08-22T14:40:33.746596Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# !rm -rf models","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:33.749419Z","iopub.execute_input":"2024-08-22T14:40:33.749804Z","iopub.status.idle":"2024-08-22T14:40:33.754948Z","shell.execute_reply.started":"2024-08-22T14:40:33.749765Z","shell.execute_reply":"2024-08-22T14:40:33.753789Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"!npm install -g github-files-fetcher","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:33.756673Z","iopub.execute_input":"2024-08-22T14:40:33.756986Z","iopub.status.idle":"2024-08-22T14:40:35.485712Z","shell.execute_reply.started":"2024-08-22T14:40:33.756956Z","shell.execute_reply":"2024-08-22T14:40:35.484717Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"\u001b[K\u001b[?25hm##################\u001b[0m] - reify:github-files-fetcher: \u001b[32;40mtiming\u001b[0m \u001b[35mreify:loadBundles\u001b[0m Com\u001b[0m\u001b[Ks\u001b[0m\u001b[K\nchanged 1 package in 344ms\n","output_type":"stream"}]},{"cell_type":"code","source":"# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:35.487004Z","iopub.execute_input":"2024-08-22T14:40:35.487305Z","iopub.status.idle":"2024-08-22T14:40:35.491760Z","shell.execute_reply.started":"2024-08-22T14:40:35.487277Z","shell.execute_reply":"2024-08-22T14:40:35.490758Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:35.492990Z","iopub.execute_input":"2024-08-22T14:40:35.493305Z","iopub.status.idle":"2024-08-22T14:40:35.507212Z","shell.execute_reply.started":"2024-08-22T14:40:35.493281Z","shell.execute_reply":"2024-08-22T14:40:35.506391Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:35.508374Z","iopub.execute_input":"2024-08-22T14:40:35.508722Z","iopub.status.idle":"2024-08-22T14:40:36.571976Z","shell.execute_reply.started":"2024-08-22T14:40:35.508693Z","shell.execute_reply":"2024-08-22T14:40:36.570684Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"--2024-08-22 14:40:36--  https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3501 (3.4K) [text/plain]\nSaving to: 'utils.py.2'\n\nutils.py.2          100%[===================>]   3.42K  --.-KB/s    in 0s      \n\n2024-08-22 14:40:36 (40.5 MB/s) - 'utils.py.2' saved [3501/3501]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from utils import progress_bar","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:36.573437Z","iopub.execute_input":"2024-08-22T14:40:36.574231Z","iopub.status.idle":"2024-08-22T14:40:36.579792Z","shell.execute_reply.started":"2024-08-22T14:40:36.574192Z","shell.execute_reply":"2024-08-22T14:40:36.578714Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"progress_bar","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:36.581025Z","iopub.execute_input":"2024-08-22T14:40:36.581356Z","iopub.status.idle":"2024-08-22T14:40:36.595093Z","shell.execute_reply.started":"2024-08-22T14:40:36.581325Z","shell.execute_reply":"2024-08-22T14:40:36.594090Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"<function utils.progress_bar(current, total, msg=None)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# from randomaug import RandAugment\nfrom torchvision.transforms import RandAugment \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:36.601469Z","iopub.execute_input":"2024-08-22T14:40:36.601950Z","iopub.status.idle":"2024-08-22T14:40:36.606277Z","shell.execute_reply.started":"2024-08-22T14:40:36.601919Z","shell.execute_reply":"2024-08-22T14:40:36.605412Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:36.607556Z","iopub.execute_input":"2024-08-22T14:40:36.608061Z","iopub.status.idle":"2024-08-22T14:40:48.763855Z","shell.execute_reply.started":"2024-08-22T14:40:36.608029Z","shell.execute_reply":"2024-08-22T14:40:48.762726Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.8.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from models import *\nfrom models.vit import ViT\nfrom models.convmixer import ConvMixer","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.765196Z","iopub.execute_input":"2024-08-22T14:40:48.765550Z","iopub.status.idle":"2024-08-22T14:40:48.770775Z","shell.execute_reply.started":"2024-08-22T14:40:48.765517Z","shell.execute_reply":"2024-08-22T14:40:48.769802Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.771888Z","iopub.execute_input":"2024-08-22T14:40:48.772133Z","iopub.status.idle":"2024-08-22T14:40:48.787792Z","shell.execute_reply.started":"2024-08-22T14:40:48.772113Z","shell.execute_reply":"2024-08-22T14:40:48.786809Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Define your arguments here\ndef parse_args():\n    # parsers\n    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n    parser.add_argument('--opt', default=\"adam\")\n    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n    parser.add_argument('--net', default='vit')\n    parser.add_argument('--dp', action='store_true', help='use data parallel')\n    parser.add_argument('--bs', default='512')\n    parser.add_argument('--size', default=\"32\")\n    parser.add_argument('--n_epochs', type=int, default='200')\n    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n    parser.add_argument('--dimhead', default=\"512\", type=int)\n    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n    \n    return parser.parse_args()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.788968Z","iopub.execute_input":"2024-08-22T14:40:48.789612Z","iopub.status.idle":"2024-08-22T14:40:48.801274Z","shell.execute_reply.started":"2024-08-22T14:40:48.789587Z","shell.execute_reply":"2024-08-22T14:40:48.800396Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\ncommand.split()[1:]","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.802427Z","iopub.execute_input":"2024-08-22T14:40:48.803202Z","iopub.status.idle":"2024-08-22T14:40:48.817022Z","shell.execute_reply.started":"2024-08-22T14:40:48.803177Z","shell.execute_reply":"2024-08-22T14:40:48.816052Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"},"metadata":{}}]},{"cell_type":"code","source":"# Simulate command-line arguments\n# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\nsys.argv = command.split()[1:]\n\nargs = parse_args()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.818273Z","iopub.execute_input":"2024-08-22T14:40:48.818572Z","iopub.status.idle":"2024-08-22T14:40:48.827586Z","shell.execute_reply.started":"2024-08-22T14:40:48.818549Z","shell.execute_reply":"2024-08-22T14:40:48.826823Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.828620Z","iopub.execute_input":"2024-08-22T14:40:48.828897Z","iopub.status.idle":"2024-08-22T14:40:48.837934Z","shell.execute_reply.started":"2024-08-22T14:40:48.828874Z","shell.execute_reply":"2024-08-22T14:40:48.837039Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (2.0.1+cu117)\n# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.838899Z","iopub.execute_input":"2024-08-22T14:40:48.839182Z","iopub.status.idle":"2024-08-22T14:40:48.848708Z","shell.execute_reply.started":"2024-08-22T14:40:48.839160Z","shell.execute_reply":"2024-08-22T14:40:48.847938Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# !pip show torchvision\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.849627Z","iopub.execute_input":"2024-08-22T14:40:48.849856Z","iopub.status.idle":"2024-08-22T14:40:48.859359Z","shell.execute_reply.started":"2024-08-22T14:40:48.849837Z","shell.execute_reply":"2024-08-22T14:40:48.858539Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# !pip show torch\n# # ","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.860291Z","iopub.execute_input":"2024-08-22T14:40:48.860562Z","iopub.status.idle":"2024-08-22T14:40:48.869778Z","shell.execute_reply.started":"2024-08-22T14:40:48.860531Z","shell.execute_reply":"2024-08-22T14:40:48.868911Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.870825Z","iopub.execute_input":"2024-08-22T14:40:48.871085Z","iopub.status.idle":"2024-08-22T14:40:48.881946Z","shell.execute_reply.started":"2024-08-22T14:40:48.871063Z","shell.execute_reply":"2024-08-22T14:40:48.881027Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"'0.16.2'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.883066Z","iopub.execute_input":"2024-08-22T14:40:48.883313Z","iopub.status.idle":"2024-08-22T14:40:48.892325Z","shell.execute_reply.started":"2024-08-22T14:40:48.883292Z","shell.execute_reply":"2024-08-22T14:40:48.891423Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"'2.1.2'"},"metadata":{}}]},{"cell_type":"code","source":"2","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.893367Z","iopub.execute_input":"2024-08-22T14:40:48.893709Z","iopub.status.idle":"2024-08-22T14:40:48.903667Z","shell.execute_reply.started":"2024-08-22T14:40:48.893686Z","shell.execute_reply":"2024-08-22T14:40:48.902806Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"\n# take in args\nusewandb = ~args.nowandb\nif usewandb:\n    import wandb\n    watermark = \"{}_lr{}\".format(args.net, args.lr)\n    wandb.init(project=\"cifar10-challange\",\n            name=watermark)\n    wandb.config.update(args)\n\nbs = int(args.bs)\nimsize = int(args.size)\n\nuse_amp = not args.noamp\naug = args.noaug\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\nif args.net==\"vit_timm\":\n    size = 384\nelse:\n    size = imsize\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize(size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Add RandAugment with N, M(hyperparameter)\nif aug:  \n    N = 2; M = 14;\n    transform_train.transforms.insert(0, RandAugment(N, M))","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:40:48.904826Z","iopub.execute_input":"2024-08-22T14:40:48.905576Z","iopub.status.idle":"2024-08-22T14:41:10.733761Z","shell.execute_reply.started":"2024-08-22T14:40:48.905550Z","shell.execute_reply":"2024-08-22T14:41:10.732894Z"},"trusted":true},"execution_count":117,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:c9kfma5g) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vit_lr0.0005</strong> at: <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/c9kfma5g' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/c9kfma5g</a><br/> View project at: <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240822_143700-c9kfma5g/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:c9kfma5g). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240822_144048-aw8wywo6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/aw8wywo6' target=\"_blank\">vit_lr0.0005</a></strong> to <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/aw8wywo6' target=\"_blank\">https://wandb.ai/yajatkapoor72974-iit-delhi/cifar10-challange/runs/aw8wywo6</a>"},"metadata":{}},{"name":"stdout","text":"==> Preparing data..\n","output_type":"stream"}]},{"cell_type":"code","source":"# api token = df6973a974ca9221b939763af4285be4583027aa","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:10.734974Z","iopub.execute_input":"2024-08-22T14:41:10.735303Z","iopub.status.idle":"2024-08-22T14:41:10.740153Z","shell.execute_reply.started":"2024-08-22T14:41:10.735276Z","shell.execute_reply":"2024-08-22T14:41:10.739212Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"\n\n# Prepare dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:10.741210Z","iopub.execute_input":"2024-08-22T14:41:10.741474Z","iopub.status.idle":"2024-08-22T14:41:12.346162Z","shell.execute_reply.started":"2024-08-22T14:41:10.741452Z","shell.execute_reply":"2024-08-22T14:41:12.345040Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# For Multi-GPU\nif 'cuda' in device:\n    print(device)\n    if args.dp:\n        print(\"using data parallel\")\n        net = torch.nn.DataParallel(net) # make parallel\n        cudnn.benchmark = True\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:12.347691Z","iopub.execute_input":"2024-08-22T14:41:12.348103Z","iopub.status.idle":"2024-08-22T14:41:12.356130Z","shell.execute_reply.started":"2024-08-22T14:41:12.348064Z","shell.execute_reply":"2024-08-22T14:41:12.354969Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model factory..\nprint('==> Building model..')\n# net = VGG('VGG19')\nif args.net=='res18':\n    net = ResNet18()\nelif args.net=='vgg':\n    net = VGG('VGG19')\nelif args.net=='res34':\n    net = ResNet34()\nelif args.net=='res50':\n    net = ResNet50()\nelif args.net=='res101':\n    net = ResNet101()\nelif args.net==\"convmixer\":\n    # from paper, accuracy >96%. you can tune the depth and dim to scale accuracy and speed.\n    net = ConvMixer(256, 16, kernel_size=args.convkernel, patch_size=1, n_classes=10)\nelif args.net==\"mlpmixer\":\n    from models.mlpmixer import MLPMixer\n    net = MLPMixer(\n    image_size = 32,\n    channels = 3,\n    patch_size = args.patch,\n    dim = 512,\n    depth = 6,\n    num_classes = 10\n)\nelif args.net==\"vit_small\":\n    from models.vit_small import ViT\n    net = ViT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,\n    heads = 8,\n    mlp_dim = 512,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)\nelif args.net==\"vit_tiny\":\n    from models.vit_small import ViT\n    net = ViT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 4,\n    heads = 6,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)\nelif args.net==\"simplevit\":\n    from models.simplevit import SimpleViT\n    net = SimpleViT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,\n    heads = 8,\n    mlp_dim = 512\n)\nelif args.net==\"vit\":\n    # ViT for cifar10\n    net = ViT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,\n    heads = 8,\n    mlp_dim = 512,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)\nelif args.net==\"vit_timm\":\n    import timm\n    net = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n    net.head = nn.Linear(net.head.in_features, 10)\nelif args.net==\"cait\":\n    from models.cait import CaiT\n    net = CaiT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,   # depth of transformer for patch to patch attention only\n    cls_depth=2, # depth of cross attention of CLS tokens to patch\n    heads = 8,\n    mlp_dim = 512,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    layer_dropout = 0.05\n)\nelif args.net==\"cait_small\":\n    from models.cait import CaiT\n    net = CaiT(\n    image_size = size,\n    patch_size = args.patch,\n    num_classes = 10,\n    dim = int(args.dimhead),\n    depth = 6,   # depth of transformer for patch to patch attention only\n    cls_depth=2, # depth of cross attention of CLS tokens to patch\n    heads = 6,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    layer_dropout = 0.05\n)\nelif args.net==\"swin\":\n    from models.swin import swin_t\n    net = swin_t(window_size=args.patch,\n                num_classes=10,\n                downscaling_factors=(2,2,2,1))\n\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:12.357833Z","iopub.execute_input":"2024-08-22T14:41:12.358446Z","iopub.status.idle":"2024-08-22T14:41:12.484272Z","shell.execute_reply.started":"2024-08-22T14:41:12.358415Z","shell.execute_reply":"2024-08-22T14:41:12.483314Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:12.485352Z","iopub.execute_input":"2024-08-22T14:41:12.485637Z","iopub.status.idle":"2024-08-22T14:41:12.491137Z","shell.execute_reply.started":"2024-08-22T14:41:12.485614Z","shell.execute_reply":"2024-08-22T14:41:12.490225Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"net","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:12.492346Z","iopub.execute_input":"2024-08-22T14:41:12.492750Z","iopub.status.idle":"2024-08-22T14:41:12.505012Z","shell.execute_reply.started":"2024-08-22T14:41:12.492715Z","shell.execute_reply":"2024-08-22T14:41:12.503873Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"ViT(\n  (to_patch_embedding): Sequential(\n    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n    (1): Linear(in_features=48, out_features=512, bias=True)\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (transformer): Transformer(\n    (layers): ModuleList(\n      (0-5): 6 x ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=512, out_features=512, bias=True)\n              (1): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=512, out_features=512, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.1, inplace=False)\n              (3): Linear(in_features=512, out_features=512, bias=True)\n              (4): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n  )\n  (to_latent): Identity()\n  (mlp_head): Sequential(\n    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=512, out_features=10, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Loss is CE\ncriterion = nn.CrossEntropyLoss()\n\nif args.opt == \"adam\":\n    optimizer = optim.Adam(net.parameters(), lr=args.lr)\nelif args.opt == \"sgd\":\n    optimizer = optim.SGD(net.parameters(), lr=args.lr)  \n    \n# use cosine scheduling\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n\n##### Training\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\ndef train(epoch,save_flag):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    # data_save=list()\n    # main_list=list()\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # Train with amp\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            if(save_flag==True and batch_idx%2==0):\n                outputs = net(inputs,True) #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n            else:\n                outputs = net(inputs)\n            loss = criterion(outputs, targets)\n        \n\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    # data_save.append(net.transformer.saved_values)\n\n#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n#     return train_loss/(batch_idx+1),net.transformer.saved_values\n    return train_loss/(batch_idx+1)\n##### Validation\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n    \n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\"model\": net.state_dict(),\n              \"optimizer\": optimizer.state_dict(),\n              \"scaler\": scaler.state_dict()}\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n        best_acc = acc\n    \n    os.makedirs(\"log\", exist_ok=True)\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n    print(content)\n    with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n        appender.write(content + \"\\n\")\n    return test_loss, acc\n\nlist_loss = []\nlist_acc = []\n\nif usewandb:\n    wandb.watch(net)\n    \nnet.cuda()\nmain_list=list()\ndata_save=list()\nn_param=5\nfor epoch in tqdm(range(start_epoch, args.n_epochs)):\n    start = time.time()\n    if(epoch%5==0):\n        trainloss = train(epoch,True)\n    else:\n        trainloss = train(epoch,False)\n        \n    \n        \n#     if(epoch%n_param!=0 or epoch==0):\n#         data_save.append(saved_data)\n#     else:\n#         data_save.append(saved_data)\n#         main_list.append(data_save)\n#         data_save=list()\n    val_loss, acc = test(epoch)\n    \n    scheduler.step(epoch-1) # step cosine scheduling\n    \n    list_loss.append(val_loss)\n    list_acc.append(acc)\n    \n    # Log training..\n    if usewandb:\n        wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n        \"epoch_time\": time.time()-start})\n\n    # Write out csv..\n    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n        writer = csv.writer(f, lineterminator='\\n')\n        writer.writerow(list_loss) \n        writer.writerow(list_acc) \n#     print(list_loss)\n\n# writeout wandb\nif usewandb:\n    wandb.save(\"wandb_{}.h5\".format(args.net))\n    ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-08-22T14:41:12.506362Z","iopub.execute_input":"2024-08-22T14:41:12.506664Z","iopub.status.idle":"2024-08-22T14:41:16.284127Z","shell.execute_reply.started":"2024-08-22T14:41:12.506641Z","shell.execute_reply":"2024-08-22T14:41:16.282427Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"  0%|          | 0/500 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/500 [00:03<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[124], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     trainloss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     trainloss \u001b[38;5;241m=\u001b[39m train(epoch,\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[124], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, save_flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39muse_amp):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(save_flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_idx\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/models/vit.py:149\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, img, save_flag)\u001b[0m\n\u001b[1;32m    146\u001b[0m         x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding[:, :(n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    147\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m--> 149\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_flag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#         if(save_flag==True):\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m#                 # Convert each tensor in `qkv` to a numpy array and save it\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m#                 qkv=attention.to_qkv \u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#                 for i, tensor in enumerate(qkv):\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x[:, \u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/models/vit.py:90\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, save_flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,save_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (attn, ff) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;66;03m# Unpack the output from the Attention layer\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m         attn_out \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_flag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# Save the query, key, value, and logits (output) for this layer\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# self.saved_values.append(q.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# self.saved_values.append(k.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# self.saved_values.append(v.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Combine the attention output with the original x\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         x \u001b[38;5;241m=\u001b[39m attn_out \u001b[38;5;241m+\u001b[39m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/models/vit.py:22\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/models/vit.py:61\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, save_flag)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(qkv):\n\u001b[1;32m     60\u001b[0m             np_array \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Convert to numpy\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m             \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqkv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, np_array)  \u001b[38;5;66;03m# Save each as a .npy file\u001b[39;00m\n\u001b[1;32m     63\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads), qkv)\n\u001b[1;32m     65\u001b[0m dots \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:16.285823Z","iopub.status.idle":"2024-08-22T14:41:16.286680Z","shell.execute_reply.started":"2024-08-22T14:41:16.286416Z","shell.execute_reply":"2024-08-22T14:41:16.286436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1","metadata":{"execution":{"iopub.status.busy":"2024-08-22T14:41:37.692735Z","iopub.execute_input":"2024-08-22T14:41:37.693363Z","iopub.status.idle":"2024-08-22T14:41:37.701448Z","shell.execute_reply.started":"2024-08-22T14:41:37.693324Z","shell.execute_reply":"2024-08-22T14:41:37.700451Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}