{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1782442,"sourceType":"datasetVersion","datasetId":1059701},{"sourceId":2359346,"sourceType":"datasetVersion","datasetId":1424838}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Define hyperparameters","metadata":{}},{"cell_type":"code","source":"\n# Dataset options\nDATASET = 'CIFAR100'  # Options: 'CIFAR10' or 'CIFAR100'\n# DATASET = 'CIFAR10'\n\n# Number of classes options\nNUM_CLASSES = 20     # Set the number of classes\n# NUM_CLASSES = 10   # For example, if using CIFAR-10, set to 10\n\n# Number of attention heads options\nNUM_HEADS = 8        # Options: 8, 4, 2, etc.\n# NUM_HEADS = 4\n# NUM_HEADS = 2","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:27.104059Z","iopub.execute_input":"2024-09-20T10:59:27.104339Z","iopub.status.idle":"2024-09-20T10:59:27.114233Z","shell.execute_reply.started":"2024-09-20T10:59:27.104299Z","shell.execute_reply":"2024-09-20T10:59:27.113374Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_hyperparameters(dataset_name, num_classes, num_heads):\n    \"\"\"\n    Validates the hyperparameters for dataset, number of classes, and number of attention heads.\n\n    Args:\n        dataset_name (str): The name of the dataset ('CIFAR10' or 'CIFAR100').\n        num_classes (int): The number of classes.\n        num_heads (int): The number of attention heads.\n\n    Raises:\n        ValueError: If any hyperparameter is invalid.\n    \"\"\"\n    valid_datasets = ['CIFAR10', 'CIFAR100']\n    if dataset_name not in valid_datasets:\n        raise ValueError(f\"Invalid DATASET value: {dataset_name}. Choose from {valid_datasets}.\")\n\n    if dataset_name == 'CIFAR10' and num_classes != 10:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 10. Current value: {num_classes}.\")\n    elif dataset_name == 'CIFAR100' and num_classes not in [20, 100]:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 20 or 100. Current value: {num_classes}.\")\n\n    valid_heads = [8, 4, 2]\n    if num_heads not in valid_heads:\n        raise ValueError(f\"Invalid NUM_HEADS value: {num_heads}. Choose from {valid_heads}.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:27.116536Z","iopub.execute_input":"2024-09-20T10:59:27.117336Z","iopub.status.idle":"2024-09-20T10:59:27.127181Z","shell.execute_reply.started":"2024-09-20T10:59:27.117302Z","shell.execute_reply":"2024-09-20T10:59:27.126297Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Validate hyperparameters\nvalidate_hyperparameters(DATASET, NUM_CLASSES, NUM_HEADS)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:27.128689Z","iopub.execute_input":"2024-09-20T10:59:27.129321Z","iopub.status.idle":"2024-09-20T10:59:27.136787Z","shell.execute_reply.started":"2024-09-20T10:59:27.129276Z","shell.execute_reply":"2024-09-20T10:59:27.136023Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial Setup","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n'''\n\nTrain CIFAR10 with PyTorch and Vision Transformers!\nwritten by @kentaroy47, @arutema47\nsource : https://github.com/kentaroy47/vision-transformers-cifar10\n\n'''\n\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport numpy as np\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport pandas as pd\nimport csv\nimport time\n\n\n","metadata":{"id":"Llt_Ire4Sxp2","execution":{"iopub.status.busy":"2024-09-20T10:59:27.141016Z","iopub.execute_input":"2024-09-20T10:59:27.141293Z","iopub.status.idle":"2024-09-20T10:59:33.195510Z","shell.execute_reply.started":"2024-09-20T10:59:27.141262Z","shell.execute_reply":"2024-09-20T10:59:33.194600Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"markdown","source":"#### Saving loading","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\n\ndef save_model_state(model, epoch, loss, accuracy, checkpoint_dir='checkpoints', log_file='training_log.txt'):\n    # Create checkpoint directory if it doesn't exist\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    # Save model state\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    torch.save(model.state_dict(), model_checkpoint_path)\n    print(f'Model state saved at epoch {epoch}')\n    \n    # Log accuracy and loss\n    log_file_path = os.path.join(checkpoint_dir, log_file)\n    \n    with open(log_file_path, 'a') as f:\n        f.write(f'Epoch {epoch}: Accuracy = {accuracy:.4f}, Loss = {loss:.4f}\\n')\n    \n    print(f'Logged epoch {epoch} - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}')\n\n    \nimport torch\nimport os\n\ndef load_model_state(model, epoch = 90, checkpoint_dir='checkpoints'):\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    model.load_state_dict(torch.load(model_checkpoint_path))   \n    print(f'Model state loaded from epoch {epoch}')\n    return epoch\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:33.197158Z","iopub.execute_input":"2024-09-20T10:59:33.197572Z","iopub.status.idle":"2024-09-20T10:59:33.205813Z","shell.execute_reply.started":"2024-09-20T10:59:33.197530Z","shell.execute_reply":"2024-09-20T10:59:33.204750Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = 'checkpoints'\n\nif os.path.isdir(directory):\n    print(\"Directory exists\")\n    items = os.listdir(directory)\n    for item in items:\n        print(item)\nelse:\n    print(\"Directory does not exist\")\n    \n#     if os.path.isdir(directory):\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:33.206990Z","iopub.execute_input":"2024-09-20T10:59:33.207376Z","iopub.status.idle":"2024-09-20T10:59:33.218213Z","shell.execute_reply.started":"2024-09-20T10:59:33.207315Z","shell.execute_reply":"2024-09-20T10:59:33.217329Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Directory does not exist\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Remapping labels function","metadata":{}},{"cell_type":"code","source":"def remap_labels(labels, num_classes_old, num_classes_new):\n    \"\"\"\n    Adjusts the labels from an old class structure to a new one.\n\n    Args:\n        labels (torch.Tensor or list): Original labels to be adjusted.\n        num_classes_old (int): The number of classes in the original dataset.\n        num_classes_new (int): The number of classes in the new dataset.\n\n    Returns:\n        torch.Tensor or list: The labels adjusted to the new class structure.\n    \"\"\"\n    # Check that the number of old classes is divisible by the number of new classes\n    assert num_classes_old % num_classes_new == 0, \"The number of old classes must be divisible by the number of new classes.\"\n\n    # Compute the factor to convert old labels to new labels\n    factor = num_classes_old // num_classes_new\n\n    # Remap each label\n    if isinstance(labels, torch.Tensor):\n        # If labels are a tensor, apply the remapping to each label and return a tensor\n        remapped_labels = torch.tensor([label.item() // factor for label in labels])\n    else:\n        # If labels are a list, apply the remapping to each label and return a list\n        remapped_labels = [label // factor for label in labels]\n    \n    return remapped_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:33.220570Z","iopub.execute_input":"2024-09-20T10:59:33.221152Z","iopub.status.idle":"2024-09-20T10:59:33.228616Z","shell.execute_reply.started":"2024-09-20T10:59:33.221109Z","shell.execute_reply":"2024-09-20T10:59:33.227846Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, num_classes_old, num_classes_new):\n        self.dataset = dataset\n        self.num_classes_old = num_classes_old\n        self.num_classes_new = num_classes_new\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, index):\n        image, label = self.dataset[index]\n        remapped_label = remap_labels(torch.tensor([label]), self.num_classes_old, self.num_classes_new).item()\n        return image, remapped_label","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:59:33.229543Z","iopub.execute_input":"2024-09-20T10:59:33.229814Z","iopub.status.idle":"2024-09-20T10:59:33.244087Z","shell.execute_reply.started":"2024-09-20T10:59:33.229784Z","shell.execute_reply":"2024-09-20T10:59:33.243181Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_number = 1\nbase_dir = \"results/runs\"\n\n# Define the new run directory\n\nos.makedirs(\"results\", exist_ok=True)\nos.makedirs(\"results/runs\", exist_ok=True)","metadata":{"id":"MmxrO8v6Sxp5","execution":{"iopub.status.busy":"2024-09-20T10:59:33.245272Z","iopub.execute_input":"2024-09-20T10:59:33.246252Z","iopub.status.idle":"2024-09-20T10:59:33.255659Z","shell.execute_reply.started":"2024-09-20T10:59:33.246219Z","shell.execute_reply":"2024-09-20T10:59:33.254760Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ROEAX6L0Wf7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O9k1NsUWISs","outputId":"6b67a80e-f9d1-43af-ebf4-3088aa41efd0","execution":{"iopub.status.busy":"2024-09-20T10:59:33.257081Z","iopub.execute_input":"2024-09-20T10:59:33.257401Z","iopub.status.idle":"2024-09-20T10:59:33.275196Z","shell.execute_reply.started":"2024-09-20T10:59:33.257366Z","shell.execute_reply":"2024-09-20T10:59:33.274366Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7854dadb8470>"},"metadata":{}}]},{"cell_type":"code","source":"# # setup for a read only personal access token\n# # note : token expires 19 aug 2025\n# token = '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'\n# token_user = 'Asterisk07'\n# repo_host = 'Asterisk07'\n# repo_name = 'BTP-Transformer-explainability'\n\n# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n# !git clone {url}\n\n# !mv {repo_name}/models .\n# !rm -rf BTP-Transformer-explainability # delete a file","metadata":{"id":"aa7zHkXPSxp5","execution":{"iopub.status.busy":"2024-09-20T10:59:33.276407Z","iopub.execute_input":"2024-09-20T10:59:33.276774Z","iopub.status.idle":"2024-09-20T10:59:33.281238Z","shell.execute_reply.started":"2024-09-20T10:59:33.276731Z","shell.execute_reply":"2024-09-20T10:59:33.280392Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JfB6PgwoSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YF9tLt1iSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eQR0IlVsSxp7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fnxx0KDSxp7","outputId":"c0015607-859a-4164-db22-8783ff70f8c1","execution":{"iopub.status.busy":"2024-09-20T10:59:33.282398Z","iopub.execute_input":"2024-09-20T10:59:33.282708Z","iopub.status.idle":"2024-09-20T10:59:34.318676Z","shell.execute_reply.started":"2024-09-20T10:59:33.282664Z","shell.execute_reply":"2024-09-20T10:59:34.317739Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"results\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"rO-x5w5QSxp8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf models","metadata":{"id":"aDRb-t5HSxp9","execution":{"iopub.status.busy":"2024-09-20T10:59:34.322798Z","iopub.execute_input":"2024-09-20T10:59:34.323140Z","iopub.status.idle":"2024-09-20T10:59:34.327915Z","shell.execute_reply.started":"2024-09-20T10:59:34.323104Z","shell.execute_reply":"2024-09-20T10:59:34.327022Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# !npm install -g github-files-fetcher","metadata":{"id":"nyZGC9wISxp9","execution":{"iopub.status.busy":"2024-09-20T10:59:34.329397Z","iopub.execute_input":"2024-09-20T10:59:34.329727Z","iopub.status.idle":"2024-09-20T10:59:34.340626Z","shell.execute_reply.started":"2024-09-20T10:59:34.329695Z","shell.execute_reply":"2024-09-20T10:59:34.339657Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n","metadata":{"id":"XLQdzmZYSxp9","execution":{"iopub.status.busy":"2024-09-20T10:59:34.341796Z","iopub.execute_input":"2024-09-20T10:59:34.342091Z","iopub.status.idle":"2024-09-20T10:59:34.350798Z","shell.execute_reply.started":"2024-09-20T10:59:34.342049Z","shell.execute_reply":"2024-09-20T10:59:34.349880Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZPrL29xSxp9","outputId":"0cab9daf-2631-4d8f-ee64-1d51ccbdf40e","execution":{"iopub.status.busy":"2024-09-20T10:59:34.351865Z","iopub.execute_input":"2024-09-20T10:59:34.352252Z","iopub.status.idle":"2024-09-20T10:59:34.364089Z","shell.execute_reply.started":"2024-09-20T10:59:34.352209Z","shell.execute_reply":"2024-09-20T10:59:34.363213Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"u0zItmyxSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Check if 'utils.py' exists in the current directory\nif os.path.exists('utils.py'):\n    print(\"utils.py exists in the current directory.\")\nelse:\n    print(\"utils.py does not exist in the current directory.\")\n    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n    print(\"utils.py fetched\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSnJhbUCU4J9","outputId":"d466bf62-4b25-4a9b-d2f7-83213799ad8a","execution":{"iopub.status.busy":"2024-09-20T11:01:21.347227Z","iopub.execute_input":"2024-09-20T11:01:21.347641Z","iopub.status.idle":"2024-09-20T11:01:22.574885Z","shell.execute_reply.started":"2024-09-20T11:01:21.347603Z","shell.execute_reply":"2024-09-20T11:01:22.573789Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"utils.py does not exist in the current directory.\n--2024-09-20 11:01:22--  https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3501 (3.4K) [text/plain]\nSaving to: 'utils.py'\n\nutils.py            100%[===================>]   3.42K  --.-KB/s    in 0s      \n\n2024-09-20 11:01:22 (50.0 MB/s) - 'utils.py' saved [3501/3501]\n\nutils.py fetched\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"id":"5XLsXJxiSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import progress_bar","metadata":{"id":"Pe1-pReSSxp-","execution":{"iopub.status.busy":"2024-09-20T11:01:59.714273Z","iopub.status.idle":"2024-09-20T11:01:59.714747Z","shell.execute_reply.started":"2024-09-20T11:01:59.714495Z","shell.execute_reply":"2024-09-20T11:01:59.714519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"_yVbM9QmSxp-","outputId":"2ebfb3d7-3459-40ed-c8a1-33e3839da492","execution":{"iopub.status.busy":"2024-09-20T11:01:22.599639Z","iopub.execute_input":"2024-09-20T11:01:22.599898Z","iopub.status.idle":"2024-09-20T11:01:22.606101Z","shell.execute_reply.started":"2024-09-20T11:01:22.599869Z","shell.execute_reply":"2024-09-20T11:01:22.605101Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<function utils.progress_bar(current, total, msg=None)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"mlKjovnlSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# from randomaug import RandAugment\nfrom torchvision.transforms import RandAugment\n\n","metadata":{"id":"RGLFDHKiSxp_","execution":{"iopub.status.busy":"2024-09-20T11:01:22.608907Z","iopub.execute_input":"2024-09-20T11:01:22.609292Z","iopub.status.idle":"2024-09-20T11:01:22.615245Z","shell.execute_reply.started":"2024-09-20T11:01:22.609252Z","shell.execute_reply":"2024-09-20T11:01:22.614394Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rHHLarISxp_","outputId":"45997e81-9926-4465-d2dd-12835012d6b5","execution":{"iopub.status.busy":"2024-09-20T11:01:22.616582Z","iopub.execute_input":"2024-09-20T11:01:22.616968Z","iopub.status.idle":"2024-09-20T11:01:37.167993Z","shell.execute_reply.started":"2024-09-20T11:01:22.616928Z","shell.execute_reply":"2024-09-20T11:01:37.166800Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m686.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# from models import *\n# from models.vit import ViT\n# from models.convmixer import ConvMixer","metadata":{"id":"UsC7sE2cSxp_","execution":{"iopub.status.busy":"2024-09-20T11:01:37.169786Z","iopub.execute_input":"2024-09-20T11:01:37.170234Z","iopub.status.idle":"2024-09-20T11:01:37.174923Z","shell.execute_reply.started":"2024-09-20T11:01:37.170184Z","shell.execute_reply":"2024-09-20T11:01:37.174050Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJEMQtO5Upra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport json","metadata":{"id":"VJNDccCQe_XC","execution":{"iopub.status.busy":"2024-09-20T11:01:37.176094Z","iopub.execute_input":"2024-09-20T11:01:37.176378Z","iopub.status.idle":"2024-09-20T11:01:37.186382Z","shell.execute_reply.started":"2024-09-20T11:01:37.176347Z","shell.execute_reply":"2024-09-20T11:01:37.185449Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\nqkv_titles = ['q','k','v']","metadata":{"id":"WADSesO6g1ea","execution":{"iopub.status.busy":"2024-09-20T11:01:37.187511Z","iopub.execute_input":"2024-09-20T11:01:37.187863Z","iopub.status.idle":"2024-09-20T11:01:37.195956Z","shell.execute_reply.started":"2024-09-20T11:01:37.187799Z","shell.execute_reply":"2024-09-20T11:01:37.195038Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n# VIT.py\nimport torch\nfrom torch import nn\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\nimport numpy as np\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        out =  self.net(x)\n        if(save_flag==True):\n                file_path = os.path.join(run_dir, 'ff_out.npy')\n                # np.save(file_path, out)\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n        return out\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n\n        inner_dim = dim_head *  heads\n        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim = -1)\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        qkv = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n\n\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n\n        out = torch.matmul(attn, v)\n        if(save_flag==True):\n\n                # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n                for i, tensor in enumerate((q,k,v)):\n                    np_array = tensor[img_idx].detach().cpu().numpy()  # Convert to numpy\n                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n                    np.save(file_path, np_array)\n                file_path = os.path.join(run_dir, 'att_out')\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n                file_path = os.path.join(run_dir, 'att_score')\n                np.save(file_path,attn[img_idx].detach().cpu().numpy())\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        # return self.to_out(out),q,k,v\n        return self.to_out(out)\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n        super().__init__()\n        # print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n\n        self.layers = nn.ModuleList([])\n#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n        # self.saved_values = list()  # To store th\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n            ]))\n\n    def forward(self, x,save_flag=False, run_dir = None, img_idx = None):\n        for i, (attn, ff) in enumerate(self.layers):\n            # Unpack the output from the Attention layer\n            #\n            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n            if save_flag:\n              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n              os.makedirs(layer_dir, exist_ok=True)\n              # print(\"passed trans layer direcetory \", layer_dir)\n            else:\n              layer_dir = None\n            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx)\n\n\n\n            # Save the query, key, value, and logits (output) for this layer\n            # self.saved_values.append(q.cpu().detach().numpy())\n            # self.saved_values.append(k.cpu().detach().numpy())\n            # self.saved_values.append(v.cpu().detach().numpy())\n\n            # Combine the attention output with the original x\n            x = attn_out + x\n            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n            # print(\"i : \",i)\n            # Apply the feedforward network\n#             x = ff(x) + x\n\n            x = ff(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx) + x\n\n        return x\n\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        # print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img, save_flag=False, run_dir = None,img_idx = None):\n        # if (save_flag):\n          # print(\"\\n\\treached here 3\")\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n\n        x = self.transformer(x,save_flag, run_dir, img_idx)\n#         if(save_flag==True):\n#                 # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n#                 for i, tensor in enumerate(qkv):\n#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n\n\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"id":"OzQdLRddSxp_","execution":{"iopub.status.busy":"2024-09-20T11:01:37.197225Z","iopub.execute_input":"2024-09-20T11:01:37.197536Z","iopub.status.idle":"2024-09-20T11:01:37.242602Z","shell.execute_reply.started":"2024-09-20T11:01:37.197504Z","shell.execute_reply":"2024-09-20T11:01:37.241728Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RskDA5B5zDv6","outputId":"85715f3b-73f8-4996-e0e8-b43df9b8dc08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Define your arguments here\ndef parse_args():\n    # parsers\n    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n    parser.add_argument('--opt', default=\"adam\")\n    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n    parser.add_argument('--net', default='vit')\n    parser.add_argument('--dp', action='store_true', help='use data parallel')\n    parser.add_argument('--bs', default='512')\n    parser.add_argument('--size', default=\"32\")\n    parser.add_argument('--n_epochs', type=int, default='200')\n    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n    parser.add_argument('--dimhead', default=\"512\", type=int)\n    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n\n    return parser.parse_args()\n\n\n","metadata":{"id":"GVdr58MRSxp_","execution":{"iopub.status.busy":"2024-09-20T11:01:37.246777Z","iopub.execute_input":"2024-09-20T11:01:37.247069Z","iopub.status.idle":"2024-09-20T11:01:37.255945Z","shell.execute_reply.started":"2024-09-20T11:01:37.247038Z","shell.execute_reply":"2024-09-20T11:01:37.255051Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\ncommand.split()[1:]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JbxSOG5SxqA","outputId":"2c280127-8d9e-4cd0-fc27-3bc03c51d0f2","execution":{"iopub.status.busy":"2024-09-20T11:01:37.256877Z","iopub.execute_input":"2024-09-20T11:01:37.257155Z","iopub.status.idle":"2024-09-20T11:01:37.270859Z","shell.execute_reply.started":"2024-09-20T11:01:37.257126Z","shell.execute_reply":"2024-09-20T11:01:37.269788Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"},"metadata":{}}]},{"cell_type":"code","source":"# Simulate command-line arguments\n# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\nsys.argv = command.split()[1:]\n\nargs = parse_args()\n\n","metadata":{"id":"SFLk9RG5SxqA","execution":{"iopub.status.busy":"2024-09-20T11:01:37.272116Z","iopub.execute_input":"2024-09-20T11:01:37.272930Z","iopub.status.idle":"2024-09-20T11:01:37.281918Z","shell.execute_reply.started":"2024-09-20T11:01:37.272897Z","shell.execute_reply":"2024-09-20T11:01:37.281081Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall","metadata":{"id":"TZfQJlNKSxqA","execution":{"iopub.status.busy":"2024-09-20T11:01:37.282965Z","iopub.execute_input":"2024-09-20T11:01:37.283273Z","iopub.status.idle":"2024-09-20T11:01:37.291751Z","shell.execute_reply.started":"2024-09-20T11:01:37.283242Z","shell.execute_reply":"2024-09-20T11:01:37.290945Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZRdesLOdSxqA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (2.0.1+cu117)\n# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)","metadata":{"id":"xBdPskigSxqA","execution":{"iopub.status.busy":"2024-09-20T11:01:37.292854Z","iopub.execute_input":"2024-09-20T11:01:37.293187Z","iopub.status.idle":"2024-09-20T11:01:37.301584Z","shell.execute_reply.started":"2024-09-20T11:01:37.293154Z","shell.execute_reply":"2024-09-20T11:01:37.300799Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# !pip show torchvision\n","metadata":{"id":"uiDtWCYKSxqA","execution":{"iopub.status.busy":"2024-09-20T11:01:37.302549Z","iopub.execute_input":"2024-09-20T11:01:37.302832Z","iopub.status.idle":"2024-09-20T11:01:37.311500Z","shell.execute_reply.started":"2024-09-20T11:01:37.302801Z","shell.execute_reply":"2024-09-20T11:01:37.310665Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"id":"_T0LacFUt74i","execution":{"iopub.status.busy":"2024-09-20T11:01:37.312675Z","iopub.execute_input":"2024-09-20T11:01:37.312989Z","iopub.status.idle":"2024-09-20T11:01:37.322492Z","shell.execute_reply.started":"2024-09-20T11:01:37.312956Z","shell.execute_reply":"2024-09-20T11:01:37.321646Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# !pip show torch\n# #","metadata":{"id":"NRmD_dGiSxqA","execution":{"iopub.status.busy":"2024-09-20T11:01:37.323488Z","iopub.execute_input":"2024-09-20T11:01:37.323734Z","iopub.status.idle":"2024-09-20T11:01:37.330602Z","shell.execute_reply.started":"2024-09-20T11:01:37.323706Z","shell.execute_reply":"2024-09-20T11:01:37.329732Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m-UHnDboSxqA","outputId":"81f73c03-4a0e-490f-e36e-08f56d3b0124","execution":{"iopub.status.busy":"2024-09-20T11:01:37.331734Z","iopub.execute_input":"2024-09-20T11:01:37.332099Z","iopub.status.idle":"2024-09-20T11:01:37.341602Z","shell.execute_reply.started":"2024-09-20T11:01:37.332057Z","shell.execute_reply":"2024-09-20T11:01:37.340887Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'0.19.0'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aQh5PidkSxqA","outputId":"78297830-3ca1-42b2-fa0a-1b761d0e61fe","execution":{"iopub.status.busy":"2024-09-20T11:01:37.342748Z","iopub.execute_input":"2024-09-20T11:01:37.343048Z","iopub.status.idle":"2024-09-20T11:01:37.352525Z","shell.execute_reply.started":"2024-09-20T11:01:37.342988Z","shell.execute_reply":"2024-09-20T11:01:37.351645Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hedCXexeSxqB","outputId":"247ba528-fb2e-4d69-e300-408eb63d93dd","execution":{"iopub.status.busy":"2024-09-20T11:01:37.353701Z","iopub.execute_input":"2024-09-20T11:01:37.354063Z","iopub.status.idle":"2024-09-20T11:01:50.625841Z","shell.execute_reply.started":"2024-09-20T11:01:37.354022Z","shell.execute_reply":"2024-09-20T11:01:50.624701Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# take in args\nusewandb = ~args.nowandb\nusewandb = False\nif usewandb:\n    import wandb\n    watermark = \"{}_lr{}\".format(args.net, args.lr)\n    wandb.init(project=\"cifar10-challange\",\n            name=watermark)\n    wandb.config.update(args)\n\nbs = int(args.bs)\nimsize = int(args.size)\n\nuse_amp = not args.noamp\naug = args.noaug\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\nif args.net==\"vit_timm\":\n    size = 384\nelse:\n    size = imsize\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize(size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Add RandAugment with N, M(hyperparameter)\nif aug:\n    N = 2; M = 14;\n    transform_train.transforms.insert(0, RandAugment(N, M))\n    \nprint(\"ready to fetch data\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"qnyCPg0HSxqB","outputId":"f6b2c294-26d0-4eaf-aede-2eb3a3c436b9","execution":{"iopub.status.busy":"2024-09-20T11:01:50.627481Z","iopub.execute_input":"2024-09-20T11:01:50.627886Z","iopub.status.idle":"2024-09-20T11:01:50.689732Z","shell.execute_reply.started":"2024-09-20T11:01:50.627841Z","shell.execute_reply":"2024-09-20T11:01:50.688548Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"==> Preparing data..\nready to fetch data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### loading cifar 100","metadata":{"execution":{"iopub.status.busy":"2024-09-08T11:42:51.856499Z","iopub.execute_input":"2024-09-08T11:42:51.857228Z","iopub.status.idle":"2024-09-08T11:42:51.866843Z","shell.execute_reply.started":"2024-09-08T11:42:51.857190Z","shell.execute_reply":"2024-09-08T11:42:51.865688Z"}}},{"cell_type":"code","source":"bs","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:50.690970Z","iopub.execute_input":"2024-09-20T11:01:50.691301Z","iopub.status.idle":"2024-09-20T11:01:50.703612Z","shell.execute_reply.started":"2024-09-20T11:01:50.691263Z","shell.execute_reply":"2024-09-20T11:01:50.702721Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    datasetname = 'cifar10-python'\n    datasetcode = 'pankrzysiu/cifar10-python'\nelif DATASET == 'CIFAR100':\n    datasetname = 'cifar100'\n    datasetcode = 'fedesoriano/cifar100'\n!kaggle datasets download -d {datasetcode}","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:50.704784Z","iopub.execute_input":"2024-09-20T11:01:50.705153Z","iopub.status.idle":"2024-09-20T11:01:54.199569Z","shell.execute_reply.started":"2024-09-20T11:01:50.705110Z","shell.execute_reply":"2024-09-20T11:01:54.198574Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/fedesoriano/cifar100\nLicense(s): copyright-authors\nDownloading cifar100.zip to /kaggle/working\n 95%|███████████████████████████████████████  | 153M/161M [00:01<00:00, 100MB/s]\n100%|█████████████████████████████████████████| 161M/161M [00:01<00:00, 115MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:54.200976Z","iopub.execute_input":"2024-09-20T11:01:54.201347Z","iopub.status.idle":"2024-09-20T11:01:54.205830Z","shell.execute_reply.started":"2024-09-20T11:01:54.201309Z","shell.execute_reply":"2024-09-20T11:01:54.204969Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Unzip the dataset\nwith zipfile.ZipFile(f'{datasetname}.zip', 'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working/dataset')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:54.206856Z","iopub.execute_input":"2024-09-20T11:01:54.207156Z","iopub.status.idle":"2024-09-20T11:01:55.538947Z","shell.execute_reply.started":"2024-09-20T11:01:54.207125Z","shell.execute_reply":"2024-09-20T11:01:55.538151Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class CIFAR10Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # CIFAR-10 images have 3 channels (RGB) and size 32x32\n        self.img_channels = 3\n        self.img_height = 32\n        self.img_width = 32\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        # Reshape the flattened image (3072) into (3, 32, 32) format\n        img = img.reshape(self.img_channels, self.img_height, self.img_width)\n\n        # Convert to PIL Image format (HxWxC)\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n\ndef unpickle(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n\ndef load_cifar10_data(data_path):\n    \"\"\" Load all CIFAR-10 data batches and return combined data and labels \"\"\"\n    train_data = []\n    train_labels = []\n\n    # CIFAR-10 contains 5 training batches\n    for i in range(1, 6):\n        batch = unpickle(f\"{data_path}/data_batch_{i}\")\n        train_data.append(batch[b'data'])\n        train_labels.extend(batch[b'labels'])\n\n    # Convert to numpy arrays\n    train_data = np.concatenate(train_data, axis=0)\n    train_labels = np.array(train_labels)\n\n    # Load test data\n    test_batch = unpickle(f\"{data_path}/test_batch\")\n    test_data = test_batch[b'data']\n    test_labels = np.array(test_batch[b'labels'])\n\n    return (train_data, train_labels), (test_data, test_labels)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.540090Z","iopub.execute_input":"2024-09-20T11:01:55.540394Z","iopub.status.idle":"2024-09-20T11:01:55.552213Z","shell.execute_reply.started":"2024-09-20T11:01:55.540361Z","shell.execute_reply":"2024-09-20T11:01:55.551353Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CIFAR100Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # Determine image dimensions from the first sample\n        sample_img = self.data[0]  # Get the first image sample\n        self.img_channels = 3  # CIFAR-100 images are RGB\n\n        # The image is flattened, so we need to infer the correct shape.\n        self.img_height, self.img_width = self._get_image_dimensions(sample_img)\n\n    def _get_image_dimensions(self, img_flat):\n        # Assuming CIFAR-100 with known number of channels (3)\n        num_pixels = img_flat.size // self.img_channels\n        side = int(np.sqrt(num_pixels))  # CIFAR-100 images are square (32x32)\n        return side, side\n\n    def _reshape_image(self, img_flat):\n        # Try reshaping based on typical formats CxHxW or HxWxC\n        try:\n            img = img_flat.reshape(self.img_channels, self.img_height, self.img_width)  # CxHxW\n        except ValueError:\n            img = img_flat.reshape(self.img_height, self.img_width, self.img_channels)  # HxWxC\n        return img\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        img = self._reshape_image(img)\n\n        # Handle case where image is in HxWxC (common in numpy arrays)\n        if img.shape[0] == self.img_height:  # HxWxC format\n            img = img.transpose(2, 0, 1)  # Convert to CxHxW\n\n        # Convert numpy array to PIL image for transformations\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')  # Convert CxHxW to HxWxC for PIL\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.553202Z","iopub.execute_input":"2024-09-20T11:01:55.553486Z","iopub.status.idle":"2024-09-20T11:01:55.569160Z","shell.execute_reply.started":"2024-09-20T11:01:55.553456Z","shell.execute_reply":"2024-09-20T11:01:55.568307Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.576975Z","iopub.execute_input":"2024-09-20T11:01:55.577374Z","iopub.status.idle":"2024-09-20T11:01:55.583558Z","shell.execute_reply.started":"2024-09-20T11:01:55.577342Z","shell.execute_reply":"2024-09-20T11:01:55.582718Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    \n    # Load CIFAR-10 data\n    data_path = '/kaggle/working/dataset/cifar-10-batches-py'  # Update path as necessary\n    (train_data, train_labels), (test_data, test_labels) = load_cifar10_data(data_path)\n\n    # Prepare datasets\n    trainset = CIFAR10Custom(data=train_data, labels=train_labels, transform=transform_train)\n    testset = CIFAR10Custom(data=test_data, labels=test_labels, transform=transform_test)\n\n    \nelif DATASET == 'CIFAR100':\n    \n\n    # Prepare dataset\n    data_pre_path = '/kaggle/working/dataset'\n    metadata_path = data_pre_path + '/meta'\n    data_train_path = data_pre_path + '/train'\n    data_test_path = data_pre_path + '/test'\n\n    def unpickle(file):\n        import pickle\n        with open(file, 'rb') as fo:\n            data_dict = pickle.load(fo, encoding='bytes')\n        return data_dict\n\n    metadata = unpickle(metadata_path)\n    data_train_dict = unpickle(data_train_path)\n    data_test_dict = unpickle(data_test_path)\n\n    data_train = data_train_dict[b'data']\n    label_train = np.array(data_train_dict[b'coarse_labels'])\n    data_test = data_test_dict[b'data']\n    label_test = np.array(data_test_dict[b'coarse_labels'])\n\n    # Prepare datasets\n    trainset = CIFAR100Custom(data=data_train, labels=label_train, transform=transform_train)\n    testset = CIFAR100Custom(data=data_test, labels=label_test, transform=transform_test)\n\n# DataLoader\nbatch_size = bs  # Adjust batch size as needed\nnum_workers = 4  # Adjust number of workers as needed\n\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\nprint(\"DataLoader prepared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.584742Z","iopub.execute_input":"2024-09-20T11:01:55.585391Z","iopub.status.idle":"2024-09-20T11:01:55.869320Z","shell.execute_reply.started":"2024-09-20T11:01:55.585348Z","shell.execute_reply":"2024-09-20T11:01:55.868359Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"DataLoader prepared.\n","output_type":"stream"}]},{"cell_type":"code","source":"# r1 is None","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.870680Z","iopub.execute_input":"2024-09-20T11:01:55.871314Z","iopub.status.idle":"2024-09-20T11:01:55.875053Z","shell.execute_reply.started":"2024-09-20T11:01:55.871268Z","shell.execute_reply":"2024-09-20T11:01:55.874255Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"i1, l1  = None, None","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.876124Z","iopub.execute_input":"2024-09-20T11:01:55.876379Z","iopub.status.idle":"2024-09-20T11:01:55.885830Z","shell.execute_reply.started":"2024-09-20T11:01:55.876351Z","shell.execute_reply":"2024-09-20T11:01:55.885059Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for images, labels in trainloader:\n    # Get the first image and label from the batch\n    print(1)\n    i1 = images\n    l1 = labels\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:55.886851Z","iopub.execute_input":"2024-09-20T11:01:55.887149Z","iopub.status.idle":"2024-09-20T11:01:57.387423Z","shell.execute_reply.started":"2024-09-20T11:01:55.887118Z","shell.execute_reply":"2024-09-20T11:01:57.386229Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"i1.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.389217Z","iopub.execute_input":"2024-09-20T11:01:57.389589Z","iopub.status.idle":"2024-09-20T11:01:57.396272Z","shell.execute_reply.started":"2024-09-20T11:01:57.389550Z","shell.execute_reply":"2024-09-20T11:01:57.395404Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"torch.Size([512, 3, 32, 32])"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n\n# # Assuming you have a tensor of shape [3, 32, 32]\n# # Create a random tensor for demonstration purposes\n# image_tensor = i1[15]\n\n# # Convert the tensor from [C, H, W] to [H, W, C] for displaying\n# image_np = image_tensor.permute(1, 2, 0).numpy()\n\n# # Plot the image\n# plt.imshow(image_np)\n# plt.axis('off')  # Turn off the axis labels\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.397391Z","iopub.execute_input":"2024-09-20T11:01:57.397716Z","iopub.status.idle":"2024-09-20T11:01:57.409018Z","shell.execute_reply.started":"2024-09-20T11:01:57.397670Z","shell.execute_reply":"2024-09-20T11:01:57.408122Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# # Prepare dataset\n# print(\"Loading dataset from kaggle/input\")\n# trainset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/train', transform=transform_train)\n# testset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/test', transform=transform_test)\n\n# print(\"Loading dataset\")\n# trainloader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.410571Z","iopub.execute_input":"2024-09-20T11:01:57.411344Z","iopub.status.idle":"2024-09-20T11:01:57.421944Z","shell.execute_reply.started":"2024-09-20T11:01:57.411293Z","shell.execute_reply":"2024-09-20T11:01:57.421266Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# len(trainset)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.423188Z","iopub.execute_input":"2024-09-20T11:01:57.423631Z","iopub.status.idle":"2024-09-20T11:01:57.432440Z","shell.execute_reply.started":"2024-09-20T11:01:57.423589Z","shell.execute_reply":"2024-09-20T11:01:57.431712Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# NUM_WORKERS = 4\n# cifar100_path = '/kaggle/input/cifar100'\n# # Prepare dataset\n\n# # trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n\n# # testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n# import torchvision\n# import torch\n# import torch.nn as nnn\n\n\n\n# # Prepare dataset based on hyperparameter\n# print(\"downloading dataset\")\n# if DATASET == 'CIFAR10':\n#     trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n    \n# elif DATASET == 'CIFAR100':\n#     if NUM_CLASSES%20 != 0 :\n#         raise ValueError(\"Invalid value of NUM_CLASSES specified. Choose 20 or 100\")\n#     trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n# else:\n#     raise ValueError(\"Invalid dataset specified. Choose 'CIFAR10' or 'CIFAR100'.\")\n    \n# print(\"loading dataset\")\n# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.433632Z","iopub.execute_input":"2024-09-20T11:01:57.434400Z","iopub.status.idle":"2024-09-20T11:01:57.443875Z","shell.execute_reply.started":"2024-09-20T11:01:57.434356Z","shell.execute_reply":"2024-09-20T11:01:57.442988Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use only this token :\n# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe #aster","metadata":{"id":"V-X21wSpSxqB","execution":{"iopub.status.busy":"2024-09-20T11:01:57.444833Z","iopub.execute_input":"2024-09-20T11:01:57.445164Z","iopub.status.idle":"2024-09-20T11:01:57.456039Z","shell.execute_reply.started":"2024-09-20T11:01:57.445132Z","shell.execute_reply":"2024-09-20T11:01:57.455154Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUzFJatHSxqB","outputId":"3a5a3505-936f-4461-b40a-fc75c7fb4f98","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remapping labels if needed","metadata":{}},{"cell_type":"code","source":"# if NUM_CLASSES == 20:\n#     # Create custom dataset class to remap labels\n\n\n#     # Create custom datasets with remapped labels\n#     trainset = CustomDataset(trainset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n#     testset = CustomDataset(testset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.457159Z","iopub.execute_input":"2024-09-20T11:01:57.457486Z","iopub.status.idle":"2024-09-20T11:01:57.465339Z","shell.execute_reply.started":"2024-09-20T11:01:57.457455Z","shell.execute_reply":"2024-09-20T11:01:57.464497Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:57.466523Z","iopub.execute_input":"2024-09-20T11:01:57.467441Z","iopub.status.idle":"2024-09-20T11:01:57.473947Z","shell.execute_reply.started":"2024-09-20T11:01:57.467407Z","shell.execute_reply":"2024-09-20T11:01:57.473063Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# For Multi-GPU\nif 'cuda' in device:\n    print(device)\n    if args.dp:\n        print(\"using data parallel\")\n        net = torch.nn.DataParallel(net) # make parallel\n        cudnn.benchmark = True\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUqsuNN8SxqB","outputId":"0a2d5706-2adf-45db-d903-f74316ec1faa","execution":{"iopub.status.busy":"2024-09-20T11:01:57.475139Z","iopub.execute_input":"2024-09-20T11:01:57.475482Z","iopub.status.idle":"2024-09-20T11:01:57.487683Z","shell.execute_reply.started":"2024-09-20T11:01:57.475442Z","shell.execute_reply":"2024-09-20T11:01:57.486774Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"ycedpM59zTyh","outputId":"aa2b13bb-b636-44c7-9b7d-b2f2880470da","execution":{"iopub.status.busy":"2024-09-20T11:01:57.488839Z","iopub.execute_input":"2024-09-20T11:01:57.489200Z","iopub.status.idle":"2024-09-20T11:01:58.504368Z","shell.execute_reply.started":"2024-09-20T11:01:57.489160Z","shell.execute_reply":"2024-09-20T11:01:58.503102Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"\ndef get_vit():\n    return ViT(\n    image_size = size,\n    patch_size = args.patch,\n    # num_classes = 10,\n    num_classes = NUM_CLASSES,\n    dim = int(args.dimhead),\n    depth = 6,\n    # heads = 8,\n    heads = NUM_HEADS,\n    # mlp_dim = 512,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    )","metadata":{"id":"ygIfkREcrvX7","execution":{"iopub.status.busy":"2024-09-20T11:01:58.505941Z","iopub.execute_input":"2024-09-20T11:01:58.506329Z","iopub.status.idle":"2024-09-20T11:01:58.512514Z","shell.execute_reply.started":"2024-09-20T11:01:58.506287Z","shell.execute_reply":"2024-09-20T11:01:58.511430Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model factory..\nprint('==> Building model..')\n# net = VGG('VGG19')\nif args.net==\"vit\":\n    # ViT for cifar10\n    net = get_vit()\n\n\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ND8qhixnSxqB","outputId":"e6edb544-3753-446e-ae32-03a9ab15df36","execution":{"iopub.status.busy":"2024-09-20T11:01:58.513643Z","iopub.execute_input":"2024-09-20T11:01:58.513969Z","iopub.status.idle":"2024-09-20T11:01:58.601561Z","shell.execute_reply.started":"2024-09-20T11:01:58.513937Z","shell.execute_reply":"2024-09-20T11:01:58.600640Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"nc4jNV-bSxqC","execution":{"iopub.status.busy":"2024-09-20T11:01:58.602610Z","iopub.execute_input":"2024-09-20T11:01:58.602900Z","iopub.status.idle":"2024-09-20T11:01:58.607743Z","shell.execute_reply.started":"2024-09-20T11:01:58.602869Z","shell.execute_reply":"2024-09-20T11:01:58.606843Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"\nlen(trainloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8emZ75LWcpgE","outputId":"5423fb4a-63af-4ffb-a027-899ae0d60136","execution":{"iopub.status.busy":"2024-09-20T11:01:58.608808Z","iopub.execute_input":"2024-09-20T11:01:58.609122Z","iopub.status.idle":"2024-09-20T11:01:58.617490Z","shell.execute_reply.started":"2024-09-20T11:01:58.609078Z","shell.execute_reply":"2024-09-20T11:01:58.616650Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"98"},"metadata":{}}]},{"cell_type":"code","source":"\n# trainloader[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"GCKRyskOugE5","outputId":"32f19894-9636-4bac-b61a-6db4237f6da5","execution":{"iopub.status.busy":"2024-09-20T11:01:58.618554Z","iopub.execute_input":"2024-09-20T11:01:58.619116Z","iopub.status.idle":"2024-09-20T11:01:58.626488Z","shell.execute_reply.started":"2024-09-20T11:01:58.619072Z","shell.execute_reply":"2024-09-20T11:01:58.625648Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# MAX_EPOCHS = 90\nMAX_EPOCHS = 200","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:58.627675Z","iopub.execute_input":"2024-09-20T11:01:58.628241Z","iopub.status.idle":"2024-09-20T11:01:58.636747Z","shell.execute_reply.started":"2024-09-20T11:01:58.628200Z","shell.execute_reply":"2024-09-20T11:01:58.635878Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from timeit import default_timer as timer\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:58.637704Z","iopub.execute_input":"2024-09-20T11:01:58.638033Z","iopub.status.idle":"2024-09-20T11:01:58.646118Z","shell.execute_reply.started":"2024-09-20T11:01:58.637978Z","shell.execute_reply":"2024-09-20T11:01:58.645222Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"!mkdir model\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:58.647334Z","iopub.execute_input":"2024-09-20T11:01:58.648108Z","iopub.status.idle":"2024-09-20T11:01:59.649586Z","shell.execute_reply.started":"2024-09-20T11:01:58.648075Z","shell.execute_reply":"2024-09-20T11:01:59.648453Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Loss is CE\ncriterion = nn.CrossEntropyLoss()\n\ntorch.manual_seed(42)\nnet = get_vit()\n\nif args.opt == \"adam\":\n    optimizer = optim.Adam(net.parameters(), lr=args.lr)\nelif args.opt == \"sgd\":\n    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n\n# use cosine scheduling\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n\n##### Training\nscaler = torch.amp.GradScaler('cuda',enabled=use_amp)\ndef train(epoch,save_flag, run_dir = None, img_idx = None):\n    \n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # Train with amp\n        with torch.amp.autocast('cuda',enabled=use_amp):\n\n            if(save_flag==True and batch_idx==0):\n                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n                os.makedirs(batch_dir, exist_ok=True)\n\n                outputs = net(inputs, True, batch_dir, img_idx)\n            else:\n                outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    acc = 100.*correct/total\n\n    return train_loss, acc\n\n##### Validation\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    acc = 100.*correct/total\n\n    # os.makedirs(\"results\", exist_ok=True)\n    # os.makedirs(\"results/log\", exist_ok=True)\n    # content = f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n    # print(content)\n    return test_loss, acc\n\nlist_loss = []\nlist_acc = []\n\nif usewandb:\n    wandb.watch(net)\n\n    \nbatch_size = int(args.bs)\n\nif device == 'cuda':\n  net.cuda()\nmain_list=list()\ndata_save=list()\nn_param=5\n\nrun_dir = os.path.join(base_dir, f\"run {run_number:02}\")\nos.makedirs(run_dir, exist_ok=True)\nprint(\"Run number \",run_number)\n\n\n\n\n\n\nimport shutil\nfrom IPython.display import FileLink\n\n# Specify the directory you want to compress\ndirectory_name = run_dir\nzip_filename = f'{run_dir}.zip'\n\n\n\n\n# run_number += 1\n\nmax_epochs = MAX_EPOCHS\n\n# # take_epoch_factor = \n# img_save_count = 50 #IMP\n\n# img_idx = torch.randperm(batch_size)[:img_save_count]\n# img_idx= img_idx.sort()[0]\n# print(\"chosen images are of batch 0 and numbers : \",[x.item() for x in list(img_idx)])\n# file_path = os.path.join(run_dir, 'img_idx.npy')\n# np.save(file_path, img_idx.detach().cpu().numpy())\n\n\n\n# save_epochs =  #IMP\n# epoch_factor = max_epochs  // save_epochs #IMP\n\nepoch_factor = 50 #IMP\npatience_param=10\npatience_counter=0\n\n\nprint(f\"Saving results every {epoch_factor} epochs \")\n\nLOG_FILE_NAME = 'trainlog'\n\n\nprint(\"Training started\")\nbest_loss = float('inf')  # Initialize best loss to a high value\nfor i in tqdm(range(0, max_epochs), desc=\"Training\"):\n    start_time = timer()\n    epoch = i+1\n    print(\"Epoch\", epoch)\n    start = time.time()\n    \n    \n    if True:\n        trainloss,train_acc = train(epoch,False)\n\n\n\n    scheduler.step() # step cosine scheduling\n\n\n    \n     \n    end_time = timer()\n    if (epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs ):\n        \n        \n        val_loss, test_acc = test(epoch)\n        save_model_state(net, epoch , val_loss, acc)\n\n        \n        content = (f\"Epoch: {epoch}  | Train Loss: {trainloss:.3f}, Acc: {train_acc:.2f}% | Test Loss: {val_loss:.3f}, Acc: {test_acc:.2f}% | Time taken: {(end_time - start_time):.3f} sec\")\n\n        if epoch == 1 : \n            filemode = 'w+'\n        else:\n            filemode = 'a+' \n        with open(f'model/{LOG_FILE_NAME}.txt', filemode) as file:\n            file.write(content+'\\n')\n\n\n        # Save the model's state dictionary\n        torch.save(net.state_dict(), 'model/model_state.pth')\n        torch.save(optimizer.state_dict(),'model/optimizer_state.pth')\n\n        \n        # Early stopping logic\n        \n        # val_loss, acc = test(epoch)\n        \n        if val_loss < best_loss:\n            best_loss = val_loss\n            patience_counter = 0  # Reset patience counter if loss improves\n\n        else:\n            patience_counter += 1  # Increment patience counter if no improvement\n\n        # If patience limit is exceeded, stop training\n        if patience_counter >= patience_param:\n            save_model_state(net, epoch , val_loss, acc)\n            print(f'Early stopping at epoch {epoch} due to no improvement')\n\n            break  ## we break out of training loop after saving the model\n    \n    \n    \n# writeout wandb\nif usewandb:\n    wandb.save(\"wandb_{}.h5\".format(args.net))\n\n# import shutil\n# from IPython.display import FileLink\n# zip_filename = 'checkpoints.zip'\n# directory_name = 'checkpoints'\n# shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n# #         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n# print(\"Click here to download checkpoints  : \")\n# display(FileLink(zip_filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":636},"id":"O1brRsc3SxqH","outputId":"062f1e66-7ad7-49f8-fb09-27f797a6909c","execution":{"iopub.status.busy":"2024-09-20T11:07:28.843737Z","iopub.execute_input":"2024-09-20T11:07:28.844659Z","iopub.status.idle":"2024-09-20T11:08:29.949455Z","shell.execute_reply.started":"2024-09-20T11:07:28.844616Z","shell.execute_reply":"2024-09-20T11:08:29.948011Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Run number  1\nSaving results every 50 epochs \nTraining started\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1\nModel state saved at epoch 1\nLogged epoch 1 - Accuracy: 26.6500, Loss: 47.4073\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 1/200 [00:28<1:36:02, 28.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n","output_type":"stream"},{"name":"stderr","text":"Training:   1%|          | 2/200 [00:53<1:26:42, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n","output_type":"stream"},{"name":"stderr","text":"Training:   1%|          | 2/200 [01:00<1:40:23, 30.42s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[74], line 153\u001b[0m\n\u001b[1;32m    149\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     trainloss,train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# step cosine scheduling\u001b[39;00m\n\u001b[1;32m    162\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timer()\n","Cell \u001b[0;32mIn[74], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, save_flag, run_dir, img_idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     42\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"\n\nimport zipfile\nimport os\nfrom IPython.display import FileLink, display\n\n# Path to the file or directory to zip\nfile_to_zip = 'model'\nzip_file_name = 'model_zip.zip'\n\n# Function to zip a directory\ndef zip_dir(directory, zip_file):\n    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(directory):\n            for file in files:\n                file_path = os.path.join(root, file)\n                zipf.write(file_path, os.path.relpath(file_path, directory))\n\n# Zip the file or directory\nif os.path.isdir(file_to_zip):\n    zip_dir(file_to_zip, zip_file_name)\nelse:\n    with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n        zipf.write(file_to_zip, os.path.basename(file_to_zip))\n\n# Display the download link\ndownload_link = FileLink(zip_file_name)\ndisplay(download_link)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.680804Z","iopub.status.idle":"2024-09-20T11:01:59.681195Z","shell.execute_reply.started":"2024-09-20T11:01:59.680979Z","shell.execute_reply":"2024-09-20T11:01:59.681015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Specify the path to your file\nfile_path = zip_file_name\n\n# Get the size of the file in bytes\nfile_size = os.path.getsize(file_path)\n\nprint(f\"The size of the file is : {(file_size/(2**20)):.0f} MB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.683240Z","iopub.status.idle":"2024-09-20T11:01:59.683736Z","shell.execute_reply.started":"2024-09-20T11:01:59.683478Z","shell.execute_reply":"2024-09-20T11:01:59.683503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raise ZeroDivisionError","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.685492Z","iopub.status.idle":"2024-09-20T11:01:59.685988Z","shell.execute_reply.started":"2024-09-20T11:01:59.685736Z","shell.execute_reply":"2024-09-20T11:01:59.685761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd data\n!ls\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.687600Z","iopub.status.idle":"2024-09-20T11:01:59.688093Z","shell.execute_reply.started":"2024-09-20T11:01:59.687821Z","shell.execute_reply":"2024-09-20T11:01:59.687846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.689160Z","iopub.status.idle":"2024-09-20T11:01:59.689652Z","shell.execute_reply.started":"2024-09-20T11:01:59.689391Z","shell.execute_reply":"2024-09-20T11:01:59.689416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf results\n# !rm -rf log\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.691372Z","iopub.status.idle":"2024-09-20T11:01:59.691725Z","shell.execute_reply.started":"2024-09-20T11:01:59.691548Z","shell.execute_reply":"2024-09-20T11:01:59.691568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.693347Z","iopub.status.idle":"2024-09-20T11:01:59.693703Z","shell.execute_reply.started":"2024-09-20T11:01:59.693523Z","shell.execute_reply":"2024-09-20T11:01:59.693541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_idx.detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.695233Z","iopub.status.idle":"2024-09-20T11:01:59.695573Z","shell.execute_reply.started":"2024-09-20T11:01:59.695401Z","shell.execute_reply":"2024-09-20T11:01:59.695418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# from IPython.display import FileLink\n\n# # Specify the directory you want to compress\n# directory_name = 'log'\n# zip_filename = 'log.zip'\n\n# # Compress the directory into a zip file, overwriting if it already exists\n# shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n# # Optionally generate and display a download link\n# print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n# FileLink(zip_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.696711Z","iopub.status.idle":"2024-09-20T11:01:59.697060Z","shell.execute_reply.started":"2024-09-20T11:01:59.696867Z","shell.execute_reply":"2024-09-20T11:01:59.696884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"e1RV3ub4bzaF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnet","metadata":{"id":"n5yDPk01T0oL","execution":{"iopub.status.busy":"2024-09-20T11:01:59.698060Z","iopub.status.idle":"2024-09-20T11:01:59.698486Z","shell.execute_reply.started":"2024-09-20T11:01:59.698253Z","shell.execute_reply":"2024-09-20T11:01:59.698272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n/content/results/runs/run 04/epoch 00/batch 0/layer 01","metadata":{"id":"c61Jvkt9v1cj","execution":{"iopub.status.busy":"2024-09-20T11:01:59.700289Z","iopub.status.idle":"2024-09-20T11:01:59.700651Z","shell.execute_reply.started":"2024-09-20T11:01:59.700475Z","shell.execute_reply":"2024-09-20T11:01:59.700493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9sDNpPTSxqI","outputId":"802a6209-4de8-4ac2-e0c7-37c20468a8bb","execution":{"iopub.status.busy":"2024-09-20T11:01:59.701681Z","iopub.status.idle":"2024-09-20T11:01:59.702064Z","shell.execute_reply.started":"2024-09-20T11:01:59.701854Z","shell.execute_reply":"2024-09-20T11:01:59.701872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:01:59.704178Z","iopub.status.idle":"2024-09-20T11:01:59.704536Z","shell.execute_reply.started":"2024-09-20T11:01:59.704360Z","shell.execute_reply":"2024-09-20T11:01:59.704379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Define the directory path you want to check\ndirectory_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/'\n\n# Check if the directory exists\nif os.path.isdir(directory_path):\n    print(f\"The directory '{directory_path}' exists.\")\nelse:\n    print(f\"The directory '{directory_path}' does not exist.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq9FNrXywIbb","outputId":"db92a1f9-34a2-49a1-8f61-f9e0750ec05d","execution":{"iopub.status.busy":"2024-09-20T11:01:59.706585Z","iopub.status.idle":"2024-09-20T11:01:59.706938Z","shell.execute_reply.started":"2024-09-20T11:01:59.706764Z","shell.execute_reply":"2024-09-20T11:01:59.706782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/01_attention_out.npy'\n\n# Load the NumPy array from the file\ndata = np.load(file_path)","metadata":{"id":"d2GSp2wbSxqI","execution":{"iopub.status.busy":"2024-09-20T11:01:59.707977Z","iopub.status.idle":"2024-09-20T11:01:59.708348Z","shell.execute_reply.started":"2024-09-20T11:01:59.708176Z","shell.execute_reply":"2024-09-20T11:01:59.708194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlFIzQIUSxqI","outputId":"5dce6a00-7620-4944-8d0d-6ccaa42668e6","execution":{"iopub.status.busy":"2024-09-20T11:01:59.709808Z","iopub.status.idle":"2024-09-20T11:01:59.710371Z","shell.execute_reply.started":"2024-09-20T11:01:59.710085Z","shell.execute_reply":"2024-09-20T11:01:59.710115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.shape\n# shape : batch x head x X x Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr5wj-at0UJo","outputId":"874907d1-f72d-45f6-f805-8623093c5a0b","execution":{"iopub.status.busy":"2024-09-20T11:01:59.712084Z","iopub.status.idle":"2024-09-20T11:01:59.712606Z","shell.execute_reply.started":"2024-09-20T11:01:59.712338Z","shell.execute_reply":"2024-09-20T11:01:59.712363Z"},"trusted":true},"execution_count":null,"outputs":[]}]}