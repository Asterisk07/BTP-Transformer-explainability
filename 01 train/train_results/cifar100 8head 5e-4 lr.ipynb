{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1782442,"sourceType":"datasetVersion","datasetId":1059701},{"sourceId":2359346,"sourceType":"datasetVersion","datasetId":1424838}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Define hyperparameters","metadata":{}},{"cell_type":"code","source":"\n# Dataset options\nDATASET = 'CIFAR100'  # Options: 'CIFAR10' or 'CIFAR100'\n# DATASET = 'CIFAR10'\n\n# Number of classes options\nNUM_CLASSES = 20     # Set the number of classes\n# NUM_CLASSES = 10   # For example, if using CIFAR-10, set to 10\n\n# Number of attention heads options\nNUM_HEADS = 8        # Options: 8, 4, 2, etc.\n# NUM_HEADS = 4\n# NUM_HEADS = 2","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.020307Z","iopub.execute_input":"2024-09-08T12:31:14.020678Z","iopub.status.idle":"2024-09-08T12:31:14.031721Z","shell.execute_reply.started":"2024-09-08T12:31:14.020622Z","shell.execute_reply":"2024-09-08T12:31:14.030848Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_hyperparameters(dataset_name, num_classes, num_heads):\n    \"\"\"\n    Validates the hyperparameters for dataset, number of classes, and number of attention heads.\n\n    Args:\n        dataset_name (str): The name of the dataset ('CIFAR10' or 'CIFAR100').\n        num_classes (int): The number of classes.\n        num_heads (int): The number of attention heads.\n\n    Raises:\n        ValueError: If any hyperparameter is invalid.\n    \"\"\"\n    valid_datasets = ['CIFAR10', 'CIFAR100']\n    if dataset_name not in valid_datasets:\n        raise ValueError(f\"Invalid DATASET value: {dataset_name}. Choose from {valid_datasets}.\")\n\n    if dataset_name == 'CIFAR10' and num_classes != 10:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 10. Current value: {num_classes}.\")\n    elif dataset_name == 'CIFAR100' and num_classes not in [20, 100]:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 20 or 100. Current value: {num_classes}.\")\n\n    valid_heads = [8, 4, 2]\n    if num_heads not in valid_heads:\n        raise ValueError(f\"Invalid NUM_HEADS value: {num_heads}. Choose from {valid_heads}.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.033169Z","iopub.execute_input":"2024-09-08T12:31:14.033454Z","iopub.status.idle":"2024-09-08T12:31:14.045062Z","shell.execute_reply.started":"2024-09-08T12:31:14.033423Z","shell.execute_reply":"2024-09-08T12:31:14.044151Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Validate hyperparameters\nvalidate_hyperparameters(DATASET, NUM_CLASSES, NUM_HEADS)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.049041Z","iopub.execute_input":"2024-09-08T12:31:14.049393Z","iopub.status.idle":"2024-09-08T12:31:14.053769Z","shell.execute_reply.started":"2024-09-08T12:31:14.049341Z","shell.execute_reply":"2024-09-08T12:31:14.052909Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial Setup","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n'''\n\nTrain CIFAR10 with PyTorch and Vision Transformers!\nwritten by @kentaroy47, @arutema47\nsource : https://github.com/kentaroy47/vision-transformers-cifar10\n\n'''\n\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport numpy as np\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport pandas as pd\nimport csv\nimport time\n\n\n","metadata":{"id":"Llt_Ire4Sxp2","execution":{"iopub.status.busy":"2024-09-08T12:31:14.066530Z","iopub.execute_input":"2024-09-08T12:31:14.067137Z","iopub.status.idle":"2024-09-08T12:31:19.007601Z","shell.execute_reply.started":"2024-09-08T12:31:14.067107Z","shell.execute_reply":"2024-09-08T12:31:19.006666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"markdown","source":"#### Saving loading","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\n\ndef save_model_state(model, epoch, loss, accuracy, checkpoint_dir='checkpoints', log_file='training_log.txt'):\n    # Create checkpoint directory if it doesn't exist\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    # Save model state\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    torch.save(model.state_dict(), model_checkpoint_path)\n    print(f'Model state saved at epoch {epoch}')\n    \n    # Log accuracy and loss\n    log_file_path = os.path.join(checkpoint_dir, log_file)\n    \n    with open(log_file_path, 'a') as f:\n        f.write(f'Epoch {epoch}: Accuracy = {accuracy:.4f}, Loss = {loss:.4f}\\n')\n    \n    print(f'Logged epoch {epoch} - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}')\n\n    \nimport torch\nimport os\n\ndef load_model_state(model, epoch = 90, checkpoint_dir='checkpoints'):\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    model.load_state_dict(torch.load(model_checkpoint_path))   \n    print(f'Model state loaded from epoch {epoch}')\n    return epoch\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.009880Z","iopub.execute_input":"2024-09-08T12:31:19.010407Z","iopub.status.idle":"2024-09-08T12:31:19.020307Z","shell.execute_reply.started":"2024-09-08T12:31:19.010361Z","shell.execute_reply":"2024-09-08T12:31:19.018013Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = 'checkpoints'\n\nif os.path.isdir(directory):\n    print(\"Directory exists\")\n    items = os.listdir(directory)\n    for item in items:\n        print(item)\nelse:\n    print(\"Directory does not exist\")\n    \n#     if os.path.isdir(directory):\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.021332Z","iopub.execute_input":"2024-09-08T12:31:19.021607Z","iopub.status.idle":"2024-09-08T12:31:19.032419Z","shell.execute_reply.started":"2024-09-08T12:31:19.021576Z","shell.execute_reply":"2024-09-08T12:31:19.031354Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Directory does not exist\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Remapping labels function","metadata":{}},{"cell_type":"code","source":"def remap_labels(labels, num_classes_old, num_classes_new):\n    \"\"\"\n    Adjusts the labels from an old class structure to a new one.\n\n    Args:\n        labels (torch.Tensor or list): Original labels to be adjusted.\n        num_classes_old (int): The number of classes in the original dataset.\n        num_classes_new (int): The number of classes in the new dataset.\n\n    Returns:\n        torch.Tensor or list: The labels adjusted to the new class structure.\n    \"\"\"\n    # Check that the number of old classes is divisible by the number of new classes\n    assert num_classes_old % num_classes_new == 0, \"The number of old classes must be divisible by the number of new classes.\"\n\n    # Compute the factor to convert old labels to new labels\n    factor = num_classes_old // num_classes_new\n\n    # Remap each label\n    if isinstance(labels, torch.Tensor):\n        # If labels are a tensor, apply the remapping to each label and return a tensor\n        remapped_labels = torch.tensor([label.item() // factor for label in labels])\n    else:\n        # If labels are a list, apply the remapping to each label and return a list\n        remapped_labels = [label // factor for label in labels]\n    \n    return remapped_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.033906Z","iopub.execute_input":"2024-09-08T12:31:19.034343Z","iopub.status.idle":"2024-09-08T12:31:19.043569Z","shell.execute_reply.started":"2024-09-08T12:31:19.034298Z","shell.execute_reply":"2024-09-08T12:31:19.042671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, num_classes_old, num_classes_new):\n        self.dataset = dataset\n        self.num_classes_old = num_classes_old\n        self.num_classes_new = num_classes_new\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, index):\n        image, label = self.dataset[index]\n        remapped_label = remap_labels(torch.tensor([label]), self.num_classes_old, self.num_classes_new).item()\n        return image, remapped_label","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.046279Z","iopub.execute_input":"2024-09-08T12:31:19.046611Z","iopub.status.idle":"2024-09-08T12:31:19.054682Z","shell.execute_reply.started":"2024-09-08T12:31:19.046572Z","shell.execute_reply":"2024-09-08T12:31:19.053750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_number = 1\nbase_dir = \"results/runs\"\n\n# Define the new run directory\n\nos.makedirs(\"results\", exist_ok=True)\nos.makedirs(\"results/runs\", exist_ok=True)","metadata":{"id":"MmxrO8v6Sxp5","execution":{"iopub.status.busy":"2024-09-08T12:31:19.055922Z","iopub.execute_input":"2024-09-08T12:31:19.056219Z","iopub.status.idle":"2024-09-08T12:31:19.063082Z","shell.execute_reply.started":"2024-09-08T12:31:19.056177Z","shell.execute_reply":"2024-09-08T12:31:19.062087Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ROEAX6L0Wf7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O9k1NsUWISs","outputId":"6b67a80e-f9d1-43af-ebf4-3088aa41efd0","execution":{"iopub.status.busy":"2024-09-08T12:31:19.064267Z","iopub.execute_input":"2024-09-08T12:31:19.064572Z","iopub.status.idle":"2024-09-08T12:31:19.078326Z","shell.execute_reply.started":"2024-09-08T12:31:19.064540Z","shell.execute_reply":"2024-09-08T12:31:19.077510Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ec8117d0470>"},"metadata":{}}]},{"cell_type":"code","source":"# # setup for a read only personal access token\n# # note : token expires 19 aug 2025\n# token = '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'\n# token_user = 'Asterisk07'\n# repo_host = 'Asterisk07'\n# repo_name = 'BTP-Transformer-explainability'\n\n# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n# !git clone {url}\n\n# !mv {repo_name}/models .\n# !rm -rf BTP-Transformer-explainability # delete a file","metadata":{"id":"aa7zHkXPSxp5","execution":{"iopub.status.busy":"2024-09-08T12:31:19.079342Z","iopub.execute_input":"2024-09-08T12:31:19.079601Z","iopub.status.idle":"2024-09-08T12:31:19.083791Z","shell.execute_reply.started":"2024-09-08T12:31:19.079572Z","shell.execute_reply":"2024-09-08T12:31:19.082932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JfB6PgwoSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YF9tLt1iSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eQR0IlVsSxp7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fnxx0KDSxp7","outputId":"c0015607-859a-4164-db22-8783ff70f8c1","execution":{"iopub.status.busy":"2024-09-08T12:31:19.084970Z","iopub.execute_input":"2024-09-08T12:31:19.085406Z","iopub.status.idle":"2024-09-08T12:31:20.131528Z","shell.execute_reply.started":"2024-09-08T12:31:19.085372Z","shell.execute_reply":"2024-09-08T12:31:20.130427Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"results\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"rO-x5w5QSxp8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf models","metadata":{"id":"aDRb-t5HSxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.133215Z","iopub.execute_input":"2024-09-08T12:31:20.133689Z","iopub.status.idle":"2024-09-08T12:31:20.139142Z","shell.execute_reply.started":"2024-09-08T12:31:20.133642Z","shell.execute_reply":"2024-09-08T12:31:20.137924Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# !npm install -g github-files-fetcher","metadata":{"id":"nyZGC9wISxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.140480Z","iopub.execute_input":"2024-09-08T12:31:20.141508Z","iopub.status.idle":"2024-09-08T12:31:20.148606Z","shell.execute_reply.started":"2024-09-08T12:31:20.141464Z","shell.execute_reply":"2024-09-08T12:31:20.147783Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n","metadata":{"id":"XLQdzmZYSxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.149772Z","iopub.execute_input":"2024-09-08T12:31:20.150146Z","iopub.status.idle":"2024-09-08T12:31:20.156309Z","shell.execute_reply.started":"2024-09-08T12:31:20.150099Z","shell.execute_reply":"2024-09-08T12:31:20.155469Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZPrL29xSxp9","outputId":"0cab9daf-2631-4d8f-ee64-1d51ccbdf40e","execution":{"iopub.status.busy":"2024-09-08T12:31:20.157667Z","iopub.execute_input":"2024-09-08T12:31:20.158485Z","iopub.status.idle":"2024-09-08T12:31:20.166499Z","shell.execute_reply.started":"2024-09-08T12:31:20.158435Z","shell.execute_reply":"2024-09-08T12:31:20.165448Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"u0zItmyxSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Check if 'utils.py' exists in the current directory\nif os.path.exists('utils.py'):\n    print(\"utils.py exists in the current directory.\")\nelse:\n    print(\"utils.py does not exist in the current directory.\")\n    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n    print(\"utils.py fetched\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSnJhbUCU4J9","outputId":"d466bf62-4b25-4a9b-d2f7-83213799ad8a","execution":{"iopub.status.busy":"2024-09-08T12:31:20.172756Z","iopub.execute_input":"2024-09-08T12:31:20.173158Z","iopub.status.idle":"2024-09-08T12:31:21.333258Z","shell.execute_reply.started":"2024-09-08T12:31:20.173109Z","shell.execute_reply":"2024-09-08T12:31:21.332268Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"utils.py does not exist in the current directory.\n--2024-09-08 12:31:21--  https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3501 (3.4K) [text/plain]\nSaving to: 'utils.py'\n\nutils.py            100%[===================>]   3.42K  --.-KB/s    in 0s      \n\n2024-09-08 12:31:21 (68.9 MB/s) - 'utils.py' saved [3501/3501]\n\nutils.py fetched\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"id":"5XLsXJxiSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import progress_bar","metadata":{"id":"Pe1-pReSSxp-","execution":{"iopub.status.busy":"2024-09-08T12:31:21.334645Z","iopub.execute_input":"2024-09-08T12:31:21.334971Z","iopub.status.idle":"2024-09-08T12:31:21.348399Z","shell.execute_reply.started":"2024-09-08T12:31:21.334935Z","shell.execute_reply":"2024-09-08T12:31:21.347550Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"stty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"}]},{"cell_type":"code","source":"progress_bar","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"_yVbM9QmSxp-","outputId":"2ebfb3d7-3459-40ed-c8a1-33e3839da492","execution":{"iopub.status.busy":"2024-09-08T12:31:21.349678Z","iopub.execute_input":"2024-09-08T12:31:21.350440Z","iopub.status.idle":"2024-09-08T12:31:21.356564Z","shell.execute_reply.started":"2024-09-08T12:31:21.350395Z","shell.execute_reply":"2024-09-08T12:31:21.355690Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<function utils.progress_bar(current, total, msg=None)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"mlKjovnlSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# from randomaug import RandAugment\nfrom torchvision.transforms import RandAugment\n\n","metadata":{"id":"RGLFDHKiSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:21.357906Z","iopub.execute_input":"2024-09-08T12:31:21.358300Z","iopub.status.idle":"2024-09-08T12:31:21.362764Z","shell.execute_reply.started":"2024-09-08T12:31:21.358260Z","shell.execute_reply":"2024-09-08T12:31:21.361843Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rHHLarISxp_","outputId":"45997e81-9926-4465-d2dd-12835012d6b5","execution":{"iopub.status.busy":"2024-09-08T12:31:21.364023Z","iopub.execute_input":"2024-09-08T12:31:21.364663Z","iopub.status.idle":"2024-09-08T12:31:35.419057Z","shell.execute_reply.started":"2024-09-08T12:31:21.364607Z","shell.execute_reply":"2024-09-08T12:31:35.418005Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m671.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# from models import *\n# from models.vit import ViT\n# from models.convmixer import ConvMixer","metadata":{"id":"UsC7sE2cSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.420755Z","iopub.execute_input":"2024-09-08T12:31:35.421657Z","iopub.status.idle":"2024-09-08T12:31:35.425911Z","shell.execute_reply.started":"2024-09-08T12:31:35.421590Z","shell.execute_reply":"2024-09-08T12:31:35.424962Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJEMQtO5Upra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport json","metadata":{"id":"VJNDccCQe_XC","execution":{"iopub.status.busy":"2024-09-08T12:31:35.427391Z","iopub.execute_input":"2024-09-08T12:31:35.427785Z","iopub.status.idle":"2024-09-08T12:31:35.435078Z","shell.execute_reply.started":"2024-09-08T12:31:35.427741Z","shell.execute_reply":"2024-09-08T12:31:35.434211Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\nqkv_titles = ['q','k','v']","metadata":{"id":"WADSesO6g1ea","execution":{"iopub.status.busy":"2024-09-08T12:31:35.436184Z","iopub.execute_input":"2024-09-08T12:31:35.436545Z","iopub.status.idle":"2024-09-08T12:31:35.442664Z","shell.execute_reply.started":"2024-09-08T12:31:35.436501Z","shell.execute_reply":"2024-09-08T12:31:35.441972Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n# VIT.py\nimport torch\nfrom torch import nn\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\nimport numpy as np\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        out =  self.net(x)\n        if(save_flag==True):\n                file_path = os.path.join(run_dir, 'ff_out.npy')\n                # np.save(file_path, out)\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n        return out\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n\n        inner_dim = dim_head *  heads\n        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim = -1)\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        qkv = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n\n\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n\n        out = torch.matmul(attn, v)\n        if(save_flag==True):\n\n                # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n                for i, tensor in enumerate((q,k,v)):\n                    np_array = tensor[img_idx].detach().cpu().numpy()  # Convert to numpy\n                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n                    np.save(file_path, np_array)\n                file_path = os.path.join(run_dir, 'att_out')\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n                file_path = os.path.join(run_dir, 'att_score')\n                np.save(file_path,attn[img_idx].detach().cpu().numpy())\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        # return self.to_out(out),q,k,v\n        return self.to_out(out)\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n        super().__init__()\n        # print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n\n        self.layers = nn.ModuleList([])\n#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n        # self.saved_values = list()  # To store th\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n            ]))\n\n    def forward(self, x,save_flag=False, run_dir = None, img_idx = None):\n        for i, (attn, ff) in enumerate(self.layers):\n            # Unpack the output from the Attention layer\n            #\n            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n            if save_flag:\n              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n              os.makedirs(layer_dir, exist_ok=True)\n              # print(\"passed trans layer direcetory \", layer_dir)\n            else:\n              layer_dir = None\n            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx)\n\n\n\n            # Save the query, key, value, and logits (output) for this layer\n            # self.saved_values.append(q.cpu().detach().numpy())\n            # self.saved_values.append(k.cpu().detach().numpy())\n            # self.saved_values.append(v.cpu().detach().numpy())\n\n            # Combine the attention output with the original x\n            x = attn_out + x\n            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n            # print(\"i : \",i)\n            # Apply the feedforward network\n#             x = ff(x) + x\n\n            x = ff(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx) + x\n\n        return x\n\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        # print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img, save_flag=False, run_dir = None,img_idx = None):\n        # if (save_flag):\n          # print(\"\\n\\treached here 3\")\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n\n        x = self.transformer(x,save_flag, run_dir, img_idx)\n#         if(save_flag==True):\n#                 # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n#                 for i, tensor in enumerate(qkv):\n#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n\n\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"id":"OzQdLRddSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.444054Z","iopub.execute_input":"2024-09-08T12:31:35.444406Z","iopub.status.idle":"2024-09-08T12:31:35.489948Z","shell.execute_reply.started":"2024-09-08T12:31:35.444366Z","shell.execute_reply":"2024-09-08T12:31:35.489021Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RskDA5B5zDv6","outputId":"85715f3b-73f8-4996-e0e8-b43df9b8dc08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Define your arguments here\ndef parse_args():\n    # parsers\n    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n    parser.add_argument('--opt', default=\"adam\")\n    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n    parser.add_argument('--net', default='vit')\n    parser.add_argument('--dp', action='store_true', help='use data parallel')\n    parser.add_argument('--bs', default='512')\n    parser.add_argument('--size', default=\"32\")\n    parser.add_argument('--n_epochs', type=int, default='200')\n    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n    parser.add_argument('--dimhead', default=\"512\", type=int)\n    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n\n    return parser.parse_args()\n\n\n","metadata":{"id":"GVdr58MRSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.491025Z","iopub.execute_input":"2024-09-08T12:31:35.491372Z","iopub.status.idle":"2024-09-08T12:31:35.500557Z","shell.execute_reply.started":"2024-09-08T12:31:35.491328Z","shell.execute_reply":"2024-09-08T12:31:35.499599Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\ncommand.split()[1:]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JbxSOG5SxqA","outputId":"2c280127-8d9e-4cd0-fc27-3bc03c51d0f2","execution":{"iopub.status.busy":"2024-09-08T12:31:35.501856Z","iopub.execute_input":"2024-09-08T12:31:35.502887Z","iopub.status.idle":"2024-09-08T12:31:35.513526Z","shell.execute_reply.started":"2024-09-08T12:31:35.502843Z","shell.execute_reply":"2024-09-08T12:31:35.512683Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"},"metadata":{}}]},{"cell_type":"code","source":"# Simulate command-line arguments\n# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\nsys.argv = command.split()[1:]\n\nargs = parse_args()\n\n","metadata":{"id":"SFLk9RG5SxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.514551Z","iopub.execute_input":"2024-09-08T12:31:35.514839Z","iopub.status.idle":"2024-09-08T12:31:35.521848Z","shell.execute_reply.started":"2024-09-08T12:31:35.514810Z","shell.execute_reply":"2024-09-08T12:31:35.521060Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall","metadata":{"id":"TZfQJlNKSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.522837Z","iopub.execute_input":"2024-09-08T12:31:35.523140Z","iopub.status.idle":"2024-09-08T12:31:35.529255Z","shell.execute_reply.started":"2024-09-08T12:31:35.523109Z","shell.execute_reply":"2024-09-08T12:31:35.528405Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZRdesLOdSxqA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (2.0.1+cu117)\n# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)","metadata":{"id":"xBdPskigSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.530167Z","iopub.execute_input":"2024-09-08T12:31:35.531006Z","iopub.status.idle":"2024-09-08T12:31:35.537416Z","shell.execute_reply.started":"2024-09-08T12:31:35.530967Z","shell.execute_reply":"2024-09-08T12:31:35.536619Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# !pip show torchvision\n","metadata":{"id":"uiDtWCYKSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.538524Z","iopub.execute_input":"2024-09-08T12:31:35.539136Z","iopub.status.idle":"2024-09-08T12:31:35.545445Z","shell.execute_reply.started":"2024-09-08T12:31:35.539095Z","shell.execute_reply":"2024-09-08T12:31:35.544620Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"id":"_T0LacFUt74i","execution":{"iopub.status.busy":"2024-09-08T12:31:35.546425Z","iopub.execute_input":"2024-09-08T12:31:35.546784Z","iopub.status.idle":"2024-09-08T12:31:35.555773Z","shell.execute_reply.started":"2024-09-08T12:31:35.546740Z","shell.execute_reply":"2024-09-08T12:31:35.554852Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# !pip show torch\n# #","metadata":{"id":"NRmD_dGiSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.557071Z","iopub.execute_input":"2024-09-08T12:31:35.557967Z","iopub.status.idle":"2024-09-08T12:31:35.561993Z","shell.execute_reply.started":"2024-09-08T12:31:35.557912Z","shell.execute_reply":"2024-09-08T12:31:35.561091Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m-UHnDboSxqA","outputId":"81f73c03-4a0e-490f-e36e-08f56d3b0124","execution":{"iopub.status.busy":"2024-09-08T12:31:35.563105Z","iopub.execute_input":"2024-09-08T12:31:35.563444Z","iopub.status.idle":"2024-09-08T12:31:35.573343Z","shell.execute_reply.started":"2024-09-08T12:31:35.563411Z","shell.execute_reply":"2024-09-08T12:31:35.572448Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'0.19.0'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aQh5PidkSxqA","outputId":"78297830-3ca1-42b2-fa0a-1b761d0e61fe","execution":{"iopub.status.busy":"2024-09-08T12:31:35.574606Z","iopub.execute_input":"2024-09-08T12:31:35.574965Z","iopub.status.idle":"2024-09-08T12:31:35.581036Z","shell.execute_reply.started":"2024-09-08T12:31:35.574933Z","shell.execute_reply":"2024-09-08T12:31:35.580042Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hedCXexeSxqB","outputId":"247ba528-fb2e-4d69-e300-408eb63d93dd","execution":{"iopub.status.busy":"2024-09-08T12:31:35.582454Z","iopub.execute_input":"2024-09-08T12:31:35.582876Z","iopub.status.idle":"2024-09-08T12:31:48.645792Z","shell.execute_reply.started":"2024-09-08T12:31:35.582828Z","shell.execute_reply":"2024-09-08T12:31:48.644675Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# take in args\nusewandb = ~args.nowandb\nusewandb = False\nif usewandb:\n    import wandb\n    watermark = \"{}_lr{}\".format(args.net, args.lr)\n    wandb.init(project=\"cifar10-challange\",\n            name=watermark)\n    wandb.config.update(args)\n\nbs = int(args.bs)\nimsize = int(args.size)\n\nuse_amp = not args.noamp\naug = args.noaug\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\nif args.net==\"vit_timm\":\n    size = 384\nelse:\n    size = imsize\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize(size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Add RandAugment with N, M(hyperparameter)\nif aug:\n    N = 2; M = 14;\n    transform_train.transforms.insert(0, RandAugment(N, M))\n    \nprint(\"ready to fetch data\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"qnyCPg0HSxqB","outputId":"f6b2c294-26d0-4eaf-aede-2eb3a3c436b9","execution":{"iopub.status.busy":"2024-09-08T12:31:48.647462Z","iopub.execute_input":"2024-09-08T12:31:48.648339Z","iopub.status.idle":"2024-09-08T12:31:48.705973Z","shell.execute_reply.started":"2024-09-08T12:31:48.648291Z","shell.execute_reply":"2024-09-08T12:31:48.704864Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"==> Preparing data..\nready to fetch data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### loading cifar 100","metadata":{"execution":{"iopub.status.busy":"2024-09-08T11:42:51.856499Z","iopub.execute_input":"2024-09-08T11:42:51.857228Z","iopub.status.idle":"2024-09-08T11:42:51.866843Z","shell.execute_reply.started":"2024-09-08T11:42:51.857190Z","shell.execute_reply":"2024-09-08T11:42:51.865688Z"}}},{"cell_type":"code","source":"bs","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:48.707436Z","iopub.execute_input":"2024-09-08T12:31:48.707842Z","iopub.status.idle":"2024-09-08T12:31:48.716208Z","shell.execute_reply.started":"2024-09-08T12:31:48.707798Z","shell.execute_reply":"2024-09-08T12:31:48.715162Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    datasetname = 'cifar10-python'\n    datasetcode = 'pankrzysiu/cifar10-python'\nelif DATASET == 'CIFAR100':\n    datasetname = 'cifar100'\n    datasetcode = 'fedesoriano/cifar100'\n!kaggle datasets download -d {datasetcode}","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:48.717246Z","iopub.execute_input":"2024-09-08T12:31:48.717570Z","iopub.status.idle":"2024-09-08T12:31:51.136153Z","shell.execute_reply.started":"2024-09-08T12:31:48.717525Z","shell.execute_reply":"2024-09-08T12:31:51.135006Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/fedesoriano/cifar100\nLicense(s): copyright-authors\nDownloading cifar100.zip to /kaggle/working\n 95%|███████████████████████████████████████  | 153M/161M [00:00<00:00, 274MB/s]\n100%|█████████████████████████████████████████| 161M/161M [00:00<00:00, 282MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:51.137614Z","iopub.execute_input":"2024-09-08T12:31:51.137945Z","iopub.status.idle":"2024-09-08T12:31:51.142954Z","shell.execute_reply.started":"2024-09-08T12:31:51.137911Z","shell.execute_reply":"2024-09-08T12:31:51.141576Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Unzip the dataset\nwith zipfile.ZipFile(f'{datasetname}.zip', 'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working/dataset')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:51.144191Z","iopub.execute_input":"2024-09-08T12:31:51.144465Z","iopub.status.idle":"2024-09-08T12:31:52.456159Z","shell.execute_reply.started":"2024-09-08T12:31:51.144436Z","shell.execute_reply":"2024-09-08T12:31:52.455171Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class CIFAR10Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # CIFAR-10 images have 3 channels (RGB) and size 32x32\n        self.img_channels = 3\n        self.img_height = 32\n        self.img_width = 32\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        # Reshape the flattened image (3072) into (3, 32, 32) format\n        img = img.reshape(self.img_channels, self.img_height, self.img_width)\n\n        # Convert to PIL Image format (HxWxC)\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n\ndef unpickle(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n\ndef load_cifar10_data(data_path):\n    \"\"\" Load all CIFAR-10 data batches and return combined data and labels \"\"\"\n    train_data = []\n    train_labels = []\n\n    # CIFAR-10 contains 5 training batches\n    for i in range(1, 6):\n        batch = unpickle(f\"{data_path}/data_batch_{i}\")\n        train_data.append(batch[b'data'])\n        train_labels.extend(batch[b'labels'])\n\n    # Convert to numpy arrays\n    train_data = np.concatenate(train_data, axis=0)\n    train_labels = np.array(train_labels)\n\n    # Load test data\n    test_batch = unpickle(f\"{data_path}/test_batch\")\n    test_data = test_batch[b'data']\n    test_labels = np.array(test_batch[b'labels'])\n\n    return (train_data, train_labels), (test_data, test_labels)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:52.457525Z","iopub.execute_input":"2024-09-08T12:31:52.457874Z","iopub.status.idle":"2024-09-08T12:31:52.469402Z","shell.execute_reply.started":"2024-09-08T12:31:52.457840Z","shell.execute_reply":"2024-09-08T12:31:52.468409Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CIFAR100Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # Determine image dimensions from the first sample\n        sample_img = self.data[0]  # Get the first image sample\n        self.img_channels = 3  # CIFAR-100 images are RGB\n\n        # The image is flattened, so we need to infer the correct shape.\n        self.img_height, self.img_width = self._get_image_dimensions(sample_img)\n\n    def _get_image_dimensions(self, img_flat):\n        # Assuming CIFAR-100 with known number of channels (3)\n        num_pixels = img_flat.size // self.img_channels\n        side = int(np.sqrt(num_pixels))  # CIFAR-100 images are square (32x32)\n        return side, side\n\n    def _reshape_image(self, img_flat):\n        # Try reshaping based on typical formats CxHxW or HxWxC\n        try:\n            img = img_flat.reshape(self.img_channels, self.img_height, self.img_width)  # CxHxW\n        except ValueError:\n            img = img_flat.reshape(self.img_height, self.img_width, self.img_channels)  # HxWxC\n        return img\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        img = self._reshape_image(img)\n\n        # Handle case where image is in HxWxC (common in numpy arrays)\n        if img.shape[0] == self.img_height:  # HxWxC format\n            img = img.transpose(2, 0, 1)  # Convert to CxHxW\n\n        # Convert numpy array to PIL image for transformations\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')  # Convert CxHxW to HxWxC for PIL\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.402732Z","iopub.execute_input":"2024-09-08T12:32:24.403150Z","iopub.status.idle":"2024-09-08T12:32:24.414570Z","shell.execute_reply.started":"2024-09-08T12:32:24.403111Z","shell.execute_reply":"2024-09-08T12:32:24.413616Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.499521Z","iopub.execute_input":"2024-09-08T12:32:24.499827Z","iopub.status.idle":"2024-09-08T12:32:24.503742Z","shell.execute_reply.started":"2024-09-08T12:32:24.499796Z","shell.execute_reply":"2024-09-08T12:32:24.502674Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    \n    # Load CIFAR-10 data\n    data_path = '/kaggle/working/dataset/cifar-10-batches-py'  # Update path as necessary\n    (train_data, train_labels), (test_data, test_labels) = load_cifar10_data(data_path)\n\n    # Prepare datasets\n    trainset = CIFAR10Custom(data=train_data, labels=train_labels, transform=transform_train)\n    testset = CIFAR10Custom(data=test_data, labels=test_labels, transform=transform_test)\n\n    \nelif DATASET == 'CIFAR100':\n    \n\n    # Prepare dataset\n    data_pre_path = '/kaggle/working/dataset'\n    metadata_path = data_pre_path + '/meta'\n    data_train_path = data_pre_path + '/train'\n    data_test_path = data_pre_path + '/test'\n\n    def unpickle(file):\n        import pickle\n        with open(file, 'rb') as fo:\n            data_dict = pickle.load(fo, encoding='bytes')\n        return data_dict\n\n    metadata = unpickle(metadata_path)\n    data_train_dict = unpickle(data_train_path)\n    data_test_dict = unpickle(data_test_path)\n\n    data_train = data_train_dict[b'data']\n    label_train = np.array(data_train_dict[b'coarse_labels'])\n    data_test = data_test_dict[b'data']\n    label_test = np.array(data_test_dict[b'coarse_labels'])\n\n    # Prepare datasets\n    trainset = CIFAR100Custom(data=data_train, labels=label_train, transform=transform_train)\n    testset = CIFAR100Custom(data=data_test, labels=label_test, transform=transform_test)\n\n# DataLoader\nbatch_size = bs  # Adjust batch size as needed\nnum_workers = 4  # Adjust number of workers as needed\n\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\nprint(\"DataLoader prepared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.511203Z","iopub.execute_input":"2024-09-08T12:32:24.511762Z","iopub.status.idle":"2024-09-08T12:32:24.806661Z","shell.execute_reply.started":"2024-09-08T12:32:24.511730Z","shell.execute_reply":"2024-09-08T12:32:24.805589Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"DataLoader prepared.\n","output_type":"stream"}]},{"cell_type":"code","source":"# r1 is None","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.927873Z","iopub.execute_input":"2024-09-08T12:32:34.928727Z","iopub.status.idle":"2024-09-08T12:32:34.932717Z","shell.execute_reply.started":"2024-09-08T12:32:34.928683Z","shell.execute_reply":"2024-09-08T12:32:34.931689Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"i1, l1  = None, None","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.934764Z","iopub.execute_input":"2024-09-08T12:32:34.935374Z","iopub.status.idle":"2024-09-08T12:32:34.941430Z","shell.execute_reply.started":"2024-09-08T12:32:34.935326Z","shell.execute_reply":"2024-09-08T12:32:34.940688Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for images, labels in trainloader:\n    # Get the first image and label from the batch\n    print(1)\n    i1 = images\n    l1 = labels\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.942683Z","iopub.execute_input":"2024-09-08T12:32:34.943226Z","iopub.status.idle":"2024-09-08T12:32:36.649101Z","shell.execute_reply.started":"2024-09-08T12:32:34.943191Z","shell.execute_reply":"2024-09-08T12:32:36.648019Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"i1.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.651721Z","iopub.execute_input":"2024-09-08T12:32:36.652051Z","iopub.status.idle":"2024-09-08T12:32:36.658478Z","shell.execute_reply.started":"2024-09-08T12:32:36.652017Z","shell.execute_reply":"2024-09-08T12:32:36.657659Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"torch.Size([512, 3, 32, 32])"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n\n# # Assuming you have a tensor of shape [3, 32, 32]\n# # Create a random tensor for demonstration purposes\n# image_tensor = i1[15]\n\n# # Convert the tensor from [C, H, W] to [H, W, C] for displaying\n# image_np = image_tensor.permute(1, 2, 0).numpy()\n\n# # Plot the image\n# plt.imshow(image_np)\n# plt.axis('off')  # Turn off the axis labels\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.659777Z","iopub.execute_input":"2024-09-08T12:32:36.660110Z","iopub.status.idle":"2024-09-08T12:32:36.666677Z","shell.execute_reply.started":"2024-09-08T12:32:36.660077Z","shell.execute_reply":"2024-09-08T12:32:36.665652Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# # Prepare dataset\n# print(\"Loading dataset from kaggle/input\")\n# trainset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/train', transform=transform_train)\n# testset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/test', transform=transform_test)\n\n# print(\"Loading dataset\")\n# trainloader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.667905Z","iopub.execute_input":"2024-09-08T12:32:36.668318Z","iopub.status.idle":"2024-09-08T12:32:36.679140Z","shell.execute_reply.started":"2024-09-08T12:32:36.668272Z","shell.execute_reply":"2024-09-08T12:32:36.678267Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# len(trainset)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.680301Z","iopub.execute_input":"2024-09-08T12:32:36.680610Z","iopub.status.idle":"2024-09-08T12:32:36.686750Z","shell.execute_reply.started":"2024-09-08T12:32:36.680577Z","shell.execute_reply":"2024-09-08T12:32:36.685949Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# NUM_WORKERS = 4\n# cifar100_path = '/kaggle/input/cifar100'\n# # Prepare dataset\n\n# # trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n\n# # testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n# import torchvision\n# import torch\n# import torch.nn as nnn\n\n\n\n# # Prepare dataset based on hyperparameter\n# print(\"downloading dataset\")\n# if DATASET == 'CIFAR10':\n#     trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n    \n# elif DATASET == 'CIFAR100':\n#     if NUM_CLASSES%20 != 0 :\n#         raise ValueError(\"Invalid value of NUM_CLASSES specified. Choose 20 or 100\")\n#     trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n# else:\n#     raise ValueError(\"Invalid dataset specified. Choose 'CIFAR10' or 'CIFAR100'.\")\n    \n# print(\"loading dataset\")\n# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.687983Z","iopub.execute_input":"2024-09-08T12:32:36.688285Z","iopub.status.idle":"2024-09-08T12:32:36.695548Z","shell.execute_reply.started":"2024-09-08T12:32:36.688254Z","shell.execute_reply":"2024-09-08T12:32:36.694602Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use only this token :\n# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe #aster","metadata":{"id":"V-X21wSpSxqB","execution":{"iopub.status.busy":"2024-09-08T12:32:36.698954Z","iopub.execute_input":"2024-09-08T12:32:36.699266Z","iopub.status.idle":"2024-09-08T12:32:36.705530Z","shell.execute_reply.started":"2024-09-08T12:32:36.699236Z","shell.execute_reply":"2024-09-08T12:32:36.704655Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUzFJatHSxqB","outputId":"3a5a3505-936f-4461-b40a-fc75c7fb4f98","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remapping labels if needed","metadata":{}},{"cell_type":"code","source":"# if NUM_CLASSES == 20:\n#     # Create custom dataset class to remap labels\n\n\n#     # Create custom datasets with remapped labels\n#     trainset = CustomDataset(trainset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n#     testset = CustomDataset(testset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.706997Z","iopub.execute_input":"2024-09-08T12:32:36.707392Z","iopub.status.idle":"2024-09-08T12:32:36.712172Z","shell.execute_reply.started":"2024-09-08T12:32:36.707351Z","shell.execute_reply":"2024-09-08T12:32:36.711335Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.713269Z","iopub.execute_input":"2024-09-08T12:32:36.713977Z","iopub.status.idle":"2024-09-08T12:32:36.719305Z","shell.execute_reply.started":"2024-09-08T12:32:36.713933Z","shell.execute_reply":"2024-09-08T12:32:36.718389Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# For Multi-GPU\nif 'cuda' in device:\n    print(device)\n    if args.dp:\n        print(\"using data parallel\")\n        net = torch.nn.DataParallel(net) # make parallel\n        cudnn.benchmark = True\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUqsuNN8SxqB","outputId":"0a2d5706-2adf-45db-d903-f74316ec1faa","execution":{"iopub.status.busy":"2024-09-08T12:32:36.720524Z","iopub.execute_input":"2024-09-08T12:32:36.721300Z","iopub.status.idle":"2024-09-08T12:32:36.729619Z","shell.execute_reply.started":"2024-09-08T12:32:36.721268Z","shell.execute_reply":"2024-09-08T12:32:36.728765Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"ycedpM59zTyh","outputId":"aa2b13bb-b636-44c7-9b7d-b2f2880470da","execution":{"iopub.status.busy":"2024-09-08T12:32:36.730610Z","iopub.execute_input":"2024-09-08T12:32:36.730913Z","iopub.status.idle":"2024-09-08T12:32:37.740040Z","shell.execute_reply.started":"2024-09-08T12:32:36.730882Z","shell.execute_reply":"2024-09-08T12:32:37.738758Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"\ndef get_vit():\n    return ViT(\n    image_size = size,\n    patch_size = args.patch,\n    # num_classes = 10,\n    num_classes = NUM_CLASSES,\n    dim = int(args.dimhead),\n    depth = 6,\n    # heads = 8,\n    heads = NUM_HEADS,\n    # mlp_dim = 512,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    )","metadata":{"id":"ygIfkREcrvX7","execution":{"iopub.status.busy":"2024-09-08T12:32:37.741774Z","iopub.execute_input":"2024-09-08T12:32:37.742110Z","iopub.status.idle":"2024-09-08T12:32:37.747771Z","shell.execute_reply.started":"2024-09-08T12:32:37.742075Z","shell.execute_reply":"2024-09-08T12:32:37.746896Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model factory..\nprint('==> Building model..')\n# net = VGG('VGG19')\nif args.net==\"vit\":\n    # ViT for cifar10\n    net = get_vit()\n\n\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ND8qhixnSxqB","outputId":"e6edb544-3753-446e-ae32-03a9ab15df36","execution":{"iopub.status.busy":"2024-09-08T12:32:37.749152Z","iopub.execute_input":"2024-09-08T12:32:37.749774Z","iopub.status.idle":"2024-09-08T12:32:37.831523Z","shell.execute_reply.started":"2024-09-08T12:32:37.749730Z","shell.execute_reply":"2024-09-08T12:32:37.830668Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"nc4jNV-bSxqC","execution":{"iopub.status.busy":"2024-09-08T12:32:37.832693Z","iopub.execute_input":"2024-09-08T12:32:37.833454Z","iopub.status.idle":"2024-09-08T12:32:37.837664Z","shell.execute_reply.started":"2024-09-08T12:32:37.833409Z","shell.execute_reply":"2024-09-08T12:32:37.836840Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"\nlen(trainloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8emZ75LWcpgE","outputId":"5423fb4a-63af-4ffb-a027-899ae0d60136","execution":{"iopub.status.busy":"2024-09-08T12:32:37.838683Z","iopub.execute_input":"2024-09-08T12:32:37.838969Z","iopub.status.idle":"2024-09-08T12:32:37.847064Z","shell.execute_reply.started":"2024-09-08T12:32:37.838938Z","shell.execute_reply":"2024-09-08T12:32:37.846282Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"98"},"metadata":{}}]},{"cell_type":"code","source":"\n# trainloader[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"GCKRyskOugE5","outputId":"32f19894-9636-4bac-b61a-6db4237f6da5","execution":{"iopub.status.busy":"2024-09-08T12:32:37.848278Z","iopub.execute_input":"2024-09-08T12:32:37.848939Z","iopub.status.idle":"2024-09-08T12:32:37.854099Z","shell.execute_reply.started":"2024-09-08T12:32:37.848893Z","shell.execute_reply":"2024-09-08T12:32:37.853195Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# MAX_EPOCHS = 90\nMAX_EPOCHS = 200","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:37.855064Z","iopub.execute_input":"2024-09-08T12:32:37.855322Z","iopub.status.idle":"2024-09-08T12:32:37.861484Z","shell.execute_reply.started":"2024-09-08T12:32:37.855293Z","shell.execute_reply":"2024-09-08T12:32:37.860745Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Loss is CE\ncriterion = nn.CrossEntropyLoss()\n\ntorch.manual_seed(42)\nnet = get_vit()\n\nif args.opt == \"adam\":\n    optimizer = optim.Adam(net.parameters(), lr=args.lr)\nelif args.opt == \"sgd\":\n    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n\n# use cosine scheduling\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n\n##### Training\nscaler = torch.amp.GradScaler('cuda',enabled=use_amp)\ndef train(epoch,save_flag, run_dir = None, img_idx = None):\n    \n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    # img_factor = len(trainloader) // img_save_count\n    # run_dir = os.path.join(run_dir,  {epoch:02}\")\n\n    # data_save=list()\n    # main_list=list()\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # Train with amp\n        with torch.amp.autocast('cuda',enabled=use_amp):\n            # if(save_flag==True and batch_idx%img_factor==0):\n\n            if(save_flag==True and batch_idx==0):\n                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n                os.makedirs(batch_dir, exist_ok=True)\n                # np.save(file_path, np_array)\n                # print(\"\\n\\tpassed \",batch_dir, type(batch_dir))\n\n                outputs = net(inputs, True, batch_dir, img_idx)\n                # outputs = net(inputs, False, 12)\n                #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n            else:\n                outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    # data_save.append(net.transformer.saved_values)\n\n#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n#     return train_loss/(batch_idx+1),net.transformer.saved_values\n    return train_loss/(batch_idx+1)\n##### Validation\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n#     if acc > best_acc:\n#         print('Saving..')\n#         state = {\"model\": net.state_dict(),\n#               \"optimizer\": optimizer.state_dict(),\n#               \"scaler\": scaler.state_dict()}\n#         if not os.path.isdir('checkpoint'):\n#             os.mkdir('checkpoint')\n#         torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n#         best_acc = acc\n\n#     os.makedirs(\"log\", exist_ok=True)\n\n    os.makedirs(\"results\", exist_ok=True)\n    os.makedirs(\"results/log\", exist_ok=True)\n    content = f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n    print(content)\n#     with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n#         appender.write(content + \"\\n\")\n    return test_loss, acc\n\nlist_loss = []\nlist_acc = []\n\nif usewandb:\n    wandb.watch(net)\n\n    \n\n# save_epochs-=1\nbatch_size = int(args.bs)\n# max_epochs = args.n_epochs\n\n\n\n\nif device == 'cuda':\n  net.cuda()\nmain_list=list()\ndata_save=list()\nn_param=5\n\nrun_dir = os.path.join(base_dir, f\"run {run_number:02}\")\nos.makedirs(run_dir, exist_ok=True)\nprint(\"Run number \",run_number)\n\n\n\n\n\n\nimport shutil\nfrom IPython.display import FileLink\n\n# Specify the directory you want to compress\ndirectory_name = run_dir\nzip_filename = f'{run_dir}.zip'\n\n\n\n\nrun_number += 1\n\nmax_epochs = MAX_EPOCHS\n\n# take_epoch_factor = \nimg_save_count = 50 #IMP\n\nimg_idx = torch.randperm(batch_size)[:img_save_count]\nimg_idx= img_idx.sort()[0]\nprint(\"chosen images are of batch 0 and numbers : \",[x.item() for x in list(img_idx)])\nfile_path = os.path.join(run_dir, 'img_idx.npy')\nnp.save(file_path, img_idx.detach().cpu().numpy())\n\n\n\n# save_epochs =  #IMP\n# epoch_factor = max_epochs  // save_epochs #IMP\n\nepoch_factor = 20 #IMP\npatience_param=500\npatience_counter=0\n\n\nprint(f\"Saving results every {epoch_factor} epochs \")\n\n\n\n\nprint(\"Training started\")\nfor i in tqdm(range(start_epoch, max_epochs), desc=\"Training\"):\n    epoch = i+1\n    start = time.time()\n    \n#     if(epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs):\n    if False:\n      # Define the new run directory\n        \n        epoch_dir = os.path.join(run_dir, f\"epoch {epoch:02}\")\n        # print(\"\\n\\tpassed into trainloss\",run_dir)\n        trainloss = train(epoch,True, run_dir = epoch_dir, img_idx = img_idx)\n        print(\"saved epoch\")\n        # Compress the directory into a zip file, overwriting if it already exists\n        shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n        print(\"Click here to download run  : \")\n        display(FileLink(zip_filename))\n    \n    else:\n        trainloss = train(epoch,False)\n\n\n\n#     if(epoch%n_param!=0 or epoch==0):\n#         data_save.append(saved_data)\n#     else:\n#         data_save.append(saved_data)\n#         main_list.append(data_save)\n#         data_save=list()\n#     val_loss, acc = test(epoch)\n\n    scheduler.step() # step cosine scheduling\n\n\n    '''\n    # Early stopping logic\n    best_loss = float('inf')  # Initialize best loss to a high value\n    val_loss, acc = test(epoch)\n    \n    if val_loss < best_loss:\n        best_loss = val_loss\n        patience_counter = 0  # Reset patience counter if loss improves\n\n    else:\n        patience_counter += 1  # Increment patience counter if no improvement\n\n    # If patience limit is exceeded, stop training\n    if patience_counter >= patience_param:\n        save_model_state(net, epoch , val_loss, acc)\n        print(f'Early stopping at epoch {epoch} due to no improvement')\n\n        break  ## we break out of training loop after saving the model\n     '''\n\n    if (epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs and MODEL_SAVE_FLAG):\n        \n        \n        val_loss, acc = test(epoch)\n        save_model_state(net, epoch , val_loss, acc)\n        \n\n#     list_loss.append(val_loss)\n#     list_acc.append(acc)\n\n    # Log training..\n#     if usewandb:\n#         wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n#         \"epoch_time\": time.time()-start})\n\n#     # Write out csv..\n#     with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n#         writer = csv.writer(f, lineterminator='\\n')\n#         writer.writerow(list_loss)\n#         writer.writerow(list_acc)\n# #     print(list_loss)\n    print()\n    \n# writeout wandb\nif usewandb:\n    wandb.save(\"wandb_{}.h5\".format(args.net))\n\nimport shutil\nfrom IPython.display import FileLink\nzip_filename = 'checkpoints.zip'\ndirectory_name = 'checkpoints'\nshutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\nprint(\"Click here to download checkpoints  : \")\ndisplay(FileLink(zip_filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":636},"id":"O1brRsc3SxqH","outputId":"062f1e66-7ad7-49f8-fb09-27f797a6909c","execution":{"iopub.status.busy":"2024-09-08T12:32:37.862745Z","iopub.execute_input":"2024-09-08T12:32:37.863059Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Run number  1\nchosen images are of batch 0 and numbers :  [7, 31, 33, 38, 45, 57, 58, 59, 60, 98, 118, 126, 131, 135, 139, 141, 142, 143, 147, 155, 162, 184, 209, 219, 233, 245, 252, 280, 286, 296, 310, 327, 349, 351, 357, 365, 368, 399, 411, 422, 424, 425, 431, 442, 452, 457, 463, 481, 482, 502]\nSaving results every 20 epochs \nTraining started\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Specify the path to your file\nfile_path = 'checkpoints.zip'\n\n# Get the size of the file in bytes\nfile_size = os.path.getsize(file_path)\n\nprint(f\"The size of the file is : {(file_size/(2**20)):.0f} MB\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raise ZeroDivisionError","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd data\n!ls\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf results\n# !rm -rf log\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_idx.detach().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# from IPython.display import FileLink\n\n# # Specify the directory you want to compress\n# directory_name = 'log'\n# zip_filename = 'log.zip'\n\n# # Compress the directory into a zip file, overwriting if it already exists\n# shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n# # Optionally generate and display a download link\n# print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n# FileLink(zip_filename)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"e1RV3ub4bzaF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnet","metadata":{"id":"n5yDPk01T0oL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n/content/results/runs/run 04/epoch 00/batch 0/layer 01","metadata":{"id":"c61Jvkt9v1cj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9sDNpPTSxqI","outputId":"802a6209-4de8-4ac2-e0c7-37c20468a8bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Define the directory path you want to check\ndirectory_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/'\n\n# Check if the directory exists\nif os.path.isdir(directory_path):\n    print(f\"The directory '{directory_path}' exists.\")\nelse:\n    print(f\"The directory '{directory_path}' does not exist.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq9FNrXywIbb","outputId":"db92a1f9-34a2-49a1-8f61-f9e0750ec05d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/01_attention_out.npy'\n\n# Load the NumPy array from the file\ndata = np.load(file_path)","metadata":{"id":"d2GSp2wbSxqI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlFIzQIUSxqI","outputId":"5dce6a00-7620-4944-8d0d-6ccaa42668e6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.shape\n# shape : batch x head x X x Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr5wj-at0UJo","outputId":"874907d1-f72d-45f6-f805-8623093c5a0b","trusted":true},"execution_count":null,"outputs":[]}]}