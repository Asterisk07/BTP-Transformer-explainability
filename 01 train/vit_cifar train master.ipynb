{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Define hyperparameters"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:14.578132Z","iopub.status.busy":"2024-09-07T09:34:14.577698Z","iopub.status.idle":"2024-09-07T09:34:14.590673Z","shell.execute_reply":"2024-09-07T09:34:14.589358Z","shell.execute_reply.started":"2024-09-07T09:34:14.578086Z"},"trusted":true},"outputs":[],"source":["\n","# Dataset options\n","DATASET = 'CIFAR100'  # Options: 'CIFAR10' or 'CIFAR100'\n","# DATASET = 'CIFAR10'\n","\n","# Number of classes options\n","NUM_CLASSES = 20     # Set the number of classes\n","# NUM_CLASSES = 10   # For example, if using CIFAR-10, set to 10\n","\n","# Number of attention heads options\n","NUM_HEADS = 8        # Options: 8, 4, 2, etc.\n","# NUM_HEADS = 4\n","# NUM_HEADS = 2"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:14.593337Z","iopub.status.busy":"2024-09-07T09:34:14.592848Z","iopub.status.idle":"2024-09-07T09:34:14.607407Z","shell.execute_reply":"2024-09-07T09:34:14.606258Z","shell.execute_reply.started":"2024-09-07T09:34:14.593292Z"},"trusted":true},"outputs":[],"source":["def validate_hyperparameters(dataset_name, num_classes, num_heads):\n","    \"\"\"\n","    Validates the hyperparameters for dataset, number of classes, and number of attention heads.\n","\n","    Args:\n","        dataset_name (str): The name of the dataset ('CIFAR10' or 'CIFAR100').\n","        num_classes (int): The number of classes.\n","        num_heads (int): The number of attention heads.\n","\n","    Raises:\n","        ValueError: If any hyperparameter is invalid.\n","    \"\"\"\n","    valid_datasets = ['CIFAR10', 'CIFAR100']\n","    if dataset_name not in valid_datasets:\n","        raise ValueError(f\"Invalid DATASET value: {dataset_name}. Choose from {valid_datasets}.\")\n","\n","    if dataset_name == 'CIFAR10' and num_classes != 10:\n","        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 10. Current value: {num_classes}.\")\n","    elif dataset_name == 'CIFAR100' and num_classes not in [20, 100]:\n","        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 20 or 100. Current value: {num_classes}.\")\n","\n","    valid_heads = [8, 4, 2]\n","    if num_heads not in valid_heads:\n","        raise ValueError(f\"Invalid NUM_HEADS value: {num_heads}. Choose from {valid_heads}.\")"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:14.611101Z","iopub.status.busy":"2024-09-07T09:34:14.610697Z","iopub.status.idle":"2024-09-07T09:34:14.616146Z","shell.execute_reply":"2024-09-07T09:34:14.615033Z","shell.execute_reply.started":"2024-09-07T09:34:14.611062Z"},"trusted":true},"outputs":[],"source":["\n","# Validate hyperparameters\n","validate_hyperparameters(DATASET, NUM_CLASSES, NUM_HEADS)\n"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:14.617840Z","iopub.status.busy":"2024-09-07T09:34:14.617522Z","iopub.status.idle":"2024-09-07T09:34:20.815189Z","shell.execute_reply":"2024-09-07T09:34:20.814226Z","shell.execute_reply.started":"2024-09-07T09:34:14.617805Z"},"trusted":true},"outputs":[],"source":["import torchvision\n","import torch\n","import torch.nn as nn\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Initial Setup"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:35.845172Z","iopub.status.busy":"2024-09-07T09:34:35.844766Z","iopub.status.idle":"2024-09-07T09:34:36.234586Z","shell.execute_reply":"2024-09-07T09:34:36.233739Z","shell.execute_reply.started":"2024-09-07T09:34:35.845132Z"},"id":"Llt_Ire4Sxp2","trusted":true},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","'''\n","\n","Train CIFAR10 with PyTorch and Vision Transformers!\n","written by @kentaroy47, @arutema47\n","source : https://github.com/kentaroy47/vision-transformers-cifar10\n","\n","'''\n","\n","from __future__ import print_function\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n","import pandas as pd\n","import csv\n","import time\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Helper functions"]},{"cell_type":"markdown","metadata":{},"source":["#### Saving loading"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:36.237100Z","iopub.status.busy":"2024-09-07T09:34:36.236539Z","iopub.status.idle":"2024-09-07T09:34:36.247108Z","shell.execute_reply":"2024-09-07T09:34:36.246138Z","shell.execute_reply.started":"2024-09-07T09:34:36.237053Z"},"trusted":true},"outputs":[],"source":["import torch\n","import os\n","\n","def save_model_state(model, epoch, loss, accuracy, checkpoint_dir='checkpoints', log_file='training_log.txt'):\n","    # Create checkpoint directory if it doesn't exist\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    \n","    # Save model state\n","    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n","    torch.save(model.state_dict(), model_checkpoint_path)\n","    print(f'Model state saved at epoch {epoch}')\n","    \n","    # Log accuracy and loss\n","    log_file_path = os.path.join(checkpoint_dir, log_file)\n","    \n","    with open(log_file_path, 'a') as f:\n","        f.write(f'Epoch {epoch}: Accuracy = {accuracy:.4f}, Loss = {loss:.4f}\\n')\n","    \n","    print(f'Logged epoch {epoch} - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}')\n","\n","    \n","import torch\n","import os\n","\n","def load_model_state(model, epoch = 90, checkpoint_dir='checkpoints'):\n","    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n","    model.load_state_dict(torch.load(model_checkpoint_path))   \n","    print(f'Model state loaded from epoch {epoch}')\n","    return epoch\n","\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:36.248677Z","iopub.status.busy":"2024-09-07T09:34:36.248318Z","iopub.status.idle":"2024-09-07T09:34:36.257577Z","shell.execute_reply":"2024-09-07T09:34:36.256603Z","shell.execute_reply.started":"2024-09-07T09:34:36.248619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory does not exist\n"]}],"source":["import os\n","\n","directory = 'checkpoints'\n","\n","if os.path.isdir(directory):\n","    print(\"Directory exists\")\n","    items = os.listdir(directory)\n","    for item in items:\n","        print(item)\n","else:\n","    print(\"Directory does not exist\")\n","    \n","#     if os.path.isdir(directory):\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["#### Remapping labels function"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:34:36.259312Z","iopub.status.busy":"2024-09-07T09:34:36.258938Z","iopub.status.idle":"2024-09-07T09:34:36.268147Z","shell.execute_reply":"2024-09-07T09:34:36.267211Z","shell.execute_reply.started":"2024-09-07T09:34:36.259275Z"},"trusted":true},"outputs":[],"source":["def remap_labels(labels, num_classes_old, num_classes_new):\n","    \"\"\"\n","    Adjusts the labels from an old class structure to a new one.\n","\n","    Args:\n","        labels (torch.Tensor or list): Original labels to be adjusted.\n","        num_classes_old (int): The number of classes in the original dataset.\n","        num_classes_new (int): The number of classes in the new dataset.\n","\n","    Returns:\n","        torch.Tensor or list: The labels adjusted to the new class structure.\n","    \"\"\"\n","    # Check that the number of old classes is divisible by the number of new classes\n","    assert num_classes_old % num_classes_new == 0, \"The number of old classes must be divisible by the number of new classes.\"\n","\n","    # Compute the factor to convert old labels to new labels\n","    factor = num_classes_old // num_classes_new\n","\n","    # Remap each label\n","    if isinstance(labels, torch.Tensor):\n","        # If labels are a tensor, apply the remapping to each label and return a tensor\n","        remapped_labels = torch.tensor([label.item() // factor for label in labels])\n","    else:\n","        # If labels are a list, apply the remapping to each label and return a list\n","        remapped_labels = [label // factor for label in labels]\n","    \n","    return remapped_labels\n"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:25.389664Z","iopub.status.busy":"2024-09-07T09:35:25.389088Z","iopub.status.idle":"2024-09-07T09:35:25.398145Z","shell.execute_reply":"2024-09-07T09:35:25.396924Z","shell.execute_reply.started":"2024-09-07T09:35:25.389617Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, dataset, num_classes_old, num_classes_new):\n","        self.dataset = dataset\n","        self.num_classes_old = num_classes_old\n","        self.num_classes_new = num_classes_new\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        image, label = self.dataset[index]\n","        remapped_label = remap_labels(torch.tensor([label]), self.num_classes_old, self.num_classes_new).item()\n","        return image, remapped_label"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:25.400734Z","iopub.status.busy":"2024-09-07T09:35:25.400350Z","iopub.status.idle":"2024-09-07T09:35:25.415995Z","shell.execute_reply":"2024-09-07T09:35:25.414832Z","shell.execute_reply.started":"2024-09-07T09:35:25.400695Z"},"id":"MmxrO8v6Sxp5","trusted":true},"outputs":[],"source":["run_number = 1\n","base_dir = \"results/runs\"\n","\n","# Define the new run directory\n","\n","os.makedirs(\"results\", exist_ok=True)\n","os.makedirs(\"results/runs\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROEAX6L0Wf7D"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:25.418292Z","iopub.status.busy":"2024-09-07T09:35:25.417871Z","iopub.status.idle":"2024-09-07T09:35:25.436668Z","shell.execute_reply":"2024-09-07T09:35:25.435600Z","shell.execute_reply.started":"2024-09-07T09:35:25.418250Z"},"id":"0O9k1NsUWISs","outputId":"6b67a80e-f9d1-43af-ebf4-3088aa41efd0","trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x10fc51d70>"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(42)"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:25.439592Z","iopub.status.busy":"2024-09-07T09:35:25.439163Z","iopub.status.idle":"2024-09-07T09:35:25.444526Z","shell.execute_reply":"2024-09-07T09:35:25.443418Z","shell.execute_reply.started":"2024-09-07T09:35:25.439550Z"},"id":"aa7zHkXPSxp5","trusted":true},"outputs":[],"source":["# # setup for a read only personal access token\n","# # note : token expires 19 aug 2025\n","# token = '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'\n","# token_user = 'Asterisk07'\n","# repo_host = 'Asterisk07'\n","# repo_name = 'BTP-Transformer-explainability'\n","\n","# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n","# !git clone {url}\n","\n","# !mv {repo_name}/models .\n","# !rm -rf BTP-Transformer-explainability # delete a file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JfB6PgwoSxp6","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YF9tLt1iSxp6","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQR0IlVsSxp7","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:25.446447Z","iopub.status.busy":"2024-09-07T09:35:25.445971Z","iopub.status.idle":"2024-09-07T09:35:26.586073Z","shell.execute_reply":"2024-09-07T09:35:26.584312Z","shell.execute_reply.started":"2024-09-07T09:35:25.446378Z"},"id":"_Fnxx0KDSxp7","outputId":"c0015607-859a-4164-db22-8783ff70f8c1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34mresults\u001b[m\u001b[m                           vit_cifar train master.ipynb\n","\u001b[34mtrain_results\u001b[m\u001b[m                     vit_cifar train master_copy.ipynb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rO-x5w5QSxp8","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:26.588178Z","iopub.status.busy":"2024-09-07T09:35:26.587784Z","iopub.status.idle":"2024-09-07T09:35:26.594131Z","shell.execute_reply":"2024-09-07T09:35:26.592717Z","shell.execute_reply.started":"2024-09-07T09:35:26.588137Z"},"id":"aDRb-t5HSxp9","trusted":true},"outputs":[],"source":["# !rm -rf models"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:26.595970Z","iopub.status.busy":"2024-09-07T09:35:26.595600Z","iopub.status.idle":"2024-09-07T09:35:26.603559Z","shell.execute_reply":"2024-09-07T09:35:26.602608Z","shell.execute_reply.started":"2024-09-07T09:35:26.595888Z"},"id":"nyZGC9wISxp9","trusted":true},"outputs":[],"source":["# !npm install -g github-files-fetcher"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:26.606506Z","iopub.status.busy":"2024-09-07T09:35:26.604939Z","iopub.status.idle":"2024-09-07T09:35:26.612452Z","shell.execute_reply":"2024-09-07T09:35:26.611475Z","shell.execute_reply.started":"2024-09-07T09:35:26.606457Z"},"id":"XLQdzmZYSxp9","trusted":true},"outputs":[],"source":["# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n","# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:26.614140Z","iopub.status.busy":"2024-09-07T09:35:26.613781Z","iopub.status.idle":"2024-09-07T09:35:26.623957Z","shell.execute_reply":"2024-09-07T09:35:26.622895Z","shell.execute_reply.started":"2024-09-07T09:35:26.614102Z"},"id":"3ZPrL29xSxp9","outputId":"0cab9daf-2631-4d8f-ee64-1d51ccbdf40e","trusted":true},"outputs":[{"data":{"text/plain":["2"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0zItmyxSxp-","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:26.629319Z","iopub.status.busy":"2024-09-07T09:35:26.628823Z","iopub.status.idle":"2024-09-07T09:35:27.933914Z","shell.execute_reply":"2024-09-07T09:35:27.932544Z","shell.execute_reply.started":"2024-09-07T09:35:26.629279Z"},"id":"YSnJhbUCU4J9","outputId":"d466bf62-4b25-4a9b-d2f7-83213799ad8a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["utils.py does not exist in the current directory.\n","zsh:1: command not found: wget\n","utils.py fetched\n"]}],"source":["\n","import os\n","\n","# Check if 'utils.py' exists in the current directory\n","if os.path.exists('utils.py'):\n","    print(\"utils.py exists in the current directory.\")\n","else:\n","    print(\"utils.py does not exist in the current directory.\")\n","    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n","    print(\"utils.py fetched\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XLsXJxiSxp-","trusted":true},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:27.936463Z","iopub.status.busy":"2024-09-07T09:35:27.935925Z","iopub.status.idle":"2024-09-07T09:35:27.959400Z","shell.execute_reply":"2024-09-07T09:35:27.958206Z","shell.execute_reply.started":"2024-09-07T09:35:27.936407Z"},"id":"Pe1-pReSSxp-","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'utils'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m progress_bar\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"]}],"source":["from utils import progress_bar"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"execution":{"iopub.execute_input":"2024-09-07T09:35:27.961921Z","iopub.status.busy":"2024-09-07T09:35:27.961511Z","iopub.status.idle":"2024-09-07T09:35:27.969300Z","shell.execute_reply":"2024-09-07T09:35:27.968110Z","shell.execute_reply.started":"2024-09-07T09:35:27.961878Z"},"id":"_yVbM9QmSxp-","outputId":"2ebfb3d7-3459-40ed-c8a1-33e3839da492","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'progress_bar' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprogress_bar\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'progress_bar' is not defined"]}],"source":["progress_bar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlKjovnlSxp-","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:27.971790Z","iopub.status.busy":"2024-09-07T09:35:27.971156Z","iopub.status.idle":"2024-09-07T09:35:27.978898Z","shell.execute_reply":"2024-09-07T09:35:27.977863Z","shell.execute_reply.started":"2024-09-07T09:35:27.971734Z"},"id":"RGLFDHKiSxp_","trusted":true},"outputs":[],"source":["\n","\n","# from randomaug import RandAugment\n","from torchvision.transforms import RandAugment\n","\n"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:27.980686Z","iopub.status.busy":"2024-09-07T09:35:27.980281Z","iopub.status.idle":"2024-09-07T09:35:45.457027Z","shell.execute_reply":"2024-09-07T09:35:45.455637Z","shell.execute_reply.started":"2024-09-07T09:35:27.980646Z"},"id":"-rHHLarISxp_","outputId":"45997e81-9926-4465-d2dd-12835012d6b5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: pip\n"]}],"source":["!pip install einops"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.459347Z","iopub.status.busy":"2024-09-07T09:35:45.458931Z","iopub.status.idle":"2024-09-07T09:35:45.464897Z","shell.execute_reply":"2024-09-07T09:35:45.463637Z","shell.execute_reply.started":"2024-09-07T09:35:45.459306Z"},"id":"UsC7sE2cSxp_","trusted":true},"outputs":[],"source":["# from models import *\n","# from models.vit import ViT\n","# from models.convmixer import ConvMixer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJEMQtO5Upra"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.467091Z","iopub.status.busy":"2024-09-07T09:35:45.466601Z","iopub.status.idle":"2024-09-07T09:35:45.481526Z","shell.execute_reply":"2024-09-07T09:35:45.480278Z","shell.execute_reply.started":"2024-09-07T09:35:45.467037Z"},"id":"VJNDccCQe_XC","trusted":true},"outputs":[],"source":["\n","import json"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.483488Z","iopub.status.busy":"2024-09-07T09:35:45.483051Z","iopub.status.idle":"2024-09-07T09:35:45.492557Z","shell.execute_reply":"2024-09-07T09:35:45.491523Z","shell.execute_reply.started":"2024-09-07T09:35:45.483447Z"},"id":"WADSesO6g1ea","trusted":true},"outputs":[],"source":["\n","qkv_titles = ['q','k','v']"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.495761Z","iopub.status.busy":"2024-09-07T09:35:45.495379Z","iopub.status.idle":"2024-09-07T09:35:45.552686Z","shell.execute_reply":"2024-09-07T09:35:45.551416Z","shell.execute_reply.started":"2024-09-07T09:35:45.495721Z"},"id":"OzQdLRddSxp_","trusted":true},"outputs":[],"source":["# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n","# VIT.py\n","import torch\n","from torch import nn\n","\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","import numpy as np\n","# helpers\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","# classes\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n","        out =  self.net(x)\n","        if(save_flag==True):\n","                file_path = os.path.join(run_dir, 'ff_out.npy')\n","                # np.save(file_path, out)\n","                np.save(file_path, out[img_idx].detach().cpu().numpy())\n","        return out\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","\n","        inner_dim = dim_head *  heads\n","        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","\n","        out = torch.matmul(attn, v)\n","        if(save_flag==True):\n","\n","                # Convert each tensor in `qkv` to a numpy array and save it\n","#                 qkv=attention.to_qkv\n","                for i, tensor in enumerate((q,k,v)):\n","                    np_array = tensor[img_idx].detach().cpu().numpy()  # Convert to numpy\n","                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n","                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n","                    np.save(file_path, np_array)\n","                file_path = os.path.join(run_dir, 'att_out')\n","                np.save(file_path, out[img_idx].detach().cpu().numpy())\n","                file_path = os.path.join(run_dir, 'att_score')\n","                np.save(file_path,attn[img_idx].detach().cpu().numpy())\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        # return self.to_out(out),q,k,v\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","        super().__init__()\n","        # print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n","\n","        self.layers = nn.ModuleList([])\n","#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n","        # self.saved_values = list()  # To store th\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n","            ]))\n","\n","    def forward(self, x,save_flag=False, run_dir = None, img_idx = None):\n","        for i, (attn, ff) in enumerate(self.layers):\n","            # Unpack the output from the Attention layer\n","            #\n","            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n","            if save_flag:\n","              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n","              os.makedirs(layer_dir, exist_ok=True)\n","              # print(\"passed trans layer direcetory \", layer_dir)\n","            else:\n","              layer_dir = None\n","            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx)\n","\n","\n","\n","            # Save the query, key, value, and logits (output) for this layer\n","            # self.saved_values.append(q.cpu().detach().numpy())\n","            # self.saved_values.append(k.cpu().detach().numpy())\n","            # self.saved_values.append(v.cpu().detach().numpy())\n","\n","            # Combine the attention output with the original x\n","            x = attn_out + x\n","            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n","            # print(\"i : \",i)\n","            # Apply the feedforward network\n","#             x = ff(x) + x\n","\n","            x = ff(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx) + x\n","\n","        return x\n","\n","\n","class ViT(nn.Module):\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        # print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n","            nn.Linear(patch_dim, dim),\n","        )\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, img, save_flag=False, run_dir = None,img_idx = None):\n","        # if (save_flag):\n","          # print(\"\\n\\treached here 3\")\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x,save_flag, run_dir, img_idx)\n","#         if(save_flag==True):\n","#                 # Convert each tensor in `qkv` to a numpy array and save it\n","#                 qkv=attention.to_qkv\n","#                 for i, tensor in enumerate(qkv):\n","#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n","#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n","\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RskDA5B5zDv6","outputId":"85715f3b-73f8-4996-e0e8-b43df9b8dc08"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.554585Z","iopub.status.busy":"2024-09-07T09:35:45.554186Z","iopub.status.idle":"2024-09-07T09:35:45.565816Z","shell.execute_reply":"2024-09-07T09:35:45.564501Z","shell.execute_reply.started":"2024-09-07T09:35:45.554547Z"},"id":"GVdr58MRSxp_","trusted":true},"outputs":[],"source":["import argparse\n","import sys\n","\n","# Define your arguments here\n","def parse_args():\n","    # parsers\n","    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n","    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n","    parser.add_argument('--opt', default=\"adam\")\n","    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n","    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n","    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n","    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n","    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n","    parser.add_argument('--net', default='vit')\n","    parser.add_argument('--dp', action='store_true', help='use data parallel')\n","    parser.add_argument('--bs', default='512')\n","    parser.add_argument('--size', default=\"32\")\n","    parser.add_argument('--n_epochs', type=int, default='200')\n","    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n","    parser.add_argument('--dimhead', default=\"512\", type=int)\n","    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n","\n","    return parser.parse_args()\n","\n","\n"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:45.567949Z","iopub.status.busy":"2024-09-07T09:35:45.567520Z","iopub.status.idle":"2024-09-07T09:35:45.582525Z","shell.execute_reply":"2024-09-07T09:35:45.581252Z","shell.execute_reply.started":"2024-09-07T09:35:45.567907Z"},"id":"5JbxSOG5SxqA","outputId":"2c280127-8d9e-4cd0-fc27-3bc03c51d0f2","trusted":true},"outputs":[{"data":{"text/plain":["['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\n","command.split()[1:]"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.584436Z","iopub.status.busy":"2024-09-07T09:35:45.584004Z","iopub.status.idle":"2024-09-07T09:35:45.591377Z","shell.execute_reply":"2024-09-07T09:35:45.590368Z","shell.execute_reply.started":"2024-09-07T09:35:45.584395Z"},"id":"SFLk9RG5SxqA","trusted":true},"outputs":[],"source":["# Simulate command-line arguments\n","# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\n","sys.argv = command.split()[1:]\n","\n","args = parse_args()\n","\n"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.593186Z","iopub.status.busy":"2024-09-07T09:35:45.592800Z","iopub.status.idle":"2024-09-07T09:35:45.601381Z","shell.execute_reply":"2024-09-07T09:35:45.600392Z","shell.execute_reply.started":"2024-09-07T09:35:45.593146Z"},"id":"TZfQJlNKSxqA","trusted":true},"outputs":[],"source":["# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRdesLOdSxqA","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.603091Z","iopub.status.busy":"2024-09-07T09:35:45.602725Z","iopub.status.idle":"2024-09-07T09:35:45.611751Z","shell.execute_reply":"2024-09-07T09:35:45.610584Z","shell.execute_reply.started":"2024-09-07T09:35:45.603053Z"},"id":"xBdPskigSxqA","trusted":true},"outputs":[],"source":["# (2.0.1+cu117)\n","# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.613803Z","iopub.status.busy":"2024-09-07T09:35:45.613149Z","iopub.status.idle":"2024-09-07T09:35:45.622071Z","shell.execute_reply":"2024-09-07T09:35:45.620659Z","shell.execute_reply.started":"2024-09-07T09:35:45.613761Z"},"id":"uiDtWCYKSxqA","trusted":true},"outputs":[],"source":["# !pip show torchvision\n"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.624572Z","iopub.status.busy":"2024-09-07T09:35:45.624067Z","iopub.status.idle":"2024-09-07T09:35:45.635483Z","shell.execute_reply":"2024-09-07T09:35:45.634231Z","shell.execute_reply.started":"2024-09-07T09:35:45.624516Z"},"id":"_T0LacFUt74i","trusted":true},"outputs":[{"data":{"text/plain":["2"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["2"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:35:45.637072Z","iopub.status.busy":"2024-09-07T09:35:45.636716Z","iopub.status.idle":"2024-09-07T09:35:45.646166Z","shell.execute_reply":"2024-09-07T09:35:45.645062Z","shell.execute_reply.started":"2024-09-07T09:35:45.637033Z"},"id":"NRmD_dGiSxqA","trusted":true},"outputs":[],"source":["# !pip show torch\n","# #"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2024-09-07T09:35:45.647889Z","iopub.status.busy":"2024-09-07T09:35:45.647543Z","iopub.status.idle":"2024-09-07T09:35:45.658262Z","shell.execute_reply":"2024-09-07T09:35:45.657139Z","shell.execute_reply.started":"2024-09-07T09:35:45.647851Z"},"id":"m-UHnDboSxqA","outputId":"81f73c03-4a0e-490f-e36e-08f56d3b0124","trusted":true},"outputs":[{"data":{"text/plain":["'0.19.1'"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["import torchvision\n","torchvision.__version__"]},{"cell_type":"code","execution_count":97,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2024-09-07T09:35:45.671821Z","iopub.status.busy":"2024-09-07T09:35:45.671215Z","iopub.status.idle":"2024-09-07T09:35:45.680950Z","shell.execute_reply":"2024-09-07T09:35:45.679162Z","shell.execute_reply.started":"2024-09-07T09:35:45.671749Z"},"id":"aQh5PidkSxqA","outputId":"78297830-3ca1-42b2-fa0a-1b761d0e61fe","trusted":true},"outputs":[{"data":{"text/plain":["'2.4.1'"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:35:45.683307Z","iopub.status.busy":"2024-09-07T09:35:45.682775Z","iopub.status.idle":"2024-09-07T09:36:00.950656Z","shell.execute_reply":"2024-09-07T09:36:00.949406Z","shell.execute_reply.started":"2024-09-07T09:35:45.683249Z"},"id":"hedCXexeSxqB","outputId":"247ba528-fb2e-4d69-e300-408eb63d93dd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: pip\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"execution":{"iopub.execute_input":"2024-09-07T09:36:00.952684Z","iopub.status.busy":"2024-09-07T09:36:00.952302Z","iopub.status.idle":"2024-09-07T09:36:27.406560Z","shell.execute_reply":"2024-09-07T09:36:27.405290Z","shell.execute_reply.started":"2024-09-07T09:36:00.952646Z"},"id":"qnyCPg0HSxqB","outputId":"f6b2c294-26d0-4eaf-aede-2eb3a3c436b9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/mt/v2_z6xpn1znd6jckkrb8kpdw0000gn/T/ipykernel_1574/2630569884.py:2: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n","  usewandb = ~args.nowandb\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'wandb'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[99], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m usewandb \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39margs\u001b[38;5;241m.\u001b[39mnowandb\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usewandb:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     watermark \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_lr\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39mnet, args\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m      6\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar10-challange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m             name\u001b[38;5;241m=\u001b[39mwatermark)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"]}],"source":["\n","# take in args\n","usewandb = ~args.nowandb\n","if usewandb:\n","    import wandb\n","    watermark = \"{}_lr{}\".format(args.net, args.lr)\n","    wandb.init(project=\"cifar10-challange\",\n","            name=watermark)\n","    wandb.config.update(args)\n","\n","bs = int(args.bs)\n","imsize = int(args.size)\n","\n","use_amp = not args.noamp\n","aug = args.noaug\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","\n","# Data\n","print('==> Preparing data..')\n","if args.net==\"vit_timm\":\n","    size = 384\n","else:\n","    size = imsize\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.Resize(size),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(size),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Add RandAugment with N, M(hyperparameter)\n","if aug:\n","    N = 2; M = 14;\n","    transform_train.transforms.insert(0, RandAugment(N, M))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:27.411748Z","iopub.status.busy":"2024-09-07T09:36:27.411222Z","iopub.status.idle":"2024-09-07T09:36:27.418743Z","shell.execute_reply":"2024-09-07T09:36:27.417227Z","shell.execute_reply.started":"2024-09-07T09:36:27.411689Z"},"id":"V-X21wSpSxqB","trusted":true},"outputs":[],"source":["# use only this token :\n","# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe #aster"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:36:27.420792Z","iopub.status.busy":"2024-09-07T09:36:27.420320Z","iopub.status.idle":"2024-09-07T09:36:34.167337Z","shell.execute_reply":"2024-09-07T09:36:34.166130Z","shell.execute_reply.started":"2024-09-07T09:36:27.420739Z"},"id":"lUzFJatHSxqB","outputId":"3a5a3505-936f-4461-b40a-fc75c7fb4f98","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 169001437/169001437 [00:02<00:00, 63020183.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["NUM_WORKERS = 4\n","\n","# Prepare dataset\n","\n","# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","\n","# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","\n","\n","# Prepare dataset based on hyperparameter\n","if DATASET == 'CIFAR10':\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","elif DATASET == 'CIFAR100':\n","    if NUM_CLASSES%20 != 0 :\n","        raise ValueError(\"Invalid value of NUM_CLASSES specified. Choose 20 or 100\")\n","    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n","    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n","else:\n","    raise ValueError(\"Invalid dataset specified. Choose 'CIFAR10' or 'CIFAR100'.\")\n","\n","    \n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)"]},{"cell_type":"markdown","metadata":{},"source":["### Remapping labels if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:34.169552Z","iopub.status.busy":"2024-09-07T09:36:34.169155Z","iopub.status.idle":"2024-09-07T09:36:34.176305Z","shell.execute_reply":"2024-09-07T09:36:34.174981Z","shell.execute_reply.started":"2024-09-07T09:36:34.169513Z"},"trusted":true},"outputs":[],"source":["if NUM_CLASSES == 20:\n","    # Create custom dataset class to remap labels\n","\n","\n","    # Create custom datasets with remapped labels\n","    trainset = CustomDataset(trainset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n","    testset = CustomDataset(testset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:34.178608Z","iopub.status.busy":"2024-09-07T09:36:34.178137Z","iopub.status.idle":"2024-09-07T09:36:34.190937Z","shell.execute_reply":"2024-09-07T09:36:34.189363Z","shell.execute_reply.started":"2024-09-07T09:36:34.178563Z"},"trusted":true},"outputs":[],"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:36:34.193521Z","iopub.status.busy":"2024-09-07T09:36:34.192952Z","iopub.status.idle":"2024-09-07T09:36:34.204223Z","shell.execute_reply":"2024-09-07T09:36:34.202937Z","shell.execute_reply.started":"2024-09-07T09:36:34.193462Z"},"id":"bUqsuNN8SxqB","outputId":"0a2d5706-2adf-45db-d903-f74316ec1faa","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# For Multi-GPU\n","if 'cuda' in device:\n","    print(device)\n","    if args.dp:\n","        print(\"using data parallel\")\n","        net = torch.nn.DataParallel(net) # make parallel\n","        cudnn.benchmark = True\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"execution":{"iopub.execute_input":"2024-09-07T09:36:34.206257Z","iopub.status.busy":"2024-09-07T09:36:34.205868Z","iopub.status.idle":"2024-09-07T09:36:35.355831Z","shell.execute_reply":"2024-09-07T09:36:35.354163Z","shell.execute_reply.started":"2024-09-07T09:36:34.206209Z"},"id":"ycedpM59zTyh","outputId":"aa2b13bb-b636-44c7-9b7d-b2f2880470da","trusted":true},"outputs":[],"source":["!rm -rf results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:35.358315Z","iopub.status.busy":"2024-09-07T09:36:35.357880Z","iopub.status.idle":"2024-09-07T09:36:35.367285Z","shell.execute_reply":"2024-09-07T09:36:35.365153Z","shell.execute_reply.started":"2024-09-07T09:36:35.358269Z"},"id":"ygIfkREcrvX7","trusted":true},"outputs":[],"source":["\n","def get_vit():\n","    return ViT(\n","    image_size = size,\n","    patch_size = args.patch,\n","    # num_classes = 10,\n","    num_classes = NUM_CLASSES,\n","    dim = int(args.dimhead),\n","    depth = 6,\n","    # heads = 8,\n","    heads = NUM_HEADS,\n","    # mlp_dim = 512,\n","    mlp_dim = 256,\n","    dropout = 0.1,\n","    emb_dropout = 0.1,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:36:35.369495Z","iopub.status.busy":"2024-09-07T09:36:35.369073Z","iopub.status.idle":"2024-09-07T09:36:35.511899Z","shell.execute_reply":"2024-09-07T09:36:35.510752Z","shell.execute_reply.started":"2024-09-07T09:36:35.369453Z"},"id":"ND8qhixnSxqB","outputId":"e6edb544-3753-446e-ae32-03a9ab15df36","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==> Building model..\n"]}],"source":["\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Model factory..\n","print('==> Building model..')\n","# net = VGG('VGG19')\n","if args.net==\"vit\":\n","    # ViT for cifar10\n","    net = get_vit()\n","\n","\n","\n","if args.resume:\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:35.513763Z","iopub.status.busy":"2024-09-07T09:36:35.513336Z","iopub.status.idle":"2024-09-07T09:36:35.520493Z","shell.execute_reply":"2024-09-07T09:36:35.519064Z","shell.execute_reply.started":"2024-09-07T09:36:35.513719Z"},"id":"nc4jNV-bSxqC","trusted":true},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T09:36:35.522831Z","iopub.status.busy":"2024-09-07T09:36:35.522424Z","iopub.status.idle":"2024-09-07T09:36:35.532800Z","shell.execute_reply":"2024-09-07T09:36:35.531715Z","shell.execute_reply.started":"2024-09-07T09:36:35.522795Z"},"id":"8emZ75LWcpgE","outputId":"5423fb4a-63af-4ffb-a027-899ae0d60136","trusted":true},"outputs":[{"data":{"text/plain":["98"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["\n","len(trainloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"execution":{"iopub.execute_input":"2024-09-07T09:36:35.535080Z","iopub.status.busy":"2024-09-07T09:36:35.534598Z","iopub.status.idle":"2024-09-07T09:36:35.542290Z","shell.execute_reply":"2024-09-07T09:36:35.541096Z","shell.execute_reply.started":"2024-09-07T09:36:35.535001Z"},"id":"GCKRyskOugE5","outputId":"32f19894-9636-4bac-b61a-6db4237f6da5","trusted":true},"outputs":[],"source":["\n","# trainloader[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T09:36:35.544058Z","iopub.status.busy":"2024-09-07T09:36:35.543662Z","iopub.status.idle":"2024-09-07T09:36:35.553444Z","shell.execute_reply":"2024-09-07T09:36:35.551716Z","shell.execute_reply.started":"2024-09-07T09:36:35.544013Z"},"trusted":true},"outputs":[],"source":["# MAX_EPOCHS = 90\n","MAX_EPOCHS = 200"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":636},"execution":{"iopub.execute_input":"2024-09-07T09:36:35.555804Z","iopub.status.busy":"2024-09-07T09:36:35.555382Z","iopub.status.idle":"2024-09-07T09:37:50.736853Z","shell.execute_reply":"2024-09-07T09:37:50.734896Z","shell.execute_reply.started":"2024-09-07T09:36:35.555755Z"},"id":"O1brRsc3SxqH","outputId":"062f1e66-7ad7-49f8-fb09-27f797a6909c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Run number  1\n","chosen images are of batch 0 and numbers :  [7, 31, 33, 38, 45, 57, 58, 59, 60, 98, 118, 126, 131, 135, 139, 141, 142, 143, 147, 155, 162, 184, 209, 219, 233, 245, 252, 280, 286, 296, 310, 327, 349, 351, 357, 365, 368, 399, 411, 422, 424, 425, 431, 442, 452, 457, 463, 481, 482, 502]\n","Saving results every 10 epochs \n","Training started\n"]},{"name":"stderr","output_type":"stream","text":["Training:   1%|          | 1/90 [00:32<47:32, 32.05s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, lr: 0.0005000, val loss: 56.42817, acc: 13.21000\n","Model state saved at epoch 1\n","Logged epoch 1 - Accuracy: 13.2100, Loss: 56.4282\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 2/90 [00:59<43:05, 29.38s/it]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 2/90 [01:14<54:33, 37.20s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 198\u001b[0m\n\u001b[1;32m    195\u001b[0m         display(FileLink(zip_filename))\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m         trainloss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#     if(epoch%n_param!=0 or epoch==0):\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#         data_save.append(saved_data)\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m#         data_save=list()\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m#     val_loss, acc = test(epoch)\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# step cosine scheduling\u001b[39;00m\n","Cell \u001b[0;32mIn[53], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, save_flag, run_dir, img_idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     52\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 53\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","\n","# Loss is CE\n","criterion = nn.CrossEntropyLoss()\n","\n","torch.manual_seed(42)\n","net = get_vit()\n","\n","if args.opt == \"adam\":\n","    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n","elif args.opt == \"sgd\":\n","    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n","\n","# use cosine scheduling\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n","\n","##### Training\n","scaler = torch.amp.GradScaler('cuda',enabled=use_amp)\n","def train(epoch,save_flag, run_dir = None, img_idx = None):\n","    \n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    # img_factor = len(trainloader) // img_save_count\n","    # run_dir = os.path.join(run_dir,  {epoch:02}\")\n","\n","    # data_save=list()\n","    # main_list=list()\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        # Train with amp\n","        with torch.amp.autocast('cuda',enabled=use_amp):\n","            # if(save_flag==True and batch_idx%img_factor==0):\n","\n","            if(save_flag==True and batch_idx==0):\n","                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n","                os.makedirs(batch_dir, exist_ok=True)\n","                # np.save(file_path, np_array)\n","                # print(\"\\n\\tpassed \",batch_dir, type(batch_dir))\n","\n","                outputs = net(inputs, True, batch_dir, img_idx)\n","                # outputs = net(inputs, False, 12)\n","                #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n","            else:\n","                outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    # data_save.append(net.transformer.saved_values)\n","\n","#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","#     return train_loss/(batch_idx+1),net.transformer.saved_values\n","    return train_loss/(batch_idx+1)\n","##### Validation\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","#     if acc > best_acc:\n","#         print('Saving..')\n","#         state = {\"model\": net.state_dict(),\n","#               \"optimizer\": optimizer.state_dict(),\n","#               \"scaler\": scaler.state_dict()}\n","#         if not os.path.isdir('checkpoint'):\n","#             os.mkdir('checkpoint')\n","#         torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n","#         best_acc = acc\n","\n","#     os.makedirs(\"log\", exist_ok=True)\n","\n","    os.makedirs(\"results\", exist_ok=True)\n","    os.makedirs(\"results/log\", exist_ok=True)\n","    content = f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n","    print(content)\n","#     with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n","#         appender.write(content + \"\\n\")\n","    return test_loss, acc\n","\n","list_loss = []\n","list_acc = []\n","\n","if usewandb:\n","    wandb.watch(net)\n","\n","    \n","\n","# save_epochs-=1\n","batch_size = int(args.bs)\n","# max_epochs = args.n_epochs\n","\n","\n","\n","\n","if device == 'cuda':\n","  net.cuda()\n","main_list=list()\n","data_save=list()\n","n_param=5\n","\n","run_dir = os.path.join(base_dir, f\"run {run_number:02}\")\n","os.makedirs(run_dir, exist_ok=True)\n","print(\"Run number \",run_number)\n","\n","\n","\n","\n","\n","\n","import shutil\n","from IPython.display import FileLink\n","\n","# Specify the directory you want to compress\n","directory_name = run_dir\n","zip_filename = f'{run_dir}.zip'\n","\n","\n","\n","\n","run_number += 1\n","\n","max_epochs = MAX_EPOCHS\n","\n","# take_epoch_factor = \n","img_save_count = 50 #IMP\n","\n","img_idx = torch.randperm(batch_size)[:img_save_count]\n","img_idx= img_idx.sort()[0]\n","print(\"chosen images are of batch 0 and numbers : \",[x.item() for x in list(img_idx)])\n","file_path = os.path.join(run_dir, 'img_idx.npy')\n","np.save(file_path, img_idx.detach().cpu().numpy())\n","\n","\n","\n","# save_epochs =  #IMP\n","# epoch_factor = max_epochs  // save_epochs #IMP\n","\n","epoch_factor = 20 #IMP\n","patience_param=500\n","patience_counter=0\n","\n","\n","print(f\"Saving results every {epoch_factor} epochs \")\n","\n","\n","\n","\n","print(\"Training started\")\n","for i in tqdm(range(start_epoch, max_epochs), desc=\"Training\"):\n","    epoch = i+1\n","    start = time.time()\n","    \n","#     if(epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs):\n","    if False:\n","      # Define the new run directory\n","        \n","        epoch_dir = os.path.join(run_dir, f\"epoch {epoch:02}\")\n","        # print(\"\\n\\tpassed into trainloss\",run_dir)\n","        trainloss = train(epoch,True, run_dir = epoch_dir, img_idx = img_idx)\n","        print(\"saved epoch\")\n","        # Compress the directory into a zip file, overwriting if it already exists\n","        shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n","\n","#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n","        print(\"Click here to download run  : \")\n","        display(FileLink(zip_filename))\n","    \n","    else:\n","        trainloss = train(epoch,False)\n","\n","\n","\n","#     if(epoch%n_param!=0 or epoch==0):\n","#         data_save.append(saved_data)\n","#     else:\n","#         data_save.append(saved_data)\n","#         main_list.append(data_save)\n","#         data_save=list()\n","#     val_loss, acc = test(epoch)\n","\n","    scheduler.step() # step cosine scheduling\n","\n","\n","'''\n","    # Early stopping logic\n","    best_loss = float('inf')  # Initialize best loss to a high value\n","    val_loss, acc = test(epoch)\n","    \n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        patience_counter = 0  # Reset patience counter if loss improves\n","\n","    else:\n","        patience_counter += 1  # Increment patience counter if no improvement\n","\n","    # If patience limit is exceeded, stop training\n","    if patience_counter >= patience_param:\n","        save_model_state(net, epoch , val_loss, acc)\n","        print(f'Early stopping at epoch {epoch} due to no improvement')\n","\n","        break  ## we break out of training loop after saving the model\n","     '''\n","\n","    if (epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs and MODEL_SAVE_FLAG):\n","        \n","        \n","        val_loss, acc = test(epoch)\n","        save_model_state(net, epoch , val_loss, acc)\n","        \n","\n","#     list_loss.append(val_loss)\n","#     list_acc.append(acc)\n","\n","    # Log training..\n","#     if usewandb:\n","#         wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n","#         \"epoch_time\": time.time()-start})\n","\n","#     # Write out csv..\n","#     with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n","#         writer = csv.writer(f, lineterminator='\\n')\n","#         writer.writerow(list_loss)\n","#         writer.writerow(list_acc)\n","# #     print(list_loss)\n","    print()\n","    \n","# writeout wandb\n","if usewandb:\n","    wandb.save(\"wandb_{}.h5\".format(args.net))\n","\n","import shutil\n","from IPython.display import FileLink\n","zip_filename = 'checkpoints.zip'\n","directory_name = 'checkpoints'\n","shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n","\n","#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n","print(\"Click here to download checkpoints  : \")\n","display(FileLink(zip_filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.738792Z","iopub.status.idle":"2024-09-07T09:37:50.739506Z","shell.execute_reply":"2024-09-07T09:37:50.739160Z","shell.execute_reply.started":"2024-09-07T09:37:50.739123Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# Specify the path to your file\n","file_path = 'checkpoints.zip'\n","\n","# Get the size of the file in bytes\n","file_size = os.path.getsize(file_path)\n","\n","print(f\"The size of the file is : {(file_size/(2**20)):.0f} MB\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.741136Z","iopub.status.idle":"2024-09-07T09:37:50.741797Z","shell.execute_reply":"2024-09-07T09:37:50.741501Z","shell.execute_reply.started":"2024-09-07T09:37:50.741458Z"},"trusted":true},"outputs":[],"source":["raise ZeroDivisionError"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.743453Z","iopub.status.idle":"2024-09-07T09:37:50.744062Z","shell.execute_reply":"2024-09-07T09:37:50.743777Z","shell.execute_reply.started":"2024-09-07T09:37:50.743748Z"},"trusted":true},"outputs":[],"source":["!cd data\n","!ls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.746544Z","iopub.status.idle":"2024-09-07T09:37:50.747094Z","shell.execute_reply":"2024-09-07T09:37:50.746839Z","shell.execute_reply.started":"2024-09-07T09:37:50.746810Z"},"trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.749181Z","iopub.status.idle":"2024-09-07T09:37:50.749787Z","shell.execute_reply":"2024-09-07T09:37:50.749514Z","shell.execute_reply.started":"2024-09-07T09:37:50.749482Z"},"trusted":true},"outputs":[],"source":["# !rm -rf results\n","# !rm -rf log\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.751154Z","iopub.status.idle":"2024-09-07T09:37:50.751736Z","shell.execute_reply":"2024-09-07T09:37:50.751476Z","shell.execute_reply.started":"2024-09-07T09:37:50.751446Z"},"trusted":true},"outputs":[],"source":["# "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.752874Z","iopub.status.idle":"2024-09-07T09:37:50.753371Z","shell.execute_reply":"2024-09-07T09:37:50.753122Z","shell.execute_reply.started":"2024-09-07T09:37:50.753099Z"},"trusted":true},"outputs":[],"source":["# img_idx.detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.755035Z","iopub.status.idle":"2024-09-07T09:37:50.755469Z","shell.execute_reply":"2024-09-07T09:37:50.755297Z","shell.execute_reply.started":"2024-09-07T09:37:50.755276Z"},"trusted":true},"outputs":[],"source":["# import shutil\n","# from IPython.display import FileLink\n","\n","# # Specify the directory you want to compress\n","# directory_name = 'log'\n","# zip_filename = 'log.zip'\n","\n","# # Compress the directory into a zip file, overwriting if it already exists\n","# shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n","\n","# # Optionally generate and display a download link\n","# print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n","# FileLink(zip_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1RV3ub4bzaF","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.756764Z","iopub.status.idle":"2024-09-07T09:37:50.757118Z","shell.execute_reply":"2024-09-07T09:37:50.756961Z","shell.execute_reply.started":"2024-09-07T09:37:50.756943Z"},"id":"n5yDPk01T0oL","trusted":true},"outputs":[],"source":["\n","net"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.758514Z","iopub.status.idle":"2024-09-07T09:37:50.758930Z","shell.execute_reply":"2024-09-07T09:37:50.758741Z","shell.execute_reply.started":"2024-09-07T09:37:50.758704Z"},"id":"c61Jvkt9v1cj","trusted":true},"outputs":[],"source":["\n","/content/results/runs/run 04/epoch 00/batch 0/layer 01"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-09-07T09:37:50.760974Z","iopub.status.idle":"2024-09-07T09:37:50.761593Z","shell.execute_reply":"2024-09-07T09:37:50.761299Z","shell.execute_reply.started":"2024-09-07T09:37:50.761268Z"},"id":"U9sDNpPTSxqI","outputId":"802a6209-4de8-4ac2-e0c7-37c20468a8bb","trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.763573Z","iopub.status.idle":"2024-09-07T09:37:50.764021Z","shell.execute_reply":"2024-09-07T09:37:50.763830Z","shell.execute_reply.started":"2024-09-07T09:37:50.763807Z"},"trusted":true},"outputs":[],"source":["cd "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-09-07T09:37:50.765754Z","iopub.status.idle":"2024-09-07T09:37:50.766355Z","shell.execute_reply":"2024-09-07T09:37:50.766059Z","shell.execute_reply.started":"2024-09-07T09:37:50.766029Z"},"id":"zq9FNrXywIbb","outputId":"db92a1f9-34a2-49a1-8f61-f9e0750ec05d","trusted":true},"outputs":[],"source":["\n","import os\n","\n","# Define the directory path you want to check\n","directory_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/'\n","\n","# Check if the directory exists\n","if os.path.isdir(directory_path):\n","    print(f\"The directory '{directory_path}' exists.\")\n","else:\n","    print(f\"The directory '{directory_path}' does not exist.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:37:50.768141Z","iopub.status.idle":"2024-09-07T09:37:50.768617Z","shell.execute_reply":"2024-09-07T09:37:50.768419Z","shell.execute_reply.started":"2024-09-07T09:37:50.768396Z"},"id":"d2GSp2wbSxqI","trusted":true},"outputs":[],"source":["file_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/01_attention_out.npy'\n","\n","# Load the NumPy array from the file\n","data = np.load(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-09-07T09:37:50.771042Z","iopub.status.idle":"2024-09-07T09:37:50.771767Z","shell.execute_reply":"2024-09-07T09:37:50.771369Z","shell.execute_reply.started":"2024-09-07T09:37:50.771339Z"},"id":"SlFIzQIUSxqI","outputId":"5dce6a00-7620-4944-8d0d-6ccaa42668e6","trusted":true},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-09-07T09:37:50.773236Z","iopub.status.idle":"2024-09-07T09:37:50.773848Z","shell.execute_reply":"2024-09-07T09:37:50.773561Z","shell.execute_reply.started":"2024-09-07T09:37:50.773531Z"},"id":"Tr5wj-at0UJo","outputId":"874907d1-f72d-45f6-f805-8623093c5a0b","trusted":true},"outputs":[],"source":["\n","data.shape\n","# shape : batch x head x X x Y"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
