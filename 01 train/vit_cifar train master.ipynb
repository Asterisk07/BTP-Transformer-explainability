{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1782442,"sourceType":"datasetVersion","datasetId":1059701},{"sourceId":2359346,"sourceType":"datasetVersion","datasetId":1424838}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Define hyperparameters","metadata":{}},{"cell_type":"code","source":"\n# Dataset options\nDATASET = 'CIFAR100'  # Options: 'CIFAR10' or 'CIFAR100'\n# DATASET = 'CIFAR10'\n\n# Number of classes options\nNUM_CLASSES = 20     # Set the number of classes\n# NUM_CLASSES = 10   # For example, if using CIFAR-10, set to 10\n\n# Number of attention heads options\nNUM_HEADS = 8        # Options: 8, 4, 2, etc.\n# NUM_HEADS = 4\n# NUM_HEADS = 2","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.020307Z","iopub.execute_input":"2024-09-08T12:31:14.020678Z","iopub.status.idle":"2024-09-08T12:31:14.031721Z","shell.execute_reply.started":"2024-09-08T12:31:14.020622Z","shell.execute_reply":"2024-09-08T12:31:14.030848Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_hyperparameters(dataset_name, num_classes, num_heads):\n    \"\"\"\n    Validates the hyperparameters for dataset, number of classes, and number of attention heads.\n\n    Args:\n        dataset_name (str): The name of the dataset ('CIFAR10' or 'CIFAR100').\n        num_classes (int): The number of classes.\n        num_heads (int): The number of attention heads.\n\n    Raises:\n        ValueError: If any hyperparameter is invalid.\n    \"\"\"\n    valid_datasets = ['CIFAR10', 'CIFAR100']\n    if dataset_name not in valid_datasets:\n        raise ValueError(f\"Invalid DATASET value: {dataset_name}. Choose from {valid_datasets}.\")\n\n    if dataset_name == 'CIFAR10' and num_classes != 10:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 10. Current value: {num_classes}.\")\n    elif dataset_name == 'CIFAR100' and num_classes not in [20, 100]:\n        raise ValueError(f\"For {dataset_name}, NUM_CLASSES must be 20 or 100. Current value: {num_classes}.\")\n\n    valid_heads = [8, 4, 2]\n    if num_heads not in valid_heads:\n        raise ValueError(f\"Invalid NUM_HEADS value: {num_heads}. Choose from {valid_heads}.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.033169Z","iopub.execute_input":"2024-09-08T12:31:14.033454Z","iopub.status.idle":"2024-09-08T12:31:14.045062Z","shell.execute_reply.started":"2024-09-08T12:31:14.033423Z","shell.execute_reply":"2024-09-08T12:31:14.044151Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Validate hyperparameters\nvalidate_hyperparameters(DATASET, NUM_CLASSES, NUM_HEADS)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:14.049041Z","iopub.execute_input":"2024-09-08T12:31:14.049393Z","iopub.status.idle":"2024-09-08T12:31:14.053769Z","shell.execute_reply.started":"2024-09-08T12:31:14.049341Z","shell.execute_reply":"2024-09-08T12:31:14.052909Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial Setup","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n'''\n\nTrain CIFAR10 with PyTorch and Vision Transformers!\nwritten by @kentaroy47, @arutema47\nsource : https://github.com/kentaroy47/vision-transformers-cifar10\n\n'''\n\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport numpy as np\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport pandas as pd\nimport csv\nimport time\n\n\n","metadata":{"id":"Llt_Ire4Sxp2","execution":{"iopub.status.busy":"2024-09-08T12:31:14.066530Z","iopub.execute_input":"2024-09-08T12:31:14.067137Z","iopub.status.idle":"2024-09-08T12:31:19.007601Z","shell.execute_reply.started":"2024-09-08T12:31:14.067107Z","shell.execute_reply":"2024-09-08T12:31:19.006666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"markdown","source":"#### Saving loading","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\n\ndef save_model_state(model, epoch, loss, accuracy, checkpoint_dir='checkpoints', log_file='training_log.txt'):\n    # Create checkpoint directory if it doesn't exist\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    # Save model state\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    torch.save(model.state_dict(), model_checkpoint_path)\n    print(f'Model state saved at epoch {epoch}')\n    \n    # Log accuracy and loss\n    log_file_path = os.path.join(checkpoint_dir, log_file)\n    \n    with open(log_file_path, 'a') as f:\n        f.write(f'Epoch {epoch}: Accuracy = {accuracy:.4f}, Loss = {loss:.4f}\\n')\n    \n    print(f'Logged epoch {epoch} - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}')\n\n    \nimport torch\nimport os\n\ndef load_model_state(model, epoch = 90, checkpoint_dir='checkpoints'):\n    model_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pth')\n    model.load_state_dict(torch.load(model_checkpoint_path))   \n    print(f'Model state loaded from epoch {epoch}')\n    return epoch\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.009880Z","iopub.execute_input":"2024-09-08T12:31:19.010407Z","iopub.status.idle":"2024-09-08T12:31:19.020307Z","shell.execute_reply.started":"2024-09-08T12:31:19.010361Z","shell.execute_reply":"2024-09-08T12:31:19.018013Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = 'checkpoints'\n\nif os.path.isdir(directory):\n    print(\"Directory exists\")\n    items = os.listdir(directory)\n    for item in items:\n        print(item)\nelse:\n    print(\"Directory does not exist\")\n    \n#     if os.path.isdir(directory):\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.021332Z","iopub.execute_input":"2024-09-08T12:31:19.021607Z","iopub.status.idle":"2024-09-08T12:31:19.032419Z","shell.execute_reply.started":"2024-09-08T12:31:19.021576Z","shell.execute_reply":"2024-09-08T12:31:19.031354Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Directory does not exist\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Remapping labels function","metadata":{}},{"cell_type":"code","source":"def remap_labels(labels, num_classes_old, num_classes_new):\n    \"\"\"\n    Adjusts the labels from an old class structure to a new one.\n\n    Args:\n        labels (torch.Tensor or list): Original labels to be adjusted.\n        num_classes_old (int): The number of classes in the original dataset.\n        num_classes_new (int): The number of classes in the new dataset.\n\n    Returns:\n        torch.Tensor or list: The labels adjusted to the new class structure.\n    \"\"\"\n    # Check that the number of old classes is divisible by the number of new classes\n    assert num_classes_old % num_classes_new == 0, \"The number of old classes must be divisible by the number of new classes.\"\n\n    # Compute the factor to convert old labels to new labels\n    factor = num_classes_old // num_classes_new\n\n    # Remap each label\n    if isinstance(labels, torch.Tensor):\n        # If labels are a tensor, apply the remapping to each label and return a tensor\n        remapped_labels = torch.tensor([label.item() // factor for label in labels])\n    else:\n        # If labels are a list, apply the remapping to each label and return a list\n        remapped_labels = [label // factor for label in labels]\n    \n    return remapped_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.033906Z","iopub.execute_input":"2024-09-08T12:31:19.034343Z","iopub.status.idle":"2024-09-08T12:31:19.043569Z","shell.execute_reply.started":"2024-09-08T12:31:19.034298Z","shell.execute_reply":"2024-09-08T12:31:19.042671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, num_classes_old, num_classes_new):\n        self.dataset = dataset\n        self.num_classes_old = num_classes_old\n        self.num_classes_new = num_classes_new\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, index):\n        image, label = self.dataset[index]\n        remapped_label = remap_labels(torch.tensor([label]), self.num_classes_old, self.num_classes_new).item()\n        return image, remapped_label","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:19.046279Z","iopub.execute_input":"2024-09-08T12:31:19.046611Z","iopub.status.idle":"2024-09-08T12:31:19.054682Z","shell.execute_reply.started":"2024-09-08T12:31:19.046572Z","shell.execute_reply":"2024-09-08T12:31:19.053750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_number = 1\nbase_dir = \"results/runs\"\n\n# Define the new run directory\n\nos.makedirs(\"results\", exist_ok=True)\nos.makedirs(\"results/runs\", exist_ok=True)","metadata":{"id":"MmxrO8v6Sxp5","execution":{"iopub.status.busy":"2024-09-08T12:31:19.055922Z","iopub.execute_input":"2024-09-08T12:31:19.056219Z","iopub.status.idle":"2024-09-08T12:31:19.063082Z","shell.execute_reply.started":"2024-09-08T12:31:19.056177Z","shell.execute_reply":"2024-09-08T12:31:19.062087Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ROEAX6L0Wf7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O9k1NsUWISs","outputId":"6b67a80e-f9d1-43af-ebf4-3088aa41efd0","execution":{"iopub.status.busy":"2024-09-08T12:31:19.064267Z","iopub.execute_input":"2024-09-08T12:31:19.064572Z","iopub.status.idle":"2024-09-08T12:31:19.078326Z","shell.execute_reply.started":"2024-09-08T12:31:19.064540Z","shell.execute_reply":"2024-09-08T12:31:19.077510Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ec8117d0470>"},"metadata":{}}]},{"cell_type":"code","source":"# # setup for a read only personal access token\n# # note : token expires 19 aug 2025\n# token = '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'\n# token_user = 'Asterisk07'\n# repo_host = 'Asterisk07'\n# repo_name = 'BTP-Transformer-explainability'\n\n# url = f'https://{token_user}:{token}@github.com/{repo_host}/{repo_name}/'\n# !git clone {url}\n\n# !mv {repo_name}/models .\n# !rm -rf BTP-Transformer-explainability # delete a file","metadata":{"id":"aa7zHkXPSxp5","execution":{"iopub.status.busy":"2024-09-08T12:31:19.079342Z","iopub.execute_input":"2024-09-08T12:31:19.079601Z","iopub.status.idle":"2024-09-08T12:31:19.083791Z","shell.execute_reply.started":"2024-09-08T12:31:19.079572Z","shell.execute_reply":"2024-09-08T12:31:19.082932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JfB6PgwoSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YF9tLt1iSxp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eQR0IlVsSxp7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fnxx0KDSxp7","outputId":"c0015607-859a-4164-db22-8783ff70f8c1","execution":{"iopub.status.busy":"2024-09-08T12:31:19.084970Z","iopub.execute_input":"2024-09-08T12:31:19.085406Z","iopub.status.idle":"2024-09-08T12:31:20.131528Z","shell.execute_reply.started":"2024-09-08T12:31:19.085372Z","shell.execute_reply":"2024-09-08T12:31:20.130427Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"results\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"rO-x5w5QSxp8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf models","metadata":{"id":"aDRb-t5HSxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.133215Z","iopub.execute_input":"2024-09-08T12:31:20.133689Z","iopub.status.idle":"2024-09-08T12:31:20.139142Z","shell.execute_reply.started":"2024-09-08T12:31:20.133642Z","shell.execute_reply":"2024-09-08T12:31:20.137924Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# !npm install -g github-files-fetcher","metadata":{"id":"nyZGC9wISxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.140480Z","iopub.execute_input":"2024-09-08T12:31:20.141508Z","iopub.status.idle":"2024-09-08T12:31:20.148606Z","shell.execute_reply.started":"2024-09-08T12:31:20.141464Z","shell.execute_reply":"2024-09-08T12:31:20.147783Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# !fetcher --url=https://github.com/kentaroy47/vision-transformers-cifar10/tree/main/models\n# !fetcher --url=https://https://github.com/Asterisk07/BTP-Transformer-explainability/main/models\n","metadata":{"id":"XLQdzmZYSxp9","execution":{"iopub.status.busy":"2024-09-08T12:31:20.149772Z","iopub.execute_input":"2024-09-08T12:31:20.150146Z","iopub.status.idle":"2024-09-08T12:31:20.156309Z","shell.execute_reply.started":"2024-09-08T12:31:20.150099Z","shell.execute_reply":"2024-09-08T12:31:20.155469Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZPrL29xSxp9","outputId":"0cab9daf-2631-4d8f-ee64-1d51ccbdf40e","execution":{"iopub.status.busy":"2024-09-08T12:31:20.157667Z","iopub.execute_input":"2024-09-08T12:31:20.158485Z","iopub.status.idle":"2024-09-08T12:31:20.166499Z","shell.execute_reply.started":"2024-09-08T12:31:20.158435Z","shell.execute_reply":"2024-09-08T12:31:20.165448Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"u0zItmyxSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Check if 'utils.py' exists in the current directory\nif os.path.exists('utils.py'):\n    print(\"utils.py exists in the current directory.\")\nelse:\n    print(\"utils.py does not exist in the current directory.\")\n    !wget https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\n    print(\"utils.py fetched\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSnJhbUCU4J9","outputId":"d466bf62-4b25-4a9b-d2f7-83213799ad8a","execution":{"iopub.status.busy":"2024-09-08T12:31:20.172756Z","iopub.execute_input":"2024-09-08T12:31:20.173158Z","iopub.status.idle":"2024-09-08T12:31:21.333258Z","shell.execute_reply.started":"2024-09-08T12:31:20.173109Z","shell.execute_reply":"2024-09-08T12:31:21.332268Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"utils.py does not exist in the current directory.\n--2024-09-08 12:31:21--  https://raw.githubusercontent.com/kentaroy47/vision-transformers-cifar10/main/utils.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3501 (3.4K) [text/plain]\nSaving to: 'utils.py'\n\nutils.py            100%[===================>]   3.42K  --.-KB/s    in 0s      \n\n2024-09-08 12:31:21 (68.9 MB/s) - 'utils.py' saved [3501/3501]\n\nutils.py fetched\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"id":"5XLsXJxiSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import progress_bar","metadata":{"id":"Pe1-pReSSxp-","execution":{"iopub.status.busy":"2024-09-08T12:31:21.334645Z","iopub.execute_input":"2024-09-08T12:31:21.334971Z","iopub.status.idle":"2024-09-08T12:31:21.348399Z","shell.execute_reply.started":"2024-09-08T12:31:21.334935Z","shell.execute_reply":"2024-09-08T12:31:21.347550Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"stty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"}]},{"cell_type":"code","source":"progress_bar","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"_yVbM9QmSxp-","outputId":"2ebfb3d7-3459-40ed-c8a1-33e3839da492","execution":{"iopub.status.busy":"2024-09-08T12:31:21.349678Z","iopub.execute_input":"2024-09-08T12:31:21.350440Z","iopub.status.idle":"2024-09-08T12:31:21.356564Z","shell.execute_reply.started":"2024-09-08T12:31:21.350395Z","shell.execute_reply":"2024-09-08T12:31:21.355690Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<function utils.progress_bar(current, total, msg=None)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"mlKjovnlSxp-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# from randomaug import RandAugment\nfrom torchvision.transforms import RandAugment\n\n","metadata":{"id":"RGLFDHKiSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:21.357906Z","iopub.execute_input":"2024-09-08T12:31:21.358300Z","iopub.status.idle":"2024-09-08T12:31:21.362764Z","shell.execute_reply.started":"2024-09-08T12:31:21.358260Z","shell.execute_reply":"2024-09-08T12:31:21.361843Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rHHLarISxp_","outputId":"45997e81-9926-4465-d2dd-12835012d6b5","execution":{"iopub.status.busy":"2024-09-08T12:31:21.364023Z","iopub.execute_input":"2024-09-08T12:31:21.364663Z","iopub.status.idle":"2024-09-08T12:31:35.419057Z","shell.execute_reply.started":"2024-09-08T12:31:21.364607Z","shell.execute_reply":"2024-09-08T12:31:35.418005Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m671.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# from models import *\n# from models.vit import ViT\n# from models.convmixer import ConvMixer","metadata":{"id":"UsC7sE2cSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.420755Z","iopub.execute_input":"2024-09-08T12:31:35.421657Z","iopub.status.idle":"2024-09-08T12:31:35.425911Z","shell.execute_reply.started":"2024-09-08T12:31:35.421590Z","shell.execute_reply":"2024-09-08T12:31:35.424962Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJEMQtO5Upra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport json","metadata":{"id":"VJNDccCQe_XC","execution":{"iopub.status.busy":"2024-09-08T12:31:35.427391Z","iopub.execute_input":"2024-09-08T12:31:35.427785Z","iopub.status.idle":"2024-09-08T12:31:35.435078Z","shell.execute_reply.started":"2024-09-08T12:31:35.427741Z","shell.execute_reply":"2024-09-08T12:31:35.434211Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\nqkv_titles = ['q','k','v']","metadata":{"id":"WADSesO6g1ea","execution":{"iopub.status.busy":"2024-09-08T12:31:35.436184Z","iopub.execute_input":"2024-09-08T12:31:35.436545Z","iopub.status.idle":"2024-09-08T12:31:35.442664Z","shell.execute_reply.started":"2024-09-08T12:31:35.436501Z","shell.execute_reply":"2024-09-08T12:31:35.441972Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n# VIT.py\nimport torch\nfrom torch import nn\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\nimport numpy as np\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        out =  self.net(x)\n        if(save_flag==True):\n                file_path = os.path.join(run_dir, 'ff_out.npy')\n                # np.save(file_path, out)\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n        return out\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n\n        inner_dim = dim_head *  heads\n        # print(\"attention : dim = \", dim, \"| inner_dim = \",inner_dim,\"| dim_head = \", dim_head, \"| heads = \",heads  )\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim = -1)\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x,save_flag=False, run_dir = None,img_idx = None):\n        qkv = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n\n\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n\n        out = torch.matmul(attn, v)\n        if(save_flag==True):\n\n                # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n                for i, tensor in enumerate((q,k,v)):\n                    np_array = tensor[img_idx].detach().cpu().numpy()  # Convert to numpy\n                    # np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n                    file_path = os.path.join(run_dir, f'{qkv_titles[i]}.npy')\n                    np.save(file_path, np_array)\n                file_path = os.path.join(run_dir, 'att_out')\n                np.save(file_path, out[img_idx].detach().cpu().numpy())\n                file_path = os.path.join(run_dir, 'att_score')\n                np.save(file_path,attn[img_idx].detach().cpu().numpy())\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        # return self.to_out(out),q,k,v\n        return self.to_out(out)\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n        super().__init__()\n        # print(\"transformer : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads  )\n\n        self.layers = nn.ModuleList([])\n#         self.saved_values = {'logits': [], 'queries': [], 'keys': [], 'values': []}  # To store the values\n        # self.saved_values = list()  # To store th\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n            ]))\n\n    def forward(self, x,save_flag=False, run_dir = None, img_idx = None):\n        for i, (attn, ff) in enumerate(self.layers):\n            # Unpack the output from the Attention layer\n            #\n            # print(\"passed trans direcetory \", run_dir, \" and saving \",save_flag)\n            if save_flag:\n              layer_dir = os.path.join(run_dir,  f\"layer {i:02}\")\n              os.makedirs(layer_dir, exist_ok=True)\n              # print(\"passed trans layer direcetory \", layer_dir)\n            else:\n              layer_dir = None\n            attn_out = attn(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx)\n\n\n\n            # Save the query, key, value, and logits (output) for this layer\n            # self.saved_values.append(q.cpu().detach().numpy())\n            # self.saved_values.append(k.cpu().detach().numpy())\n            # self.saved_values.append(v.cpu().detach().numpy())\n\n            # Combine the attention output with the original x\n            x = attn_out + x\n            # self.saved_values.append(x.cpu().detach().numpy())  # Save logits\n            # print(\"i : \",i)\n            # Apply the feedforward network\n#             x = ff(x) + x\n\n            x = ff(x,save_flag=save_flag, run_dir = layer_dir, img_idx = img_idx) + x\n\n        return x\n\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        # print(\"vit : dim = \", dim, \"| dim_head = \", dim_head, \"| heads = \",heads , \" | mlp = \",mlp_dim )\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img, save_flag=False, run_dir = None,img_idx = None):\n        # if (save_flag):\n          # print(\"\\n\\treached here 3\")\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n\n        x = self.transformer(x,save_flag, run_dir, img_idx)\n#         if(save_flag==True):\n#                 # Convert each tensor in `qkv` to a numpy array and save it\n#                 qkv=attention.to_qkv\n#                 for i, tensor in enumerate(qkv):\n#                     np_array = tensor.detach().cpu().numpy()  # Convert to numpy\n#                     np.save(f'qkv_{i}.npy', np_array)  # Save each as a .npy file\n\n\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"id":"OzQdLRddSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.444054Z","iopub.execute_input":"2024-09-08T12:31:35.444406Z","iopub.status.idle":"2024-09-08T12:31:35.489948Z","shell.execute_reply.started":"2024-09-08T12:31:35.444366Z","shell.execute_reply":"2024-09-08T12:31:35.489021Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RskDA5B5zDv6","outputId":"85715f3b-73f8-4996-e0e8-b43df9b8dc08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Define your arguments here\ndef parse_args():\n    # parsers\n    parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4\n    parser.add_argument('--opt', default=\"adam\")\n    parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n    parser.add_argument('--noaug', action='store_false', help='disable use randomaug')\n    parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')\n    parser.add_argument('--nowandb', action='store_true', help='disable wandb')\n    parser.add_argument('--mixup', action='store_true', help='add mixup augumentations')\n    parser.add_argument('--net', default='vit')\n    parser.add_argument('--dp', action='store_true', help='use data parallel')\n    parser.add_argument('--bs', default='512')\n    parser.add_argument('--size', default=\"32\")\n    parser.add_argument('--n_epochs', type=int, default='200')\n    parser.add_argument('--patch', default='4', type=int, help=\"patch for ViT\")\n    parser.add_argument('--dimhead', default=\"512\", type=int)\n    parser.add_argument('--convkernel', default='8', type=int, help=\"parameter for convmixer\")\n\n    return parser.parse_args()\n\n\n","metadata":{"id":"GVdr58MRSxp_","execution":{"iopub.status.busy":"2024-09-08T12:31:35.491025Z","iopub.execute_input":"2024-09-08T12:31:35.491372Z","iopub.status.idle":"2024-09-08T12:31:35.500557Z","shell.execute_reply.started":"2024-09-08T12:31:35.491328Z","shell.execute_reply":"2024-09-08T12:31:35.499599Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"command = 'python train_cifar10.py --n_epochs 500 --lr 0.0005'\ncommand.split()[1:]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JbxSOG5SxqA","outputId":"2c280127-8d9e-4cd0-fc27-3bc03c51d0f2","execution":{"iopub.status.busy":"2024-09-08T12:31:35.501856Z","iopub.execute_input":"2024-09-08T12:31:35.502887Z","iopub.status.idle":"2024-09-08T12:31:35.513526Z","shell.execute_reply.started":"2024-09-08T12:31:35.502843Z","shell.execute_reply":"2024-09-08T12:31:35.512683Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['train_cifar10.py', '--n_epochs', '500', '--lr', '0.0005']"},"metadata":{}}]},{"cell_type":"code","source":"# Simulate command-line arguments\n# sys.argv = ['your_script.py', '--lr', '0.2', '--opt', 'adam', '--net', 'vit', '--bs', '64','--dimhead','256']\nsys.argv = command.split()[1:]\n\nargs = parse_args()\n\n","metadata":{"id":"SFLk9RG5SxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.514551Z","iopub.execute_input":"2024-09-08T12:31:35.514839Z","iopub.status.idle":"2024-09-08T12:31:35.521848Z","shell.execute_reply.started":"2024-09-08T12:31:35.514810Z","shell.execute_reply":"2024-09-08T12:31:35.521060Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall","metadata":{"id":"TZfQJlNKSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.522837Z","iopub.execute_input":"2024-09-08T12:31:35.523140Z","iopub.status.idle":"2024-09-08T12:31:35.529255Z","shell.execute_reply.started":"2024-09-08T12:31:35.523109Z","shell.execute_reply":"2024-09-08T12:31:35.528405Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZRdesLOdSxqA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (2.0.1+cu117)\n# Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2+cu117)","metadata":{"id":"xBdPskigSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.530167Z","iopub.execute_input":"2024-09-08T12:31:35.531006Z","iopub.status.idle":"2024-09-08T12:31:35.537416Z","shell.execute_reply.started":"2024-09-08T12:31:35.530967Z","shell.execute_reply":"2024-09-08T12:31:35.536619Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# !pip show torchvision\n","metadata":{"id":"uiDtWCYKSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.538524Z","iopub.execute_input":"2024-09-08T12:31:35.539136Z","iopub.status.idle":"2024-09-08T12:31:35.545445Z","shell.execute_reply.started":"2024-09-08T12:31:35.539095Z","shell.execute_reply":"2024-09-08T12:31:35.544620Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"2","metadata":{"id":"_T0LacFUt74i","execution":{"iopub.status.busy":"2024-09-08T12:31:35.546425Z","iopub.execute_input":"2024-09-08T12:31:35.546784Z","iopub.status.idle":"2024-09-08T12:31:35.555773Z","shell.execute_reply.started":"2024-09-08T12:31:35.546740Z","shell.execute_reply":"2024-09-08T12:31:35.554852Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# !pip show torch\n# #","metadata":{"id":"NRmD_dGiSxqA","execution":{"iopub.status.busy":"2024-09-08T12:31:35.557071Z","iopub.execute_input":"2024-09-08T12:31:35.557967Z","iopub.status.idle":"2024-09-08T12:31:35.561993Z","shell.execute_reply.started":"2024-09-08T12:31:35.557912Z","shell.execute_reply":"2024-09-08T12:31:35.561091Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m-UHnDboSxqA","outputId":"81f73c03-4a0e-490f-e36e-08f56d3b0124","execution":{"iopub.status.busy":"2024-09-08T12:31:35.563105Z","iopub.execute_input":"2024-09-08T12:31:35.563444Z","iopub.status.idle":"2024-09-08T12:31:35.573343Z","shell.execute_reply.started":"2024-09-08T12:31:35.563411Z","shell.execute_reply":"2024-09-08T12:31:35.572448Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'0.19.0'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aQh5PidkSxqA","outputId":"78297830-3ca1-42b2-fa0a-1b761d0e61fe","execution":{"iopub.status.busy":"2024-09-08T12:31:35.574606Z","iopub.execute_input":"2024-09-08T12:31:35.574965Z","iopub.status.idle":"2024-09-08T12:31:35.581036Z","shell.execute_reply.started":"2024-09-08T12:31:35.574933Z","shell.execute_reply":"2024-09-08T12:31:35.580042Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hedCXexeSxqB","outputId":"247ba528-fb2e-4d69-e300-408eb63d93dd","execution":{"iopub.status.busy":"2024-09-08T12:31:35.582454Z","iopub.execute_input":"2024-09-08T12:31:35.582876Z","iopub.status.idle":"2024-09-08T12:31:48.645792Z","shell.execute_reply.started":"2024-09-08T12:31:35.582828Z","shell.execute_reply":"2024-09-08T12:31:48.644675Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# take in args\nusewandb = ~args.nowandb\nusewandb = False\nif usewandb:\n    import wandb\n    watermark = \"{}_lr{}\".format(args.net, args.lr)\n    wandb.init(project=\"cifar10-challange\",\n            name=watermark)\n    wandb.config.update(args)\n\nbs = int(args.bs)\nimsize = int(args.size)\n\nuse_amp = not args.noamp\naug = args.noaug\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\nif args.net==\"vit_timm\":\n    size = 384\nelse:\n    size = imsize\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize(size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Add RandAugment with N, M(hyperparameter)\nif aug:\n    N = 2; M = 14;\n    transform_train.transforms.insert(0, RandAugment(N, M))\n    \nprint(\"ready to fetch data\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"qnyCPg0HSxqB","outputId":"f6b2c294-26d0-4eaf-aede-2eb3a3c436b9","execution":{"iopub.status.busy":"2024-09-08T12:31:48.647462Z","iopub.execute_input":"2024-09-08T12:31:48.648339Z","iopub.status.idle":"2024-09-08T12:31:48.705973Z","shell.execute_reply.started":"2024-09-08T12:31:48.648291Z","shell.execute_reply":"2024-09-08T12:31:48.704864Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"==> Preparing data..\nready to fetch data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### loading cifar 100","metadata":{"execution":{"iopub.status.busy":"2024-09-08T11:42:51.856499Z","iopub.execute_input":"2024-09-08T11:42:51.857228Z","iopub.status.idle":"2024-09-08T11:42:51.866843Z","shell.execute_reply.started":"2024-09-08T11:42:51.857190Z","shell.execute_reply":"2024-09-08T11:42:51.865688Z"}}},{"cell_type":"code","source":"bs","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:48.707436Z","iopub.execute_input":"2024-09-08T12:31:48.707842Z","iopub.status.idle":"2024-09-08T12:31:48.716208Z","shell.execute_reply.started":"2024-09-08T12:31:48.707798Z","shell.execute_reply":"2024-09-08T12:31:48.715162Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    datasetname = 'cifar10-python'\n    datasetcode = 'pankrzysiu/cifar10-python'\nelif DATASET == 'CIFAR100':\n    datasetname = 'cifar100'\n    datasetcode = 'fedesoriano/cifar100'\n!kaggle datasets download -d {datasetcode}","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:48.717246Z","iopub.execute_input":"2024-09-08T12:31:48.717570Z","iopub.status.idle":"2024-09-08T12:31:51.136153Z","shell.execute_reply.started":"2024-09-08T12:31:48.717525Z","shell.execute_reply":"2024-09-08T12:31:51.135006Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/fedesoriano/cifar100\nLicense(s): copyright-authors\nDownloading cifar100.zip to /kaggle/working\n 95%|███████████████████████████████████████  | 153M/161M [00:00<00:00, 274MB/s]\n100%|█████████████████████████████████████████| 161M/161M [00:00<00:00, 282MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:51.137614Z","iopub.execute_input":"2024-09-08T12:31:51.137945Z","iopub.status.idle":"2024-09-08T12:31:51.142954Z","shell.execute_reply.started":"2024-09-08T12:31:51.137911Z","shell.execute_reply":"2024-09-08T12:31:51.141576Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Unzip the dataset\nwith zipfile.ZipFile(f'{datasetname}.zip', 'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working/dataset')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:51.144191Z","iopub.execute_input":"2024-09-08T12:31:51.144465Z","iopub.status.idle":"2024-09-08T12:31:52.456159Z","shell.execute_reply.started":"2024-09-08T12:31:51.144436Z","shell.execute_reply":"2024-09-08T12:31:52.455171Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class CIFAR10Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # CIFAR-10 images have 3 channels (RGB) and size 32x32\n        self.img_channels = 3\n        self.img_height = 32\n        self.img_width = 32\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        # Reshape the flattened image (3072) into (3, 32, 32) format\n        img = img.reshape(self.img_channels, self.img_height, self.img_width)\n\n        # Convert to PIL Image format (HxWxC)\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n\ndef unpickle(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n\ndef load_cifar10_data(data_path):\n    \"\"\" Load all CIFAR-10 data batches and return combined data and labels \"\"\"\n    train_data = []\n    train_labels = []\n\n    # CIFAR-10 contains 5 training batches\n    for i in range(1, 6):\n        batch = unpickle(f\"{data_path}/data_batch_{i}\")\n        train_data.append(batch[b'data'])\n        train_labels.extend(batch[b'labels'])\n\n    # Convert to numpy arrays\n    train_data = np.concatenate(train_data, axis=0)\n    train_labels = np.array(train_labels)\n\n    # Load test data\n    test_batch = unpickle(f\"{data_path}/test_batch\")\n    test_data = test_batch[b'data']\n    test_labels = np.array(test_batch[b'labels'])\n\n    return (train_data, train_labels), (test_data, test_labels)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:31:52.457525Z","iopub.execute_input":"2024-09-08T12:31:52.457874Z","iopub.status.idle":"2024-09-08T12:31:52.469402Z","shell.execute_reply.started":"2024-09-08T12:31:52.457840Z","shell.execute_reply":"2024-09-08T12:31:52.468409Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CIFAR100Custom(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n        # Determine image dimensions from the first sample\n        sample_img = self.data[0]  # Get the first image sample\n        self.img_channels = 3  # CIFAR-100 images are RGB\n\n        # The image is flattened, so we need to infer the correct shape.\n        self.img_height, self.img_width = self._get_image_dimensions(sample_img)\n\n    def _get_image_dimensions(self, img_flat):\n        # Assuming CIFAR-100 with known number of channels (3)\n        num_pixels = img_flat.size // self.img_channels\n        side = int(np.sqrt(num_pixels))  # CIFAR-100 images are square (32x32)\n        return side, side\n\n    def _reshape_image(self, img_flat):\n        # Try reshaping based on typical formats CxHxW or HxWxC\n        try:\n            img = img_flat.reshape(self.img_channels, self.img_height, self.img_width)  # CxHxW\n        except ValueError:\n            img = img_flat.reshape(self.img_height, self.img_width, self.img_channels)  # HxWxC\n        return img\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        img = self._reshape_image(img)\n\n        # Handle case where image is in HxWxC (common in numpy arrays)\n        if img.shape[0] == self.img_height:  # HxWxC format\n            img = img.transpose(2, 0, 1)  # Convert to CxHxW\n\n        # Convert numpy array to PIL image for transformations\n        img = Image.fromarray(img.transpose(1, 2, 0), 'RGB')  # Convert CxHxW to HxWxC for PIL\n\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.402732Z","iopub.execute_input":"2024-09-08T12:32:24.403150Z","iopub.status.idle":"2024-09-08T12:32:24.414570Z","shell.execute_reply.started":"2024-09-08T12:32:24.403111Z","shell.execute_reply":"2024-09-08T12:32:24.413616Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.499521Z","iopub.execute_input":"2024-09-08T12:32:24.499827Z","iopub.status.idle":"2024-09-08T12:32:24.503742Z","shell.execute_reply.started":"2024-09-08T12:32:24.499796Z","shell.execute_reply":"2024-09-08T12:32:24.502674Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"if DATASET == 'CIFAR10':\n    \n    # Load CIFAR-10 data\n    data_path = '/kaggle/working/dataset/cifar-10-batches-py'  # Update path as necessary\n    (train_data, train_labels), (test_data, test_labels) = load_cifar10_data(data_path)\n\n    # Prepare datasets\n    trainset = CIFAR10Custom(data=train_data, labels=train_labels, transform=transform_train)\n    testset = CIFAR10Custom(data=test_data, labels=test_labels, transform=transform_test)\n\n    \nelif DATASET == 'CIFAR100':\n    \n\n    # Prepare dataset\n    data_pre_path = '/kaggle/working/dataset'\n    metadata_path = data_pre_path + '/meta'\n    data_train_path = data_pre_path + '/train'\n    data_test_path = data_pre_path + '/test'\n\n    def unpickle(file):\n        import pickle\n        with open(file, 'rb') as fo:\n            data_dict = pickle.load(fo, encoding='bytes')\n        return data_dict\n\n    metadata = unpickle(metadata_path)\n    data_train_dict = unpickle(data_train_path)\n    data_test_dict = unpickle(data_test_path)\n\n    data_train = data_train_dict[b'data']\n    label_train = np.array(data_train_dict[b'coarse_labels'])\n    data_test = data_test_dict[b'data']\n    label_test = np.array(data_test_dict[b'coarse_labels'])\n\n    # Prepare datasets\n    trainset = CIFAR100Custom(data=data_train, labels=label_train, transform=transform_train)\n    testset = CIFAR100Custom(data=data_test, labels=label_test, transform=transform_test)\n\n# DataLoader\nbatch_size = bs  # Adjust batch size as needed\nnum_workers = 4  # Adjust number of workers as needed\n\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\nprint(\"DataLoader prepared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:24.511203Z","iopub.execute_input":"2024-09-08T12:32:24.511762Z","iopub.status.idle":"2024-09-08T12:32:24.806661Z","shell.execute_reply.started":"2024-09-08T12:32:24.511730Z","shell.execute_reply":"2024-09-08T12:32:24.805589Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"DataLoader prepared.\n","output_type":"stream"}]},{"cell_type":"code","source":"# r1 is None","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.927873Z","iopub.execute_input":"2024-09-08T12:32:34.928727Z","iopub.status.idle":"2024-09-08T12:32:34.932717Z","shell.execute_reply.started":"2024-09-08T12:32:34.928683Z","shell.execute_reply":"2024-09-08T12:32:34.931689Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"i1, l1  = None, None","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.934764Z","iopub.execute_input":"2024-09-08T12:32:34.935374Z","iopub.status.idle":"2024-09-08T12:32:34.941430Z","shell.execute_reply.started":"2024-09-08T12:32:34.935326Z","shell.execute_reply":"2024-09-08T12:32:34.940688Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for images, labels in trainloader:\n    # Get the first image and label from the batch\n    print(1)\n    i1 = images\n    l1 = labels\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:34.942683Z","iopub.execute_input":"2024-09-08T12:32:34.943226Z","iopub.status.idle":"2024-09-08T12:32:36.649101Z","shell.execute_reply.started":"2024-09-08T12:32:34.943191Z","shell.execute_reply":"2024-09-08T12:32:36.648019Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"i1.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.651721Z","iopub.execute_input":"2024-09-08T12:32:36.652051Z","iopub.status.idle":"2024-09-08T12:32:36.658478Z","shell.execute_reply.started":"2024-09-08T12:32:36.652017Z","shell.execute_reply":"2024-09-08T12:32:36.657659Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"torch.Size([512, 3, 32, 32])"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n\n# # Assuming you have a tensor of shape [3, 32, 32]\n# # Create a random tensor for demonstration purposes\n# image_tensor = i1[15]\n\n# # Convert the tensor from [C, H, W] to [H, W, C] for displaying\n# image_np = image_tensor.permute(1, 2, 0).numpy()\n\n# # Plot the image\n# plt.imshow(image_np)\n# plt.axis('off')  # Turn off the axis labels\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.659777Z","iopub.execute_input":"2024-09-08T12:32:36.660110Z","iopub.status.idle":"2024-09-08T12:32:36.666677Z","shell.execute_reply.started":"2024-09-08T12:32:36.660077Z","shell.execute_reply":"2024-09-08T12:32:36.665652Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# # Prepare dataset\n# print(\"Loading dataset from kaggle/input\")\n# trainset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/train', transform=transform_train)\n# testset = CIFAR100Custom(root_dir='/kaggle/input/cifar100/test', transform=transform_test)\n\n# print(\"Loading dataset\")\n# trainloader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.667905Z","iopub.execute_input":"2024-09-08T12:32:36.668318Z","iopub.status.idle":"2024-09-08T12:32:36.679140Z","shell.execute_reply.started":"2024-09-08T12:32:36.668272Z","shell.execute_reply":"2024-09-08T12:32:36.678267Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# len(trainset)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.680301Z","iopub.execute_input":"2024-09-08T12:32:36.680610Z","iopub.status.idle":"2024-09-08T12:32:36.686750Z","shell.execute_reply.started":"2024-09-08T12:32:36.680577Z","shell.execute_reply":"2024-09-08T12:32:36.685949Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# NUM_WORKERS = 4\n# cifar100_path = '/kaggle/input/cifar100'\n# # Prepare dataset\n\n# # trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n\n# # testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n# import torchvision\n# import torch\n# import torch.nn as nnn\n\n\n\n# # Prepare dataset based on hyperparameter\n# print(\"downloading dataset\")\n# if DATASET == 'CIFAR10':\n#     trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n    \n# elif DATASET == 'CIFAR100':\n#     if NUM_CLASSES%20 != 0 :\n#         raise ValueError(\"Invalid value of NUM_CLASSES specified. Choose 20 or 100\")\n#     trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n#     print(\"downloaded dataset\")\n#     testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n# else:\n#     raise ValueError(\"Invalid dataset specified. Choose 'CIFAR10' or 'CIFAR100'.\")\n    \n# print(\"loading dataset\")\n# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.687983Z","iopub.execute_input":"2024-09-08T12:32:36.688285Z","iopub.status.idle":"2024-09-08T12:32:36.695548Z","shell.execute_reply.started":"2024-09-08T12:32:36.688254Z","shell.execute_reply":"2024-09-08T12:32:36.694602Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use only this token :\n# f439c9e9cdf4ff7e3d47e80d4588628783d8bafe #aster","metadata":{"id":"V-X21wSpSxqB","execution":{"iopub.status.busy":"2024-09-08T12:32:36.698954Z","iopub.execute_input":"2024-09-08T12:32:36.699266Z","iopub.status.idle":"2024-09-08T12:32:36.705530Z","shell.execute_reply.started":"2024-09-08T12:32:36.699236Z","shell.execute_reply":"2024-09-08T12:32:36.704655Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUzFJatHSxqB","outputId":"3a5a3505-936f-4461-b40a-fc75c7fb4f98","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remapping labels if needed","metadata":{}},{"cell_type":"code","source":"# if NUM_CLASSES == 20:\n#     # Create custom dataset class to remap labels\n\n\n#     # Create custom datasets with remapped labels\n#     trainset = CustomDataset(trainset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n#     testset = CustomDataset(testset, num_classes_old=100, num_classes_new=NUM_CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.706997Z","iopub.execute_input":"2024-09-08T12:32:36.707392Z","iopub.status.idle":"2024-09-08T12:32:36.712172Z","shell.execute_reply.started":"2024-09-08T12:32:36.707351Z","shell.execute_reply":"2024-09-08T12:32:36.711335Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=NUM_WORKERS)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:36.713269Z","iopub.execute_input":"2024-09-08T12:32:36.713977Z","iopub.status.idle":"2024-09-08T12:32:36.719305Z","shell.execute_reply.started":"2024-09-08T12:32:36.713933Z","shell.execute_reply":"2024-09-08T12:32:36.718389Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# For Multi-GPU\nif 'cuda' in device:\n    print(device)\n    if args.dp:\n        print(\"using data parallel\")\n        net = torch.nn.DataParallel(net) # make parallel\n        cudnn.benchmark = True\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUqsuNN8SxqB","outputId":"0a2d5706-2adf-45db-d903-f74316ec1faa","execution":{"iopub.status.busy":"2024-09-08T12:32:36.720524Z","iopub.execute_input":"2024-09-08T12:32:36.721300Z","iopub.status.idle":"2024-09-08T12:32:36.729619Z","shell.execute_reply.started":"2024-09-08T12:32:36.721268Z","shell.execute_reply":"2024-09-08T12:32:36.728765Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"ycedpM59zTyh","outputId":"aa2b13bb-b636-44c7-9b7d-b2f2880470da","execution":{"iopub.status.busy":"2024-09-08T12:32:36.730610Z","iopub.execute_input":"2024-09-08T12:32:36.730913Z","iopub.status.idle":"2024-09-08T12:32:37.740040Z","shell.execute_reply.started":"2024-09-08T12:32:36.730882Z","shell.execute_reply":"2024-09-08T12:32:37.738758Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"\ndef get_vit():\n    return ViT(\n    image_size = size,\n    patch_size = args.patch,\n    # num_classes = 10,\n    num_classes = NUM_CLASSES,\n    dim = int(args.dimhead),\n    depth = 6,\n    # heads = 8,\n    heads = NUM_HEADS,\n    # mlp_dim = 512,\n    mlp_dim = 256,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    )","metadata":{"id":"ygIfkREcrvX7","execution":{"iopub.status.busy":"2024-09-08T12:32:37.741774Z","iopub.execute_input":"2024-09-08T12:32:37.742110Z","iopub.status.idle":"2024-09-08T12:32:37.747771Z","shell.execute_reply.started":"2024-09-08T12:32:37.742075Z","shell.execute_reply":"2024-09-08T12:32:37.746896Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model factory..\nprint('==> Building model..')\n# net = VGG('VGG19')\nif args.net==\"vit\":\n    # ViT for cifar10\n    net = get_vit()\n\n\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ND8qhixnSxqB","outputId":"e6edb544-3753-446e-ae32-03a9ab15df36","execution":{"iopub.status.busy":"2024-09-08T12:32:37.749152Z","iopub.execute_input":"2024-09-08T12:32:37.749774Z","iopub.status.idle":"2024-09-08T12:32:37.831523Z","shell.execute_reply.started":"2024-09-08T12:32:37.749730Z","shell.execute_reply":"2024-09-08T12:32:37.830668Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"nc4jNV-bSxqC","execution":{"iopub.status.busy":"2024-09-08T12:32:37.832693Z","iopub.execute_input":"2024-09-08T12:32:37.833454Z","iopub.status.idle":"2024-09-08T12:32:37.837664Z","shell.execute_reply.started":"2024-09-08T12:32:37.833409Z","shell.execute_reply":"2024-09-08T12:32:37.836840Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"\nlen(trainloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8emZ75LWcpgE","outputId":"5423fb4a-63af-4ffb-a027-899ae0d60136","execution":{"iopub.status.busy":"2024-09-08T12:32:37.838683Z","iopub.execute_input":"2024-09-08T12:32:37.838969Z","iopub.status.idle":"2024-09-08T12:32:37.847064Z","shell.execute_reply.started":"2024-09-08T12:32:37.838938Z","shell.execute_reply":"2024-09-08T12:32:37.846282Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"98"},"metadata":{}}]},{"cell_type":"code","source":"\n# trainloader[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"GCKRyskOugE5","outputId":"32f19894-9636-4bac-b61a-6db4237f6da5","execution":{"iopub.status.busy":"2024-09-08T12:32:37.848278Z","iopub.execute_input":"2024-09-08T12:32:37.848939Z","iopub.status.idle":"2024-09-08T12:32:37.854099Z","shell.execute_reply.started":"2024-09-08T12:32:37.848893Z","shell.execute_reply":"2024-09-08T12:32:37.853195Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# MAX_EPOCHS = 90\nMAX_EPOCHS = 200","metadata":{"execution":{"iopub.status.busy":"2024-09-08T12:32:37.855064Z","iopub.execute_input":"2024-09-08T12:32:37.855322Z","iopub.status.idle":"2024-09-08T12:32:37.861484Z","shell.execute_reply.started":"2024-09-08T12:32:37.855293Z","shell.execute_reply":"2024-09-08T12:32:37.860745Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Loss is CE\ncriterion = nn.CrossEntropyLoss()\n\ntorch.manual_seed(42)\nnet = get_vit()\n\nif args.opt == \"adam\":\n    optimizer = optim.Adam(net.parameters(), lr=args.lr)\nelif args.opt == \"sgd\":\n    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n\n# use cosine scheduling\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)\n\n##### Training\nscaler = torch.amp.GradScaler('cuda',enabled=use_amp)\ndef train(epoch,save_flag, run_dir = None, img_idx = None):\n    \n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    # img_factor = len(trainloader) // img_save_count\n    # run_dir = os.path.join(run_dir,  {epoch:02}\")\n\n    # data_save=list()\n    # main_list=list()\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # Train with amp\n        with torch.amp.autocast('cuda',enabled=use_amp):\n            # if(save_flag==True and batch_idx%img_factor==0):\n\n            if(save_flag==True and batch_idx==0):\n                batch_dir = os.path.join(run_dir, f'batch {batch_idx}')\n                os.makedirs(batch_dir, exist_ok=True)\n                # np.save(file_path, np_array)\n                # print(\"\\n\\tpassed \",batch_dir, type(batch_dir))\n\n                outputs = net(inputs, True, batch_dir, img_idx)\n                # outputs = net(inputs, False, 12)\n                #here can pass in net(inputs,image_saveflag=1) so it will save the image to disk by making changes in model.\n            else:\n                outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    # data_save.append(net.transformer.saved_values)\n\n#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n#     return train_loss/(batch_idx+1),net.transformer.saved_values\n    return train_loss/(batch_idx+1)\n##### Validation\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n#     if acc > best_acc:\n#         print('Saving..')\n#         state = {\"model\": net.state_dict(),\n#               \"optimizer\": optimizer.state_dict(),\n#               \"scaler\": scaler.state_dict()}\n#         if not os.path.isdir('checkpoint'):\n#             os.mkdir('checkpoint')\n#         torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n#         best_acc = acc\n\n#     os.makedirs(\"log\", exist_ok=True)\n\n    os.makedirs(\"results\", exist_ok=True)\n    os.makedirs(\"results/log\", exist_ok=True)\n    content = f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n    print(content)\n#     with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n#         appender.write(content + \"\\n\")\n    return test_loss, acc\n\nlist_loss = []\nlist_acc = []\n\nif usewandb:\n    wandb.watch(net)\n\n    \n\n# save_epochs-=1\nbatch_size = int(args.bs)\n# max_epochs = args.n_epochs\n\n\n\n\nif device == 'cuda':\n  net.cuda()\nmain_list=list()\ndata_save=list()\nn_param=5\n\nrun_dir = os.path.join(base_dir, f\"run {run_number:02}\")\nos.makedirs(run_dir, exist_ok=True)\nprint(\"Run number \",run_number)\n\n\n\n\n\n\nimport shutil\nfrom IPython.display import FileLink\n\n# Specify the directory you want to compress\ndirectory_name = run_dir\nzip_filename = f'{run_dir}.zip'\n\n\n\n\nrun_number += 1\n\nmax_epochs = MAX_EPOCHS\n\n# take_epoch_factor = \nimg_save_count = 50 #IMP\n\nimg_idx = torch.randperm(batch_size)[:img_save_count]\nimg_idx= img_idx.sort()[0]\nprint(\"chosen images are of batch 0 and numbers : \",[x.item() for x in list(img_idx)])\nfile_path = os.path.join(run_dir, 'img_idx.npy')\nnp.save(file_path, img_idx.detach().cpu().numpy())\n\n\n\n# save_epochs =  #IMP\n# epoch_factor = max_epochs  // save_epochs #IMP\n\nepoch_factor = 20 #IMP\npatience_param=500\npatience_counter=0\n\n\nprint(f\"Saving results every {epoch_factor} epochs \")\n\n\n\n\nprint(\"Training started\")\nfor i in tqdm(range(start_epoch, max_epochs), desc=\"Training\"):\n    epoch = i+1\n    start = time.time()\n    \n#     if(epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs):\n    if False:\n      # Define the new run directory\n        \n        epoch_dir = os.path.join(run_dir, f\"epoch {epoch:02}\")\n        # print(\"\\n\\tpassed into trainloss\",run_dir)\n        trainloss = train(epoch,True, run_dir = epoch_dir, img_idx = img_idx)\n        print(\"saved epoch\")\n        # Compress the directory into a zip file, overwriting if it already exists\n        shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n        print(\"Click here to download run  : \")\n        display(FileLink(zip_filename))\n    \n    else:\n        trainloss = train(epoch,False)\n\n\n\n#     if(epoch%n_param!=0 or epoch==0):\n#         data_save.append(saved_data)\n#     else:\n#         data_save.append(saved_data)\n#         main_list.append(data_save)\n#         data_save=list()\n#     val_loss, acc = test(epoch)\n\n    scheduler.step() # step cosine scheduling\n\n\n    '''\n    # Early stopping logic\n    best_loss = float('inf')  # Initialize best loss to a high value\n    val_loss, acc = test(epoch)\n    \n    if val_loss < best_loss:\n        best_loss = val_loss\n        patience_counter = 0  # Reset patience counter if loss improves\n\n    else:\n        patience_counter += 1  # Increment patience counter if no improvement\n\n    # If patience limit is exceeded, stop training\n    if patience_counter >= patience_param:\n        save_model_state(net, epoch , val_loss, acc)\n        print(f'Early stopping at epoch {epoch} due to no improvement')\n\n        break  ## we break out of training loop after saving the model\n     '''\n    val_loss, acc = test(epoch)\n    if (epoch%epoch_factor==0 or epoch == 1 or epoch == max_epochs and MODEL_SAVE_FLAG):\n        \n        \n#         val_loss, acc = test(epoch)\n        save_model_state(net, epoch , val_loss, acc)\n        \n\n#     list_loss.append(val_loss)\n#     list_acc.append(acc)\n\n    # Log training..\n#     if usewandb:\n#         wandb.log({'epoch': epoch, 'train_loss': trainloss, 'val_loss': val_loss, \"val_acc\": acc, \"lr\": optimizer.param_groups[0][\"lr\"],\n#         \"epoch_time\": time.time()-start})\n\n#     # Write out csv..\n#     with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n#         writer = csv.writer(f, lineterminator='\\n')\n#         writer.writerow(list_loss)\n#         writer.writerow(list_acc)\n# #     print(list_loss)\n    print()\n    \n# writeout wandb\nif usewandb:\n    wandb.save(\"wandb_{}.h5\".format(args.net))\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":636},"id":"O1brRsc3SxqH","outputId":"062f1e66-7ad7-49f8-fb09-27f797a6909c","execution":{"iopub.status.busy":"2024-09-08T12:32:37.862745Z","iopub.execute_input":"2024-09-08T12:32:37.863059Z","iopub.status.idle":"2024-09-08T13:52:11.607089Z","shell.execute_reply.started":"2024-09-08T12:32:37.863028Z","shell.execute_reply":"2024-09-08T13:52:11.604558Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Run number  1\nchosen images are of batch 0 and numbers :  [7, 31, 33, 38, 45, 57, 58, 59, 60, 98, 118, 126, 131, 135, 139, 141, 142, 143, 147, 155, 162, 184, 209, 219, 233, 245, 252, 280, 286, 296, 310, 327, 349, 351, 357, 365, 368, 399, 411, 422, 424, 425, 431, 442, 452, 457, 463, 481, 482, 502]\nSaving results every 20 epochs \nTraining started\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 1/200 [00:30<1:40:23, 30.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1, lr: 0.0005000, val loss: 46.50945, acc: 27.61000\nModel state saved at epoch 1\nLogged epoch 1 - Accuracy: 27.6100, Loss: 46.5094\n\n","output_type":"stream"},{"name":"stderr","text":"Training:   1%|          | 2/200 [00:56<1:31:05, 27.60s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▏         | 3/200 [01:22<1:28:50, 27.06s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▏         | 4/200 [01:48<1:27:31, 26.79s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▎         | 5/200 [02:14<1:26:10, 26.51s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 6/200 [02:40<1:25:19, 26.39s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▎         | 7/200 [03:07<1:24:43, 26.34s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▍         | 8/200 [03:33<1:23:59, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▍         | 9/200 [03:59<1:23:29, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   5%|▌         | 10/200 [04:25<1:23:11, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▌         | 11/200 [04:52<1:22:46, 26.28s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▌         | 12/200 [05:18<1:22:18, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▋         | 13/200 [05:44<1:21:49, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   7%|▋         | 14/200 [06:10<1:21:13, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 15/200 [06:37<1:21:04, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 16/200 [07:03<1:20:39, 26.30s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 17/200 [07:29<1:20:09, 26.28s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:   9%|▉         | 18/200 [07:55<1:19:42, 26.28s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|▉         | 19/200 [08:22<1:19:07, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 20/200 [08:52<1:22:51, 27.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20, lr: 0.0004980, val loss: 30.43110, acc: 52.60000\nModel state saved at epoch 20\nLogged epoch 20 - Accuracy: 52.6000, Loss: 30.4311\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 21/200 [09:19<1:21:05, 27.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 22/200 [09:45<1:19:52, 26.92s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▏        | 23/200 [10:11<1:18:48, 26.72s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▏        | 24/200 [10:37<1:17:56, 26.57s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▎        | 25/200 [11:04<1:17:12, 26.47s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  13%|█▎        | 26/200 [11:30<1:16:30, 26.38s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▎        | 27/200 [11:56<1:16:02, 26.37s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▍        | 28/200 [12:22<1:15:31, 26.34s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▍        | 29/200 [12:49<1:15:01, 26.32s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  15%|█▌        | 30/200 [13:15<1:14:30, 26.30s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▌        | 31/200 [13:41<1:13:59, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▌        | 32/200 [14:07<1:13:33, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▋        | 33/200 [14:34<1:13:12, 26.30s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  17%|█▋        | 34/200 [15:00<1:12:39, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 35/200 [15:26<1:12:10, 26.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 36/200 [15:52<1:11:46, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 37/200 [16:19<1:11:14, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  19%|█▉        | 38/200 [16:45<1:10:52, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|█▉        | 39/200 [17:11<1:10:23, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|██        | 40/200 [17:42<1:13:42, 27.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 40, lr: 0.0004921, val loss: 23.92619, acc: 62.25000\nModel state saved at epoch 40\nLogged epoch 40 - Accuracy: 62.2500, Loss: 23.9262\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|██        | 41/200 [18:08<1:12:04, 27.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██        | 42/200 [18:34<1:10:49, 26.90s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  22%|██▏       | 43/200 [19:01<1:09:47, 26.67s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  22%|██▏       | 44/200 [19:27<1:08:56, 26.52s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  22%|██▎       | 45/200 [19:53<1:08:17, 26.43s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  23%|██▎       | 46/200 [20:19<1:07:39, 26.36s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  24%|██▎       | 47/200 [20:45<1:07:08, 26.33s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  24%|██▍       | 48/200 [21:11<1:06:32, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  24%|██▍       | 49/200 [21:38<1:06:13, 26.32s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  25%|██▌       | 50/200 [22:04<1:05:47, 26.31s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  26%|██▌       | 51/200 [22:30<1:05:17, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  26%|██▌       | 52/200 [22:57<1:04:46, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  26%|██▋       | 53/200 [23:23<1:04:14, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  27%|██▋       | 54/200 [23:49<1:03:47, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|██▊       | 55/200 [24:15<1:03:19, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|██▊       | 56/200 [24:41<1:02:50, 26.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|██▊       | 57/200 [25:08<1:02:29, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 58/200 [25:34<1:02:04, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|██▉       | 59/200 [26:00<1:01:35, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|███       | 60/200 [26:31<1:04:38, 27.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 60, lr: 0.0004824, val loss: 20.96637, acc: 67.77000\nModel state saved at epoch 60\nLogged epoch 60 - Accuracy: 67.7700, Loss: 20.9664\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|███       | 61/200 [26:58<1:03:14, 27.30s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  31%|███       | 62/200 [27:24<1:02:04, 26.99s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 63/200 [27:50<1:01:04, 26.75s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 64/200 [28:16<1:00:15, 26.59s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▎      | 65/200 [28:42<59:30, 26.44s/it]  ","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  33%|███▎      | 66/200 [29:09<58:55, 26.38s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|███▎      | 67/200 [29:35<58:21, 26.32s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|███▍      | 68/200 [30:01<57:59, 26.36s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|███▍      | 69/200 [30:27<57:27, 26.32s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  35%|███▌      | 70/200 [30:54<56:55, 26.28s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  36%|███▌      | 71/200 [31:20<56:22, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  36%|███▌      | 72/200 [31:46<55:57, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  36%|███▋      | 73/200 [32:12<55:28, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  37%|███▋      | 74/200 [32:38<55:05, 26.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  38%|███▊      | 75/200 [33:05<54:37, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  38%|███▊      | 76/200 [33:31<54:10, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  38%|███▊      | 77/200 [33:57<53:55, 26.31s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  39%|███▉      | 78/200 [34:24<53:28, 26.30s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|███▉      | 79/200 [34:50<52:58, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|████      | 80/200 [35:21<55:21, 27.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 80, lr: 0.0004691, val loss: 19.65438, acc: 70.18000\nModel state saved at epoch 80\nLogged epoch 80 - Accuracy: 70.1800, Loss: 19.6544\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|████      | 81/200 [35:47<54:01, 27.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  41%|████      | 82/200 [36:13<52:57, 26.93s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  42%|████▏     | 83/200 [36:39<52:05, 26.71s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  42%|████▏     | 84/200 [37:06<51:23, 26.58s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  42%|████▎     | 85/200 [37:32<50:44, 26.47s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 86/200 [37:58<50:09, 26.40s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  44%|████▎     | 87/200 [38:24<49:37, 26.35s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  44%|████▍     | 88/200 [38:51<49:04, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  44%|████▍     | 89/200 [39:17<48:37, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  45%|████▌     | 90/200 [39:43<48:08, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  46%|████▌     | 91/200 [40:09<47:37, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  46%|████▌     | 92/200 [40:35<47:11, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  46%|████▋     | 93/200 [41:01<46:41, 26.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  47%|████▋     | 94/200 [41:28<46:17, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  48%|████▊     | 95/200 [41:54<45:52, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  48%|████▊     | 96/200 [42:20<45:24, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  48%|████▊     | 97/200 [42:46<44:59, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  49%|████▉     | 98/200 [43:12<44:31, 26.19s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  50%|████▉     | 99/200 [43:39<44:03, 26.17s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  50%|█████     | 100/200 [44:10<46:02, 27.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 100, lr: 0.0004523, val loss: 20.00005, acc: 71.48000\nModel state saved at epoch 100\nLogged epoch 100 - Accuracy: 71.4800, Loss: 20.0001\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  50%|█████     | 101/200 [44:36<44:55, 27.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  51%|█████     | 102/200 [45:02<43:56, 26.91s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  52%|█████▏    | 103/200 [45:28<43:08, 26.69s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  52%|█████▏    | 104/200 [45:55<42:31, 26.58s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  52%|█████▎    | 105/200 [46:21<41:51, 26.44s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 106/200 [46:47<41:21, 26.40s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  54%|█████▎    | 107/200 [47:13<40:49, 26.34s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  54%|█████▍    | 108/200 [47:39<40:17, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▍    | 109/200 [48:06<39:50, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 110/200 [48:32<39:20, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  56%|█████▌    | 111/200 [48:58<38:54, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  56%|█████▌    | 112/200 [49:24<38:25, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  56%|█████▋    | 113/200 [49:50<38:00, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  57%|█████▋    | 114/200 [50:17<37:33, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  57%|█████▊    | 115/200 [50:43<37:07, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  58%|█████▊    | 116/200 [51:09<36:39, 26.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  58%|█████▊    | 117/200 [51:35<36:15, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  59%|█████▉    | 118/200 [52:01<35:47, 26.19s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|█████▉    | 119/200 [52:27<35:20, 26.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|██████    | 120/200 [52:58<36:49, 27.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 120, lr: 0.0004322, val loss: 20.60483, acc: 71.60000\nModel state saved at epoch 120\nLogged epoch 120 - Accuracy: 71.6000, Loss: 20.6048\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|██████    | 121/200 [53:24<35:45, 27.16s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  61%|██████    | 122/200 [53:51<34:52, 26.83s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  62%|██████▏   | 123/200 [54:17<34:12, 26.65s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  62%|██████▏   | 124/200 [54:43<33:35, 26.52s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  62%|██████▎   | 125/200 [55:09<33:00, 26.41s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  63%|██████▎   | 126/200 [55:35<32:30, 26.35s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▎   | 127/200 [56:01<31:58, 26.28s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 128/200 [56:28<31:37, 26.35s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 129/200 [56:54<31:08, 26.31s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  65%|██████▌   | 130/200 [57:20<30:39, 26.27s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  66%|██████▌   | 131/200 [57:47<30:11, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  66%|██████▌   | 132/200 [58:13<29:44, 26.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  66%|██████▋   | 133/200 [58:39<29:15, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  67%|██████▋   | 134/200 [59:05<28:52, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  68%|██████▊   | 135/200 [59:32<28:26, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  68%|██████▊   | 136/200 [59:58<27:59, 26.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  68%|██████▊   | 137/200 [1:00:24<27:31, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  69%|██████▉   | 138/200 [1:00:50<27:04, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|██████▉   | 139/200 [1:01:16<26:40, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|███████   | 140/200 [1:01:47<27:37, 27.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 140, lr: 0.0004094, val loss: 21.88950, acc: 72.16000\nModel state saved at epoch 140\nLogged epoch 140 - Accuracy: 72.1600, Loss: 21.8895\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|███████   | 141/200 [1:02:14<26:45, 27.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  71%|███████   | 142/200 [1:02:40<25:59, 26.89s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  72%|███████▏  | 143/200 [1:03:06<25:20, 26.67s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  72%|███████▏  | 144/200 [1:03:32<24:46, 26.54s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  72%|███████▎  | 145/200 [1:03:58<24:17, 26.51s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  73%|███████▎  | 146/200 [1:04:25<23:45, 26.39s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  74%|███████▎  | 147/200 [1:04:51<23:17, 26.37s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  74%|███████▍  | 148/200 [1:05:17<22:47, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  74%|███████▍  | 149/200 [1:05:43<22:19, 26.26s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▌  | 150/200 [1:06:09<21:50, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  76%|███████▌  | 151/200 [1:06:36<21:24, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  76%|███████▌  | 152/200 [1:07:02<20:57, 26.19s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  76%|███████▋  | 153/200 [1:07:28<20:30, 26.19s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  77%|███████▋  | 154/200 [1:07:54<20:05, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  78%|███████▊  | 155/200 [1:08:20<19:37, 26.16s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  78%|███████▊  | 156/200 [1:08:47<19:14, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  78%|███████▊  | 157/200 [1:09:13<18:48, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  79%|███████▉  | 158/200 [1:09:39<18:20, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  80%|███████▉  | 159/200 [1:10:05<17:54, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  80%|████████  | 160/200 [1:10:36<18:23, 27.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 160, lr: 0.0003840, val loss: 22.02450, acc: 72.81000\nModel state saved at epoch 160\nLogged epoch 160 - Accuracy: 72.8100, Loss: 22.0245\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  80%|████████  | 161/200 [1:11:02<17:37, 27.13s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  81%|████████  | 162/200 [1:11:28<17:02, 26.89s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 163/200 [1:11:55<16:27, 26.68s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 164/200 [1:12:21<15:54, 26.51s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▎ | 165/200 [1:12:47<15:23, 26.38s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  83%|████████▎ | 166/200 [1:13:13<14:54, 26.31s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  84%|████████▎ | 167/200 [1:13:39<14:26, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  84%|████████▍ | 168/200 [1:14:05<13:59, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  84%|████████▍ | 169/200 [1:14:31<13:33, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 170/200 [1:14:58<13:06, 26.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  86%|████████▌ | 171/200 [1:15:24<12:40, 26.21s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  86%|████████▌ | 172/200 [1:15:50<12:12, 26.17s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  86%|████████▋ | 173/200 [1:16:16<11:49, 26.29s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  87%|████████▋ | 174/200 [1:16:43<11:22, 26.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|████████▊ | 175/200 [1:17:09<10:55, 26.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|████████▊ | 176/200 [1:17:35<10:28, 26.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|████████▊ | 177/200 [1:18:01<10:01, 26.17s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  89%|████████▉ | 178/200 [1:18:27<09:35, 26.16s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  90%|████████▉ | 179/200 [1:18:53<09:09, 26.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Training:  90%|█████████ | 180/200 [1:19:24<09:12, 27.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 180, lr: 0.0003564, val loss: 24.14222, acc: 72.07000\nModel state saved at epoch 180\nLogged epoch 180 - Accuracy: 72.0700, Loss: 24.1422\n\n","output_type":"stream"},{"name":"stderr","text":"Training:  90%|█████████ | 180/200 [1:19:33<08:50, 26.52s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 200\u001b[0m\n\u001b[1;32m    197\u001b[0m         display(FileLink(zip_filename))\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         trainloss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#     if(epoch%n_param!=0 or epoch==0):\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m#         data_save.append(saved_data)\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m#         data_save=list()\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m#     val_loss, acc = test(epoch)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# step cosine scheduling\u001b[39;00m\n","Cell \u001b[0;32mIn[67], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, save_flag, run_dir, img_idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     52\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 53\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"\nimport shutil\nfrom IPython.display import FileLink\nzip_filename = 'checkpoints.zip'\ndirectory_name = 'checkpoints'\nshutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n#         print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\nprint(\"Click here to download checkpoints  : \")\ndisplay(FileLink(zip_filename))","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:39.842067Z","iopub.execute_input":"2024-09-08T13:52:39.842849Z","iopub.status.idle":"2024-09-08T13:52:58.011891Z","shell.execute_reply.started":"2024-09-08T13:52:39.842806Z","shell.execute_reply":"2024-09-08T13:52:58.010936Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Click here to download checkpoints  : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/checkpoints.zip","text/html":"<a href='checkpoints.zip' target='_blank'>checkpoints.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import os\n\n# Specify the path to your file\nfile_path = 'checkpoints.zip'\n\n# Get the size of the file in bytes\nfile_size = os.path.getsize(file_path)\n\nprint(f\"The size of the file is : {(file_size/(2**20)):.0f} MB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:58.013312Z","iopub.execute_input":"2024-09-08T13:52:58.013623Z","iopub.status.idle":"2024-09-08T13:52:58.018687Z","shell.execute_reply.started":"2024-09-08T13:52:58.013590Z","shell.execute_reply":"2024-09-08T13:52:58.017683Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"The size of the file is : 281 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf checkpoints.zip","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:53:33.509037Z","iopub.execute_input":"2024-09-08T13:53:33.509752Z","iopub.status.idle":"2024-09-08T13:53:34.519550Z","shell.execute_reply.started":"2024-09-08T13:53:33.509711Z","shell.execute_reply":"2024-09-08T13:53:34.518440Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"raise ZeroDivisionError","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.610230Z","iopub.status.idle":"2024-09-08T13:52:11.610603Z","shell.execute_reply.started":"2024-09-08T13:52:11.610417Z","shell.execute_reply":"2024-09-08T13:52:11.610436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd data\n!ls\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.611931Z","iopub.status.idle":"2024-09-08T13:52:11.612348Z","shell.execute_reply.started":"2024-09-08T13:52:11.612152Z","shell.execute_reply":"2024-09-08T13:52:11.612173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.613373Z","iopub.status.idle":"2024-09-08T13:52:11.613788Z","shell.execute_reply.started":"2024-09-08T13:52:11.613561Z","shell.execute_reply":"2024-09-08T13:52:11.613581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf results\n# !rm -rf log\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.615747Z","iopub.status.idle":"2024-09-08T13:52:11.616132Z","shell.execute_reply.started":"2024-09-08T13:52:11.615932Z","shell.execute_reply":"2024-09-08T13:52:11.615952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.618210Z","iopub.status.idle":"2024-09-08T13:52:11.618766Z","shell.execute_reply.started":"2024-09-08T13:52:11.618463Z","shell.execute_reply":"2024-09-08T13:52:11.618491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_idx.detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.620370Z","iopub.status.idle":"2024-09-08T13:52:11.620943Z","shell.execute_reply.started":"2024-09-08T13:52:11.620648Z","shell.execute_reply":"2024-09-08T13:52:11.620678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# from IPython.display import FileLink\n\n# # Specify the directory you want to compress\n# directory_name = 'log'\n# zip_filename = 'log.zip'\n\n# # Compress the directory into a zip file, overwriting if it already exists\n# shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', directory_name)\n\n# # Optionally generate and display a download link\n# print(f\"Directory '{directory_name}' has been zipped as '{zip_filename}'.\")\n# FileLink(zip_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.622605Z","iopub.status.idle":"2024-09-08T13:52:11.623170Z","shell.execute_reply.started":"2024-09-08T13:52:11.622883Z","shell.execute_reply":"2024-09-08T13:52:11.622911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"e1RV3ub4bzaF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnet","metadata":{"id":"n5yDPk01T0oL","execution":{"iopub.status.busy":"2024-09-08T13:52:11.624778Z","iopub.status.idle":"2024-09-08T13:52:11.625310Z","shell.execute_reply.started":"2024-09-08T13:52:11.625025Z","shell.execute_reply":"2024-09-08T13:52:11.625053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n/content/results/runs/run 04/epoch 00/batch 0/layer 01","metadata":{"id":"c61Jvkt9v1cj","execution":{"iopub.status.busy":"2024-09-08T13:52:11.627665Z","iopub.status.idle":"2024-09-08T13:52:11.628186Z","shell.execute_reply.started":"2024-09-08T13:52:11.627913Z","shell.execute_reply":"2024-09-08T13:52:11.627940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9sDNpPTSxqI","outputId":"802a6209-4de8-4ac2-e0c7-37c20468a8bb","execution":{"iopub.status.busy":"2024-09-08T13:52:11.629399Z","iopub.status.idle":"2024-09-08T13:52:11.629942Z","shell.execute_reply.started":"2024-09-08T13:52:11.629666Z","shell.execute_reply":"2024-09-08T13:52:11.629695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ","metadata":{"execution":{"iopub.status.busy":"2024-09-08T13:52:11.631031Z","iopub.status.idle":"2024-09-08T13:52:11.631603Z","shell.execute_reply.started":"2024-09-08T13:52:11.631324Z","shell.execute_reply":"2024-09-08T13:52:11.631352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\n\n# Define the directory path you want to check\ndirectory_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/'\n\n# Check if the directory exists\nif os.path.isdir(directory_path):\n    print(f\"The directory '{directory_path}' exists.\")\nelse:\n    print(f\"The directory '{directory_path}' does not exist.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq9FNrXywIbb","outputId":"db92a1f9-34a2-49a1-8f61-f9e0750ec05d","execution":{"iopub.status.busy":"2024-09-08T13:52:11.633484Z","iopub.status.idle":"2024-09-08T13:52:11.633870Z","shell.execute_reply.started":"2024-09-08T13:52:11.633683Z","shell.execute_reply":"2024-09-08T13:52:11.633702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = r'results/runs/run 03/epoch 00/batch 0/layer 01/01_attention_out.npy'\n\n# Load the NumPy array from the file\ndata = np.load(file_path)","metadata":{"id":"d2GSp2wbSxqI","execution":{"iopub.status.busy":"2024-09-08T13:52:11.635867Z","iopub.status.idle":"2024-09-08T13:52:11.636378Z","shell.execute_reply.started":"2024-09-08T13:52:11.636114Z","shell.execute_reply":"2024-09-08T13:52:11.636140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlFIzQIUSxqI","outputId":"5dce6a00-7620-4944-8d0d-6ccaa42668e6","execution":{"iopub.status.busy":"2024-09-08T13:52:11.637895Z","iopub.status.idle":"2024-09-08T13:52:11.638391Z","shell.execute_reply.started":"2024-09-08T13:52:11.638136Z","shell.execute_reply":"2024-09-08T13:52:11.638161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.shape\n# shape : batch x head x X x Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr5wj-at0UJo","outputId":"874907d1-f72d-45f6-f805-8623093c5a0b","execution":{"iopub.status.busy":"2024-09-08T13:52:11.642546Z","iopub.status.idle":"2024-09-08T13:52:11.643027Z","shell.execute_reply.started":"2024-09-08T13:52:11.642779Z","shell.execute_reply":"2024-09-08T13:52:11.642803Z"},"trusted":true},"execution_count":null,"outputs":[]}]}